/*
 * This file was automatically generated by UTestGen and EvoSuite
 * Mon Apr 21 17:54:58 GMT 2025
 */

package edu.stanford.nlp.parser.lexparser;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import edu.stanford.nlp.fsm.AutomatonMinimizer;
import edu.stanford.nlp.fsm.FastExactAutomatonMinimizer;
import edu.stanford.nlp.ie.AbstractSequenceClassifier;
import edu.stanford.nlp.ie.NERClassifierCombiner;
import edu.stanford.nlp.international.arabic.ArabicMorphoFeatureSpecification;
import edu.stanford.nlp.international.french.FrenchMorphoFeatureSpecification;
import edu.stanford.nlp.international.morph.MorphoFeatureSpecification;
import edu.stanford.nlp.io.ExtensionFileFilter;
import edu.stanford.nlp.io.NumberRangeFileFilter;
import edu.stanford.nlp.io.NumberRangesFileFilter;
import edu.stanford.nlp.io.RegExFileFilter;
import edu.stanford.nlp.ling.BasicDocument;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.ling.HasWord;
import edu.stanford.nlp.ling.IndexedWord;
import edu.stanford.nlp.ling.LabeledWord;
import edu.stanford.nlp.ling.TaggedWord;
import edu.stanford.nlp.ling.Word;
import edu.stanford.nlp.parser.common.ParserGrammar;
import edu.stanford.nlp.parser.common.ParserQuery;
import edu.stanford.nlp.parser.lexparser.BaseLexicon;
import edu.stanford.nlp.parser.lexparser.BinaryGrammar;
import edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor;
import edu.stanford.nlp.parser.lexparser.GrammarCompactor;
import edu.stanford.nlp.parser.lexparser.HebrewTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.LexicalizedParser;
import edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery;
import edu.stanford.nlp.parser.lexparser.Lexicon;
import edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar;
import edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.Options;
import edu.stanford.nlp.parser.lexparser.OutsideRuleFilter;
import edu.stanford.nlp.parser.lexparser.SpanishTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.SpanishUnknownWordModelTrainer;
import edu.stanford.nlp.parser.lexparser.TestOptions;
import edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer;
import edu.stanford.nlp.parser.lexparser.TreebankLangParserParams;
import edu.stanford.nlp.parser.lexparser.UnaryGrammar;
import edu.stanford.nlp.parser.metrics.Eval;
import edu.stanford.nlp.parser.metrics.ParserQueryEval;
import edu.stanford.nlp.parser.shiftreduce.PerceptronModel;
import edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions;
import edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser;
import edu.stanford.nlp.parser.shiftreduce.Transition;
import edu.stanford.nlp.process.Morphology;
import edu.stanford.nlp.process.WhitespaceTokenizer;
import edu.stanford.nlp.process.WordTokenFactory;
import edu.stanford.nlp.sequences.SeqClassifierFlags;
import edu.stanford.nlp.trees.BobChrisTreeNormalizer;
import edu.stanford.nlp.trees.CompositeTreeTransformer;
import edu.stanford.nlp.trees.DiskTreebank;
import edu.stanford.nlp.trees.FilteringTreebank;
import edu.stanford.nlp.trees.MemoryTreebank;
import edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer;
import edu.stanford.nlp.trees.PennTreeReaderFactory;
import edu.stanford.nlp.trees.PennTreebankLanguagePack;
import edu.stanford.nlp.trees.TransformingTreebank;
import edu.stanford.nlp.trees.Tree;
import edu.stanford.nlp.trees.TreeFactory;
import edu.stanford.nlp.trees.TreeGraphNode;
import edu.stanford.nlp.trees.TreeLemmatizer;
import edu.stanford.nlp.trees.TreeNormalizer;
import edu.stanford.nlp.trees.TreeReaderFactory;
import edu.stanford.nlp.trees.Treebank;
import edu.stanford.nlp.trees.TreebankLanguagePack;
import edu.stanford.nlp.util.DeltaIndex;
import edu.stanford.nlp.util.Filters;
import edu.stanford.nlp.util.HashIndex;
import edu.stanford.nlp.util.Index;
import edu.stanford.nlp.util.Pair;
import edu.stanford.nlp.util.Triple;
import java.io.BufferedReader;
import java.io.FileFilter;
import java.io.IOException;
import java.io.ObjectInputStream;
import java.io.Reader;
import java.lang.reflect.Array;
import java.util.ArrayList;
import java.util.Collection;
import java.util.LinkedList;
import java.util.List;
import java.util.Locale;
import java.util.Properties;
import java.util.Set;
import java.util.Stack;
import java.util.Vector;
import java.util.function.Function;
import java.util.function.Predicate;
import java.util.function.UnaryOperator;
import java.util.regex.Pattern;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.System;
import org.evosuite.runtime.mock.java.io.MockFileInputStream;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, separateClassLoader = true) 
public class LexicalizedParser_3_ESTest extends LexicalizedParser_3_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebank0()  throws Throwable  {
      DiskTreebank diskTreebank0 = new DiskTreebank();
      byte[] byteArray0 = new byte[5];
      byteArray0[0] = (byte)77;
      byteArray0[1] = (byte)18;
      byteArray0[2] = (byte) (-98);
      byteArray0[3] = (byte) (-96);
      byteArray0[4] = (byte)72;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      Morphology morphology0 = new Morphology();
      shiftReduceOptions0.wordFunction = (Function<String, String>) morphology0;
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(diskTreebank0, diskTreebank0, diskTreebank0, shiftReduceOptions0);
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingObjectInputStream()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      DiskTreebank diskTreebank0 = new DiskTreebank(100);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser.getParserFromSerializedFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      MockFileInputStream mockFileInputStream0 = new MockFileInputStream("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      ObjectInputStream objectInputStream0 = new ObjectInputStream(mockFileInputStream0);
      LexicalizedParser.loadModel(objectInputStream0);
      Triple<Treebank, Treebank, Treebank> triple0 = LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(diskTreebank0, diskTreebank0, diskTreebank0, shiftReduceOptions0);
      assertNotNull(triple0);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankAndGetParserFromTreebankWithPositiveAndGetParserFromTreebankWithEmptyList()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.doDep = false;
      DiskTreebank diskTreebank0 = new DiskTreebank();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, false);
      LinkedList<List<TaggedWord>> linkedList0 = new LinkedList<List<TaggedWord>>();
      LexicalizedParser.getParserFromTreebank(diskTreebank0, diskTreebank0, 100, exactGrammarCompactor0, shiftReduceOptions0, diskTreebank0, linkedList0);
      boolean boolean0 = false;
      boolean boolean1 = false;
      AbstractSequenceClassifier<CoreLabel>[] abstractSequenceClassifierArray0 = (AbstractSequenceClassifier<CoreLabel>[]) Array.newInstance(AbstractSequenceClassifier.class, 8);
      NERClassifierCombiner nERClassifierCombiner0 = null;
      try {
        nERClassifierCombiner0 = new NERClassifierCombiner(abstractSequenceClassifierArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.ie.ClassifierCombiner", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndGetAnnotatedBinaryTreebankFromTreebank0()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, (Treebank) null, memoryTreebank0, shiftReduceOptions0);
      String[] stringArray0 = new String[5];
      stringArray0[0] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[3] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[4] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankAndGetAnnotatedBinaryTreebankFromTreebankWithNull0()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      MemoryTreebank memoryTreebank1 = new MemoryTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      Triple<Treebank, Treebank, Treebank> triple0 = LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank1, (Treebank) null, memoryTreebank0, shiftReduceOptions0);
      assertNotNull(triple0);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileWithEmptyString()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      DiskTreebank diskTreebank0 = new DiskTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (Options) shiftReduceOptions0);
      Stack<BasicDocument<TransformingTreebank>> stack0 = new Stack<BasicDocument<TransformingTreebank>>();
      Reader reader0 = Reader.nullReader();
      BasicDocument<TransformingTreebank> basicDocument0 = BasicDocument.init(reader0, "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", false);
      stack0.add(basicDocument0);
      BasicDocument<TransformingTreebank> basicDocument1 = BasicDocument.init(reader0, "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", false);
      stack0.add(basicDocument1);
      lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) stack0, 100);
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromTextFile("", shiftReduceOptions0);
      assertNull(lexicalizedParser1);
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFileThrowsNullPointerException()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      String string0 = "Trouble saving parser data to ASCII format.";
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      hebrewTreebankParserParams0.defaultTestSentence();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      ChineseTreebankParserParams chineseTreebankParserParams0 = new ChineseTreebankParserParams();
      Lexicon lexicon0 = chineseTreebankParserParams0.lex(options0, lexicalizedParser0.stateIndex, lexicalizedParser0.stateIndex);
      lexicalizedParser0.lex = lexicon0;
      // Undeclared exception!
      try { 
        lexicalizedParser0.saveParserToTextFile("Trouble saving parser data to ASCII format.");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.BaseLexicon", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesLexicalizedParserAndSaveParserToTextFileThrowsNullPointerException()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      DiskTreebank diskTreebank0 = new DiskTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, true, false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (GrammarCompactor) exactGrammarCompactor0, (Options) shiftReduceOptions0);
      NegraPennTreebankParserParams negraPennTreebankParserParams0 = new NegraPennTreebankParserParams();
      Lexicon lexicon0 = negraPennTreebankParserParams0.lex(shiftReduceOptions0, lexicalizedParser0.stateIndex, lexicalizedParser0.stateIndex);
      LexicalizedParser lexicalizedParser1 = new LexicalizedParser(lexicon0, lexicalizedParser0.bg, lexicalizedParser0.ug, lexicalizedParser0.dg, lexicalizedParser0.wordIndex, lexicalizedParser0.wordIndex, lexicalizedParser0.tagIndex, shiftReduceOptions0);
      // Undeclared exception!
      try { 
        lexicalizedParser1.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.BaseLexicon", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseMultipleTaking2ArgumentsWithNonEmptyList()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      DiskTreebank diskTreebank0 = new DiskTreebank();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (Options) shiftReduceOptions0);
      BasicDocument<TransformingTreebank> basicDocument0 = new BasicDocument<TransformingTreebank>();
      Stack<BasicDocument<TransformingTreebank>> stack0 = new Stack<BasicDocument<TransformingTreebank>>();
      stack0.add(basicDocument0);
      List<Tree> list0 = lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) stack0, 100);
      assertEquals("[[]]", stack0.toString());
      assertEquals(1, list0.size());
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain0()  throws Throwable  {
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "-markFinalStates");
      String[] stringArray0 = new String[8];
      stringArray0[0] = "-escaper";
      stringArray0[1] = "-loadfromtextfile";
      stringArray0[2] = "-savetotextfile";
      stringArray0[4] = "-loadfromtextfile";
      stringArray0[5] = "r";
      stringArray0[6] = "-markFinalStates";
      stringArray0[7] = "-tokenized";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain1()  throws Throwable  {
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "-markFinalStates");
      String[] stringArray0 = new String[8];
      stringArray0[0] = "-escaper";
      stringArray0[1] = "tSo ";
      stringArray0[2] = "-savetotextfile";
      stringArray0[3] = "-loadfromtextfile";
      stringArray0[4] = "-loadfromtextfile";
      stringArray0[5] = "r";
      stringArray0[6] = "-markFinalStates";
      stringArray0[7] = "-tokenized";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsRuntimeException0()  throws Throwable  {
      String[] stringArray0 = new String[4];
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("-loadfromtextfile");
      byte[] byteArray0 = new byte[0];
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      stringArray0[0] = "-loadfromtextfile";
      stringArray0[1] = "-loadfromtextfile";
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("tSo ");
      FileSystemHandling.appendStringToFile(evoSuiteFile1, "-loadfromtextfile");
      stringArray0[2] = "-testTreebank";
      stringArray0[3] = "tSo ";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // -loadfromtextfile: expecting BEGIN block; got end of file.
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsRuntimeException1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("tSo ");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "");
      String[] stringArray0 = new String[2];
      stringArray0[0] = "tSo ";
      stringArray0[1] = "tSo ";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // tSo : expecting BEGIN block; got end of file.
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFile()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      options0.doDep = false;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      lexicalizedParser0.saveParserToTextFile("because");
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromTextFile("because", options0);
      assertFalse(lexicalizedParser1.requiresTags());
  }

  @Test(timeout = 4000)
  public void testParseMultipleTaking2ArgumentsAndSaveParserToTextFileAndTrainFromTreebankTaking11And1()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      options0.newTestOptions();
      lexicalizedParser0.saveParserToTextFile("v#5n>JJ`Qo#e");
      Stack<String> stack0 = new Stack<String>();
      LinkedList<BasicDocument<Object>> linkedList0 = new LinkedList<BasicDocument<Object>>();
      List<Tree> list0 = lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) linkedList0, 100);
      assertEquals(0, list0.size());
  }

  @Test(timeout = 4000)
  public void testParseMultipleTaking2ArgumentsAndParseMultipleTaking2ArgumentsAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      DiskTreebank diskTreebank0 = new DiskTreebank(100);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (Options) shiftReduceOptions0);
      Vector<BasicDocument<TransformingTreebank>> vector0 = new Vector<BasicDocument<TransformingTreebank>>();
      WordTokenFactory wordTokenFactory0 = new WordTokenFactory();
      WhitespaceTokenizer.WhitespaceTokenizerFactory<Word> whitespaceTokenizer_WhitespaceTokenizerFactory0 = new WhitespaceTokenizer.WhitespaceTokenizerFactory<Word>(wordTokenFactory0);
      BasicDocument<TransformingTreebank> basicDocument0 = new BasicDocument<TransformingTreebank>(whitespaceTokenizer_WhitespaceTokenizerFactory0);
      vector0.add(basicDocument0);
      List<Tree> list0 = lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) vector0, 100);
      assertEquals("[[]]", vector0.toString());
      assertEquals(1, list0.size());
  }

  @Test(timeout = 4000)
  public void testParseMultipleTaking2ArgumentsReturningListWhereIsEmptyIsTrue()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      options0.newTestOptions();
      lexicalizedParser0.saveParserToTextFile(" l# ");
      Stack<String> stack0 = new Stack<String>();
      lexicalizedParser0.parseStrings(stack0);
      LinkedList<BasicDocument<Object>> linkedList0 = new LinkedList<BasicDocument<Object>>();
      List<Tree> list0 = lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) linkedList0, (-1880817736));
      assertTrue(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testParseMultipleTaking2ArgumentsAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      assertFalse(lexicalizedParser0.requiresTags());
      
      Vector<BasicDocument<TransformingTreebank>> vector0 = new Vector<BasicDocument<TransformingTreebank>>();
      List<Tree> list0 = lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) vector0, 100);
      assertEquals(0, list0.size());
  }

  @Test(timeout = 4000)
  public void testDefaultCoreNLPFlagsReturningEmptyArray()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/app");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "\"i5!Dqj[Q9\"()");
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      lexicalizedParser0.saveParserToTextFile(" l# ");
      lexicalizedParser0.defaultCoreNLPFlags();
      lexicalizedParser0.getTLPParams();
      String[] stringArray0 = new String[5];
      stringArray0[0] = " l# ";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.ParseFiles", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankAndGetAnnotatedBinaryTreebankFromTreebankWithNull1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank((String) null);
      Triple<Treebank, Treebank, Treebank> triple0 = LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, (Treebank) null, shiftReduceOptions0);
      assertNotNull(triple0);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileReturningLexicalizedParserWhereRequiresTagsIsFalse()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      lexicalizedParser0.saveParserToTextFile(" l# ");
      String[] stringArray0 = new String[5];
      stringArray0[0] = " l# ";
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromTextFile(" l# ", options0);
      assertFalse(lexicalizedParser1.requiresTags());
  }

  @Test(timeout = 4000)
  public void testGetTreePrintAndCopyLexicalizedParserThrowsNullPointerException()  throws Throwable  {
      Pattern pattern0 = Pattern.compile("those");
      RegExFileFilter regExFileFilter0 = new RegExFileFilter(pattern0);
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      Options options0 = new Options(italianTreebankParserParams0);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("Number of features of kind ", (FileFilter) regExFileFilter0, options0);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, true, false);
      lexicalizedParser0.lexicalizedParserQuery();
      lexicalizedParser0.getParserQueryEvals();
      lexicalizedParser0.parserQuery();
      lexicalizedParser0.getTreePrint();
      lexicalizedParser0.getParserQueryEvals();
      LexicalizedParser.loadModel();
      // Undeclared exception!
      try { 
        LexicalizedParser.copyLexicalizedParser((LexicalizedParser) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain2()  throws Throwable  {
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-loadfromtextfile";
      stringArray0[1] = "-loadfromtextfile";
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("tSo ");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "-loadfromtextfile");
      stringArray0[2] = "-testTreebank";
      stringArray0[3] = "tSo ";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.metrics.EvaluateTreebank", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankWithNullAndGetParserFromTreebankAndParseStrings()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, true);
      Stack<List<TaggedWord>> stack0 = new Stack<List<TaggedWord>>();
      DiskTreebank diskTreebank0 = new DiskTreebank();
      Options options0 = new Options(shiftReduceOptions0.tlpParams);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.getParserFromTreebank(diskTreebank0, (Treebank) null, 0.0, exactGrammarCompactor0, options0, (Treebank) null, stack0);
      SeqClassifierFlags seqClassifierFlags0 = new SeqClassifierFlags();
      List<String> list0 = seqClassifierFlags0.comboProps;
      Tree tree0 = lexicalizedParser0.parseStrings(list0);
      assertEquals(Double.NaN, tree0.score(), 0.01);
  }

  @Test(timeout = 4000)
  public void testGetTLPParamsReturningTreebankLangParserParamsWhereSupportsBasicDependenciesIsFalse()  throws Throwable  {
      System.setCurrentTimeMillis(0L);
      int int0 = (-1881195787);
      NegraPennTreebankParserParams negraPennTreebankParserParams0 = new NegraPennTreebankParserParams();
      TreeReaderFactory treeReaderFactory0 = negraPennTreebankParserParams0.treeReaderFactory();
      DiskTreebank diskTreebank0 = new DiskTreebank((-1881195787), treeReaderFactory0);
      Options options0 = new Options(negraPennTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      FastExactAutomatonMinimizer fastExactAutomatonMinimizer0 = (FastExactAutomatonMinimizer)exactGrammarCompactor0.minimizer;
      exactGrammarCompactor0.minimizer = (AutomatonMinimizer) fastExactAutomatonMinimizer0;
      exactGrammarCompactor0.outputType = (Object) fastExactAutomatonMinimizer0;
      exactGrammarCompactor0.verbose = false;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      lexicalizedParser0.getTLPParams();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      lexicalizedParser0.parserQuery();
      Options options1 = lexicalizedParser0.getOp();
      LexicalizedParser.buildTrainTransformer(options1);
      String[] stringArray0 = new String[5];
      stringArray0[0] = "VP^NP,VP^VP,VP^SINV,VP^SQ";
      stringArray0[1] = "oA*aIC3~@";
      stringArray0[2] = "savoured";
      stringArray0[3] = "-traintreebank";
      stringArray0[4] = "\uFF5D";
      // Undeclared exception!
      try { 
        options0.setOptionOrWarn(stringArray0, (-1881195787));
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index -1881195787 out of bounds for length 5
         //
         verifyException("edu.stanford.nlp.parser.lexparser.Options", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ReturningLexicalizedParserWhereRequiresTagsIsFalse0()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      lexicalizedParser0.saveParserToSerialized("fL");
      ArrayList<String> arrayList0 = new ArrayList<String>();
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.loadModel("fL", (List<String>) arrayList0);
      lexicalizedParser1.requiresTags();
      LexicalizedParser lexicalizedParser2 = LexicalizedParser.getParserFromSerializedFile("BEGINBEGIN WORD_INDEX");
      assertNull(lexicalizedParser2);
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking2Arguments0()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.doDep = false;
      DiskTreebank diskTreebank0 = new DiskTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (Options) shiftReduceOptions0);
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray0()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-parseInside";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testGetExtraEvalsThrowsRuntimeException()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      DiskTreebank diskTreebank0 = new DiskTreebank();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (Options) shiftReduceOptions0);
      // Undeclared exception!
      try { 
        lexicalizedParser0.saveParserToTextFile("");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.io.FileNotFoundException
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNoClassDefFoundError0()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("_", false);
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-traintreebank";
      stringArray0[1] = "_";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsRuntimeExceptionAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      Options options0 = new Options();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, options0);
      ArrayList<Word> arrayList0 = new ArrayList<Word>();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-loadfromtextfile";
      stringArray0[1] = "n7G.v6_,2uMj:";
      stringArray0[2] = "-testTreebank";
      stringArray0[3] = "t1 j";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // MemoryTreebank.processFile IOException in file t1 j
         //
         verifyException("edu.stanford.nlp.trees.MemoryTreebank", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsRuntimeException2()  throws Throwable  {
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-loadfromtextfile";
      stringArray0[1] = "-loadfromtextfile";
      stringArray0[2] = "-testTreebank";
      stringArray0[3] = "tSo ";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // MemoryTreebank.processFile IOException in file tSo 
         //
         verifyException("edu.stanford.nlp.trees.MemoryTreebank", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsStringIndexOutOfBoundsExceptionAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      Options options0 = new Options();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, options0);
      Stack<String> stack0 = new Stack<String>();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-tokenizerMethod";
      stringArray0[1] = "-test";
      stringArray0[2] = "";
      stringArray0[3] = "-sunHead";
      stringArray0[4] = "Mk$%SZc@C ";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: StringIndexOutOfBoundsException");
      
      } catch(StringIndexOutOfBoundsException e) {
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray1()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-tokenizermethod";
      stringArray0[1] = "Trouble saving parser data to ASCII format.";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFile0()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      DiskTreebank diskTreebank0 = new DiskTreebank();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory.gz");
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", shiftReduceOptions0);
      assertNull(lexicalizedParser1);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankReturningLexicalizedParserWhereRequiresTagsIsFalse()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      Stack<List<TaggedWord>> stack0 = new Stack<List<TaggedWord>>();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, true);
      LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, 100, exactGrammarCompactor0, shiftReduceOptions0, (Treebank) null, stack0);
      List<ParserQueryEval> list0 = lexicalizedParser0.getParserQueryEvals();
      assertTrue(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankThrowsClassCastException()  throws Throwable  {
      Options options0 = new Options();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-escaper";
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      MemoryTreebank memoryTreebank0 = englishTreebankParserParams0.memoryTreebank();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      IndexedWord indexedWord0 = new IndexedWord();
      TaggedWord taggedWord0 = new TaggedWord(indexedWord0, indexedWord0);
      TreeGraphNode treeGraphNode0 = new TreeGraphNode(taggedWord0, memoryTreebank0);
      TreeGraphNode treeGraphNode1 = treeGraphNode0.highestNodeWithSameHead();
      ArrayList<TaggedWord> arrayList0 = new ArrayList<TaggedWord>();
      List<List<TaggedWord>> list0 = List.of(arrayList0, arrayList0, arrayList0, arrayList0);
      List<List<TaggedWord>> list1 = OutsideRuleFilter.reverse(list0);
      List<List<TaggedWord>> list2 = treeGraphNode1.yield(list1);
      // Undeclared exception!
      try { 
        LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, 100, exactGrammarCompactor0, options0, memoryTreebank0, list2);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // class edu.stanford.nlp.ling.CoreLabel cannot be cast to class java.util.List (edu.stanford.nlp.ling.CoreLabel is in unnamed module of loader org.evosuite.instrumentation.InstrumentingClassLoader @4e80577e; java.util.List is in module java.base of loader 'bootstrap')
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankWithZero()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      DiskTreebank diskTreebank0 = new DiskTreebank();
      LinkedList<TaggedWord> linkedList0 = new LinkedList<TaggedWord>();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, true);
      List<List<TaggedWord>> list0 = List.of(linkedList0, linkedList0, linkedList0, linkedList0);
      // Undeclared exception!
      LexicalizedParser.getParserFromTreebank(diskTreebank0, diskTreebank0, 0.0, exactGrammarCompactor0, shiftReduceOptions0, diskTreebank0, list0);
  }

  @Test(timeout = 4000)
  public void testSetOptionFlags()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      MemoryTreebank memoryTreebank0 = englishTreebankParserParams0.testMemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      HashIndex<String> hashIndex0 = new HashIndex<String>();
      LinkedList<BasicDocument<TransformingTreebank>> linkedList0 = new LinkedList<BasicDocument<TransformingTreebank>>();
      lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) linkedList0);
      String[] stringArray0 = new String[0];
      lexicalizedParser0.setOptionFlags(stringArray0);
      assertEquals(0, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testParseMultipleTakingListWithNonEmptyList()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      DiskTreebank diskTreebank0 = new DiskTreebank();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (Options) shiftReduceOptions0);
      BasicDocument<TransformingTreebank> basicDocument0 = new BasicDocument<TransformingTreebank>();
      Stack<BasicDocument<TransformingTreebank>> stack0 = new Stack<BasicDocument<TransformingTreebank>>();
      stack0.add(basicDocument0);
      List<Tree> list0 = lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) stack0);
      assertEquals("[[]]", stack0.toString());
      assertFalse(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException0()  throws Throwable  {
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-savetotextfile";
      stringArray0[6] = "tSo '";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsArrayIndexOutOfBoundsException0()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-loadfromtextfile";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentExceptionAndMain0()  throws Throwable  {
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory((TreeNormalizer) null);
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-test";
      String string0 = "q";
      stringArray0[1] = "q";
      stringArray0[2] = "usage: java edu.stanford.nlp.parser.lexparser.LexicalizedParser -train trainFilesPath [fileRange] -saveToSerializedFile serializedParserFilename";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Constructor argument not valid list of number ranges: usage: java edu.stanford.nlp.parser.lexparser.LexicalizedParser -train trainFilesPath [fileRange] -saveToSerializedFile serializedParserFilename
         //
         verifyException("edu.stanford.nlp.io.NumberRangesFileFilter", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentException0()  throws Throwable  {
      DiskTreebank diskTreebank0 = new DiskTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-test";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -test
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testTreebankLanguagePackReturningTreebankLanguagePackWhereSupportsGrammaticalStructuresIsFalse()  throws Throwable  {
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      Options options0 = new Options(italianTreebankParserParams0);
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory((TreeFactory) null);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(pennTreeReaderFactory0, "-ppfrien&dly");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, options0);
      HashIndex<String> hashIndex0 = new HashIndex<String>();
      Stack<Locale.LanguageRange> stack0 = new Stack<Locale.LanguageRange>();
      Stack<String> stack1 = new Stack<String>();
      lexicalizedParser0.parseStrings(stack1);
      TreebankLanguagePack treebankLanguagePack0 = lexicalizedParser0.treebankLanguagePack();
      assertEquals("UTF-8", treebankLanguagePack0.getEncoding());
  }

  @Test(timeout = 4000)
  public void testMainThrowsArrayIndexOutOfBoundsException1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-tagseparator";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain3()  throws Throwable  {
      Options options0 = new Options();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-parseinside";
      stringArray0[1] = "-tokenizermethod";
      stringArray0[2] = "-saveToSerializedFile";
      stringArray0[3] = "&";
      stringArray0[4] = "&1Y";
      stringArray0[5] = "-encoding";
      stringArray0[6] = "**^Bv[c<m]dE";
      stringArray0[7] = "-CCdtr";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray2()  throws Throwable  {
      LinkedList<BasicDocument<TransformingTreebank>> linkedList0 = new LinkedList<BasicDocument<TransformingTreebank>>();
      String[] stringArray0 = new String[6];
      stringArray0[0] = "-escaper";
      stringArray0[1] = "-escaper";
      stringArray0[2] = "-savetoserializedfile";
      stringArray0[3] = "tJQloULJS3~W";
      stringArray0[4] = "-escaper";
      LexicalizedParser.main(stringArray0);
      assertEquals(6, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentExceptionAndMain1()  throws Throwable  {
      TreeLemmatizer treeLemmatizer0 = new TreeLemmatizer();
      Options options0 = new Options();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-savetoserializedfile";
      stringArray0[1] = "-savetoserializedfile";
      stringArray0[2] = "-escaper";
      stringArray0[3] = "-savetoserializedfile";
      stringArray0[4] = "-escaper";
      stringArray0[5] = "-savetoserializedfile";
      stringArray0[6] = "-testtreebank";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -test
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentException1()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-testTreebank";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -test
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testParserQueryThrowsNullPointerException()  throws Throwable  {
      TreeLemmatizer treeLemmatizer0 = new TreeLemmatizer();
      Options options0 = new Options();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-escaper";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel(options0, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentExceptionAndSaveParserToTextFile()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("xJrnFf`", true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("/>+po", (FileFilter) extensionFileFilter0, options0);
      extensionFileFilter0.getDescription();
      lexicalizedParser0.saveParserToTextFile("XJRNFF` Files (*.xJrnFf`)");
      lexicalizedParser0.requiresTags();
      lexicalizedParser0.saveParserToTextFile("/>+po");
      String[] stringArray0 = new String[8];
      stringArray0[0] = "-NL";
      stringArray0[1] = "XJRNFF` Files (*.xJrnFf`)";
      stringArray0[2] = "/>+po";
      stringArray0[6] = "xJrnFf`";
      stringArray0[4] = "-treebank";
      stringArray0[5] = "xJrnFf`";
      stringArray0[6] = "XJRNFF` Files (*.xJrnFf`)";
      stringArray0[7] = "/>+po";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Unknown option: -NL
         //
         verifyException("edu.stanford.nlp.parser.lexparser.Options", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsArrayIndexOutOfBoundsException2()  throws Throwable  {
      DiskTreebank diskTreebank0 = new DiskTreebank();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-tokenizerFactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException1()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain4()  throws Throwable  {
      TreeLemmatizer treeLemmatizer0 = new TreeLemmatizer();
      String string0 = "-un";
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-un";
      stringArray0[1] = "-loadfromserializedfile";
      stringArray0[2] = "-un";
      stringArray0[4] = "-un";
      stringArray0[5] = "-un";
      stringArray0[6] = "-un";
      stringArray0[7] = "-un";
      stringArray0[8] = "-un";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingNoArgumentsAndMain()  throws Throwable  {
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.loadModel();
      assertNull(lexicalizedParser0);
      
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-loadfromserializedfile";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException2()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-savetoserializedfile";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray3()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-savetoserializedfile";
      LexicalizedParser.main(stringArray0);
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainAndMain0()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("cZUHYzqZ5@U1HcShw#'");
      FileSystemHandling.appendLineToFile(evoSuiteFile0, "-savetoserializedfile");
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-savetoserializedfile";
      stringArray0[1] = "-savetoserializedfile";
      stringArray0[2] = "-savetoserializedfile";
      stringArray0[3] = "-savetoserializedfile";
      stringArray0[4] = "-savetoserializedfile";
      stringArray0[5] = "-savetoserializedfile";
      stringArray0[6] = "-savetoserializedfile";
      LexicalizedParser.main(stringArray0);
      assertEquals(7, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentException2()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-train";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -train
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentException3()  throws Throwable  {
      String[] stringArray0 = new String[8];
      stringArray0[0] = "-treebank";
      stringArray0[1] = "&PPFrien&dly";
      stringArray0[2] = "-treebank";
      stringArray0[3] = "+ry<[x{v";
      stringArray0[4] = "-treebank";
      stringArray0[5] = "\uFFFD\uFFFD\u0000\u0005s";
      stringArray0[6] = "-treebank";
      stringArray0[7] = "-treebank";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -test
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseMultipleTakingListReturningListWhereIsEmptyIsFalse()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      MemoryTreebank memoryTreebank0 = englishTreebankParserParams0.testMemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      HashIndex<String> hashIndex0 = new HashIndex<String>();
      LinkedList<BasicDocument<TransformingTreebank>> linkedList0 = new LinkedList<BasicDocument<TransformingTreebank>>();
      BasicDocument<TransformingTreebank> basicDocument0 = BasicDocument.init("No test treebank path specified...", "");
      Reader reader0 = Reader.nullReader();
      BufferedReader bufferedReader0 = new BufferedReader(reader0, 100);
      BasicDocument<TransformingTreebank> basicDocument1 = basicDocument0.init((Reader) bufferedReader0);
      linkedList0.add(basicDocument1);
      List<Tree> list0 = lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) linkedList0);
      assertFalse(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testParseMultipleTakingListReturningListWhereIsEmptyIsTrue()  throws Throwable  {
      TreeLemmatizer treeLemmatizer0 = new TreeLemmatizer();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      Options options0 = new Options();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-escaper";
      stringArray0[1] = "-escaper";
      LexicalizedParser.main(stringArray0);
      PennTreebankLanguagePack pennTreebankLanguagePack0 = new PennTreebankLanguagePack();
      BobChrisTreeNormalizer bobChrisTreeNormalizer0 = new BobChrisTreeNormalizer(pennTreebankLanguagePack0);
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory(bobChrisTreeNormalizer0);
      DiskTreebank diskTreebank0 = new DiskTreebank(187, pennTreeReaderFactory0);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, options0);
      LinkedList<BasicDocument<TransformingTreebank>> linkedList0 = new LinkedList<BasicDocument<TransformingTreebank>>();
      lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) linkedList0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, false);
      LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      TreeAnnotatorAndBinarizer treeAnnotatorAndBinarizer0 = new TreeAnnotatorAndBinarizer(options0.tlpParams, true, false, true, options0);
      CompositeTreeTransformer compositeTreeTransformer0 = LexicalizedParser.buildTrainTransformer(options0, treeAnnotatorAndBinarizer0);
      assertNotNull(compositeTreeTransformer0);
  }

  @Test(timeout = 4000)
  public void testParseMultipleTakingListAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      LinkedList<BasicDocument<TransformingTreebank>> linkedList0 = new LinkedList<BasicDocument<TransformingTreebank>>();
      List<Tree> list0 = lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) linkedList0);
      assertEquals(0, list0.size());
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndGetAnnotatedBinaryTreebankFromTreebank1()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options();
      Options options1 = new Options();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, memoryTreebank0, options1);
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-model";
      stringArray0[1] = "-IN";
      stringArray0[2] = "BEGIN";
      stringArray0[3] = "lI.";
      stringArray0[4] = "OR!";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray4()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-model";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException3()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-model";
      stringArray0[1] = "-savetoserializedfile";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsStringIndexOutOfBoundsExceptionAndRequiresTags()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("-ppfrien&dly", false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("-encoding", (FileFilter) extensionFileFilter0, options0);
      lexicalizedParser0.saveParserToSerialized("-ppfrien&dly");
      extensionFileFilter0.getDescription();
      lexicalizedParser0.requiresTags();
      String[] stringArray0 = new String[6];
      stringArray0[0] = "-encoding";
      stringArray0[1] = "-ppfrien&dly";
      stringArray0[2] = "-PPFRIEN&DLY Files (*.-ppfrien&dly)";
      stringArray0[3] = "-PPFRIEN&DLY Files (*.-ppfrien&dly)";
      stringArray0[4] = "";
      stringArray0[5] = "-ppfrien&dly";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: StringIndexOutOfBoundsException");
      
      } catch(StringIndexOutOfBoundsException e) {
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray5()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-encoding";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankThrowsNullPointerExceptionAndGetAnnotatedBinaryTreebankFromTreebank()  throws Throwable  {
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      Options options0 = new Options(italianTreebankParserParams0);
      String[] stringArray0 = new String[8];
      stringArray0[0] = "#<+b-$ ";
      stringArray0[1] = "-traintreebank";
      stringArray0[2] = "anagram";
      stringArray0[3] = "4b LZrt";
      stringArray0[4] = "4fPfY-r1a2r14Pd";
      stringArray0[5] = "qQ36#%>NvH$-RnDJ";
      stringArray0[6] = "-encoding";
      stringArray0[7] = "UW~7,W/v;GULP,";
      options0.setOptionsOrWarn(stringArray0);
      // Undeclared exception!
      try { 
        LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank((Treebank) null, (Treebank) null, (Treebank) null, options0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankThrowsNullPointerException()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      // Undeclared exception!
      try { 
        LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank((Treebank) null, (Treebank) null, (Treebank) null, shiftReduceOptions0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankWithNullAndGetParserFromTreebankThrowsTooManyResourcesException()  throws Throwable  {
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      MemoryTreebank memoryTreebank0 = englishTreebankParserParams0.testMemoryTreebank();
      Options options0 = new Options(englishTreebankParserParams0);
      BasicDocument<Pair<TransformingTreebank, TransformingTreebank>> basicDocument0 = BasicDocument.init("-treebank");
      ArrayList<Word> arrayList0 = new ArrayList<Word>();
      basicDocument0.init((List<? extends Word>) arrayList0);
      ArrayList<List<TaggedWord>> arrayList1 = new ArrayList<List<TaggedWord>>();
      // Undeclared exception!
      LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, 0.0, (GrammarCompactor) null, options0, memoryTreebank0, arrayList1);
  }

  @Test(timeout = 4000)
  public void testGetParserFromFileAndTreebankLanguagePack()  throws Throwable  {
      TreeLemmatizer treeLemmatizer0 = new TreeLemmatizer();
      Options options0 = new Options();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("xJrnFf`");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("xJrnFf`", (FileFilter) extensionFileFilter0, options0);
      lexicalizedParser0.saveParserToSerialized("xJrnFf`");
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/app");
      byte[] byteArray0 = new byte[9];
      byteArray0[0] = (byte)9;
      byteArray0[1] = (byte)3;
      byteArray0[2] = (byte)1;
      byteArray0[3] = (byte) (-52);
      byteArray0[4] = (byte)66;
      byteArray0[5] = (byte) (-116);
      byteArray0[6] = (byte) (-81);
      byteArray0[7] = (byte)52;
      byteArray0[8] = (byte)42;
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      boolean boolean0 = lexicalizedParser0.requiresTags();
      assertFalse(boolean0);
      
      Vector<Locale.LanguageRange> vector0 = new Vector<Locale.LanguageRange>();
      HashIndex<String> hashIndex0 = new HashIndex<String>(1);
      Stack<Locale.LanguageRange> stack0 = new Stack<Locale.LanguageRange>();
      List<String> list0 = Locale.filterTags((List<Locale.LanguageRange>) stack0, (Collection<String>) hashIndex0);
      lexicalizedParser0.parseStrings(list0);
      lexicalizedParser0.treebankLanguagePack();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      HashIndex<Transition> hashIndex1 = new HashIndex<Transition>(497);
      DeltaIndex<Transition> deltaIndex0 = new DeltaIndex<Transition>(hashIndex1);
      PerceptronModel perceptronModel0 = new PerceptronModel(shiftReduceOptions0, deltaIndex0, (Set<String>) null, (Set<String>) null, (Set<String>) null);
      ShiftReduceParser shiftReduceParser0 = new ShiftReduceParser(shiftReduceOptions0, perceptronModel0);
      Options options1 = shiftReduceParser0.getOp();
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromFile("xJrnFf`", options1);
      assertNotNull(lexicalizedParser1);
      assertFalse(lexicalizedParser1.requiresTags());
  }

  @Test(timeout = 4000)
  public void testMainThrowsArrayIndexOutOfBoundsExceptionAndMain()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      Options options0 = new Options();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-escaper";
      stringArray0[1] = "-escaper";
      stringArray0[2] = "-escaper";
      stringArray0[3] = "-escaper";
      stringArray0[4] = "-saveToTextFile";
      stringArray0[5] = "-escaper";
      stringArray0[6] = "-escaper";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 7 out of bounds for length 7
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException4()  throws Throwable  {
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-escaper";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray6()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "\u00EE");
      Predicate.isEqual("\u00EE");
      Options.LexOptions options_LexOptions0 = new Options.LexOptions();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-train2";
      stringArray0[1] = "/u/scr/nlp/deeplearning/datasets/turian/embeddings-scaled.EMBEDDING_SIZE=25.txt";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testParseTree()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, options0);
      ArrayList<Word> arrayList0 = new ArrayList<Word>();
      Tree tree0 = lexicalizedParser0.parseTree(arrayList0);
      assertNull(tree0);
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray7()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-tlpp";
      LexicalizedParser.main(stringArray0);
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException5()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-traintreebank";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNoClassDefFoundError1()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-traintreebank";
      stringArray0[1] = "\u00EE";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetOpAndSaveParserToTextFile()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      LexicalizedParser.getParserFromSerializedFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, true);
      lexicalizedParser0.saveParserToTextFile("5jk56Djz4hq.gz");
      Options options0 = lexicalizedParser0.getOp();
      assertEquals(0.0, options0.baseParserWeight, 0.01);
  }

  @Test(timeout = 4000)
  public void testGetTreePrintAndGetTreePrintThrowsNoClassDefFoundError()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("xJrnFf`", false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("\u00EE", (FileFilter) extensionFileFilter0, options0);
      lexicalizedParser0.saveParserToSerialized("xJrnFf`");
      lexicalizedParser0.requiresTags();
      Vector<Locale.LanguageRange> vector0 = new Vector<Locale.LanguageRange>();
      HashIndex<String> hashIndex0 = new HashIndex<String>(100);
      Stack<Locale.LanguageRange> stack0 = new Stack<Locale.LanguageRange>();
      List<String> list0 = Locale.filterTags((List<Locale.LanguageRange>) stack0, (Collection<String>) hashIndex0);
      lexicalizedParser0.parseStrings(list0);
      lexicalizedParser0.treebankLanguagePack();
      lexicalizedParser0.saveParserToTextFile("\u00EE");
      // Undeclared exception!
      try { 
        lexicalizedParser0.getTreePrint();
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFile1()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      assertFalse(lexicalizedParser0.requiresTags());
      
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", shiftReduceOptions0);
      assertFalse(lexicalizedParser1.requiresTags());
  }

  @Test(timeout = 4000)
  public void testMainThrowsRuntimeExceptionAndMain0()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-tune";
      stringArray0[1] = "xJrnFf`";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // MemoryTreebank.processFile IOException in file xJrnFf`
         //
         verifyException("edu.stanford.nlp.trees.MemoryTreebank", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException6()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-tune";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseStringsThrowsNoClassDefFoundError()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      Stack<String> stack0 = new Stack<String>();
      stack0.add("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      // Undeclared exception!
      try { 
        lexicalizedParser0.parseStrings(stack0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testDefaultCoreNLPFlagsAndMainThrowsNoClassDefFoundError()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      MemoryTreebank memoryTreebank1 = new MemoryTreebank(1);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser.getParserFromSerializedFile("H7LRh%h,-Y");
      BobChrisTreeNormalizer.EmptyFilter bobChrisTreeNormalizer_EmptyFilter0 = new BobChrisTreeNormalizer.EmptyFilter();
      BobChrisTreeNormalizer.EmptyFilter bobChrisTreeNormalizer_EmptyFilter1 = new BobChrisTreeNormalizer.EmptyFilter();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("H7LRh%h,-Y", true);
      ExtensionFileFilter extensionFileFilter1 = new ExtensionFileFilter("-ZUoj7c[nY/#xB", true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("H7LRh%h,-Y", (FileFilter) extensionFileFilter1, (Options) shiftReduceOptions0);
      extensionFileFilter1.getDescription();
      lexicalizedParser0.saveParserToSerialized("X4riT^");
      lexicalizedParser0.requiresTags();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "X4riT^";
      stringArray0[1] = "-ZUoj7c[nY/#xB";
      lexicalizedParser0.defaultCoreNLPFlags();
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testDefaultCoreNLPFlagsAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      DiskTreebank diskTreebank0 = new DiskTreebank();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (Options) shiftReduceOptions0);
      String[] stringArray0 = lexicalizedParser0.defaultCoreNLPFlags();
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testBuildTrainTransformerTaking2Arguments()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.distance = false;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      Filters.RandomFilter<Object> filters_RandomFilter0 = new Filters.RandomFilter<Object>(0.0);
      Predicate.isEqual(null);
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      BinaryGrammar binaryGrammar0 = new BinaryGrammar(lexicalizedParser0.tagIndex);
      MemoryTreebank memoryTreebank1 = new MemoryTreebank((TreeNormalizer) null);
      BinaryGrammar binaryGrammar1 = new BinaryGrammar(lexicalizedParser1.tagIndex);
      Options.LexOptions options_LexOptions0 = shiftReduceOptions0.lexOptions;
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank1, memoryTreebank1, shiftReduceOptions0);
      lexicalizedParser0.requiresTags();
      Vector<Locale.LanguageRange> vector0 = new Vector<Locale.LanguageRange>();
      HashIndex<String> hashIndex0 = new HashIndex<String>(2072);
      List<String> list0 = Locale.filterTags((List<Locale.LanguageRange>) vector0, (Collection<String>) hashIndex0);
      lexicalizedParser0.parseStrings(list0);
      lexicalizedParser1.treebankLanguagePack();
      TreeAnnotatorAndBinarizer treeAnnotatorAndBinarizer0 = new TreeAnnotatorAndBinarizer(shiftReduceOptions0.tlpParams, false, false, true, shiftReduceOptions0);
      CompositeTreeTransformer compositeTreeTransformer0 = LexicalizedParser.buildTrainTransformer((Options) shiftReduceOptions0, treeAnnotatorAndBinarizer0);
      assertNotNull(compositeTreeTransformer0);
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain5()  throws Throwable  {
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-PSEQcS";
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      TreebankLanguagePack treebankLanguagePack0 = englishTreebankParserParams0.treebankLanguagePack();
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams(treebankLanguagePack0);
      String[] stringArray1 = new String[5];
      stringArray1[0] = "-PSEQcS";
      stringArray1[1] = "-tokenized";
      stringArray1[2] = "-PSEQcS";
      stringArray1[3] = "x8*Bca[q{e0{";
      stringArray1[4] = "-PSEQcS";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray8()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      Options options0 = new Options();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-tokenized";
      stringArray0[1] = "-parseinside.gz";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testCreatesLexicalizedParserAndGetExtraEvals()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options();
      String string0 = "xJrnFf`";
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("xJrnFf`", false);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, true);
      HashIndex<String> hashIndex0 = new HashIndex<String>(100);
      BaseLexicon baseLexicon0 = new BaseLexicon(options0, hashIndex0, hashIndex0);
      UnaryGrammar unaryGrammar0 = new UnaryGrammar(hashIndex0);
      Options options1 = new Options();
      MLEDependencyGrammar mLEDependencyGrammar0 = new MLEDependencyGrammar(options0.tlpParams, true, false, true, true, options1, hashIndex0, hashIndex0);
      HashIndex<String> hashIndex1 = new HashIndex<String>((Index<? extends String>) hashIndex0);
      LexicalizedParser lexicalizedParser0 = new LexicalizedParser(baseLexicon0, (BinaryGrammar) null, unaryGrammar0, mLEDependencyGrammar0, hashIndex0, hashIndex1, hashIndex1, options1);
      lexicalizedParser0.requiresTags();
      EvoSuiteFile evoSuiteFile0 = null;
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      lexicalizedParser0.getExtraEvals();
      NumberRangesFileFilter numberRangesFileFilter0 = null;
      try {
        numberRangesFileFilter0 = new NumberRangesFileFilter("}{= i@nm", false);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Constructor argument not valid list of number ranges: }{= i@nm
         //
         verifyException("edu.stanford.nlp.io.NumberRangesFileFilter", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray9()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-savetrantrees";
      LexicalizedParser.main(stringArray0);
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testTreebankLanguagePackAndTreebankLanguagePack()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.distance = false;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      Filters.RandomFilter<Object> filters_RandomFilter0 = new Filters.RandomFilter<Object>(0.0);
      Predicate.isEqual(null);
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      BinaryGrammar binaryGrammar0 = new BinaryGrammar(lexicalizedParser0.tagIndex);
      MemoryTreebank memoryTreebank1 = new MemoryTreebank((TreeNormalizer) null);
      BinaryGrammar binaryGrammar1 = new BinaryGrammar(lexicalizedParser1.tagIndex);
      Options.LexOptions options_LexOptions0 = shiftReduceOptions0.lexOptions;
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank1, memoryTreebank1, shiftReduceOptions0);
      boolean boolean0 = lexicalizedParser0.requiresTags();
      assertFalse(boolean0);
      
      Vector<Locale.LanguageRange> vector0 = new Vector<Locale.LanguageRange>();
      HashIndex<String> hashIndex0 = new HashIndex<String>(2072);
      List<String> list0 = Locale.filterTags((List<Locale.LanguageRange>) vector0, (Collection<String>) hashIndex0);
      lexicalizedParser1.parseStrings(list0);
      lexicalizedParser0.treebankLanguagePack();
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testParserQueryAndMainAndParserQuery()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      TreeLemmatizer treeLemmatizer0 = new TreeLemmatizer();
      PennTreebankLanguagePack pennTreebankLanguagePack0 = new PennTreebankLanguagePack();
      englishTreebankParserParams0.treebankLanguagePack();
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams(pennTreebankLanguagePack0);
      String[] stringArray0 = new String[0];
      LexicalizedParser.main(stringArray0);
      LexicalizedParser.main(stringArray0);
      MemoryTreebank memoryTreebank0 = englishTreebankParserParams0.testMemoryTreebank();
      TransformingTreebank transformingTreebank0 = new TransformingTreebank(memoryTreebank0, treeLemmatizer0);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      ParserQuery parserQuery0 = lexicalizedParser0.parserQuery();
      assertFalse(parserQuery0.parseFallback());
  }

  @Test(timeout = 4000)
  public void testLexicalizedParserQuery()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      DiskTreebank diskTreebank0 = new DiskTreebank(100);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (Options) shiftReduceOptions0);
      LexicalizedParserQuery lexicalizedParserQuery0 = lexicalizedParser0.lexicalizedParserQuery();
      assertFalse(lexicalizedParserQuery0.hasFactoredParse());
  }

  @Test(timeout = 4000)
  public void testLexicalizedParserQueryAndGetExtraEvals()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(1398);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.distance = true;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      BobChrisTreeNormalizer.EmptyFilter bobChrisTreeNormalizer_EmptyFilter0 = new BobChrisTreeNormalizer.EmptyFilter();
      Filters.RandomFilter<Object> filters_RandomFilter0 = new Filters.RandomFilter<Object>(0.0);
      bobChrisTreeNormalizer_EmptyFilter0.or(filters_RandomFilter0);
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser1.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      FileSystemHandling.shouldAllThrowIOExceptions();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[3] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      lexicalizedParser0.lexicalizedParserQuery();
      LexicalizedParser.getParserFromTextFile(")+f\"s9bLQ*P&\"KwK", shiftReduceOptions0);
      List<Eval> list0 = lexicalizedParser0.getExtraEvals();
      assertTrue(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ReturningNull()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(1363);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      Options options0 = new Options();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("-tune", false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("xJrnFf`", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("7MQ2");
      lexicalizedParser0.requiresTags();
      String[] stringArray0 = new String[0];
      LexicalizedParser.loadModel(";mvR", stringArray0);
      LexicalizedParser.main(stringArray0);
      assertEquals(0, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testTreebankLanguagePack()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      DiskTreebank diskTreebank0 = new DiskTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (Options) shiftReduceOptions0);
      TreebankLanguagePack treebankLanguagePack0 = lexicalizedParser0.treebankLanguagePack();
      assertEquals("mrg", treebankLanguagePack0.treebankFileExtension());
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking2Arguments1()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(1363);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.distance = true;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      BobChrisTreeNormalizer.EmptyFilter bobChrisTreeNormalizer_EmptyFilter0 = new BobChrisTreeNormalizer.EmptyFilter();
      // Undeclared exception!
      try { 
        lexicalizedParser0.lemmatize("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromSerializedFileWithNull()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(1363);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.distance = true;
      LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      BobChrisTreeNormalizer.EmptyFilter bobChrisTreeNormalizer_EmptyFilter0 = new BobChrisTreeNormalizer.EmptyFilter();
      Predicate.isEqual(null);
      MemoryTreebank memoryTreebank1 = new MemoryTreebank();
      Options.LexOptions options_LexOptions0 = new Options.LexOptions();
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank1, memoryTreebank0, memoryTreebank0, shiftReduceOptions0);
      EvoSuiteFile evoSuiteFile0 = null;
      FileSystemHandling.setPermissions((EvoSuiteFile) null, true, false, false);
      LexicalizedParser.getParserFromSerializedFile((String) null);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, true, false);
      // Undeclared exception!
      LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, 3653.34, exactGrammarCompactor0, shiftReduceOptions0, memoryTreebank0, (List<List<TaggedWord>>) null);
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndSaveParserToSerializedAndTrainFromTreebankTaking11And1()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(1363);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.distance = true;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      BobChrisTreeNormalizer.EmptyFilter bobChrisTreeNormalizer_EmptyFilter0 = new BobChrisTreeNormalizer.EmptyFilter();
      Filters.RandomFilter<Object> filters_RandomFilter0 = new Filters.RandomFilter<Object>(0.0);
      bobChrisTreeNormalizer_EmptyFilter0.or(filters_RandomFilter0);
      Predicate.isEqual(null);
      FilteringTreebank filteringTreebank0 = new FilteringTreebank(memoryTreebank0, bobChrisTreeNormalizer_EmptyFilter0);
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.trainFromTreebank((Treebank) filteringTreebank0, (Options) shiftReduceOptions0);
      BinaryGrammar binaryGrammar0 = new BinaryGrammar(lexicalizedParser0.tagIndex);
      lexicalizedParser0.bg = binaryGrammar0;
      MemoryTreebank memoryTreebank1 = new MemoryTreebank((TreeNormalizer) null);
      NumberRangeFileFilter numberRangeFileFilter0 = new NumberRangeFileFilter(1363, (-3305), true);
      LexicalizedParser lexicalizedParser2 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) numberRangeFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser1.saveParserToSerialized("-tokenizeroptions");
      lexicalizedParser2.requiresTags();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-tokenizeroptions";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[3] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[4] = "-tokenizeroptions";
      stringArray0[5] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[6] = "-tokenizeroptions";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray10()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-tokenizeroptions";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testCopyLexicalizedParserReturningLexicalizedParserWhereRequiresTagsIsFalse()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.distance = false;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      BobChrisTreeNormalizer.EmptyFilter bobChrisTreeNormalizer_EmptyFilter0 = new BobChrisTreeNormalizer.EmptyFilter();
      Filters.RandomFilter<Object> filters_RandomFilter0 = new Filters.RandomFilter<Object>(0.0);
      bobChrisTreeNormalizer_EmptyFilter0.or(filters_RandomFilter0);
      Predicate.isEqual(null);
      FilteringTreebank filteringTreebank0 = new FilteringTreebank(memoryTreebank0, bobChrisTreeNormalizer_EmptyFilter0);
      LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      BinaryGrammar binaryGrammar0 = new BinaryGrammar(lexicalizedParser0.tagIndex);
      MemoryTreebank memoryTreebank1 = new MemoryTreebank();
      Options.LexOptions options_LexOptions0 = new Options.LexOptions();
      shiftReduceOptions0.lexOptions = options_LexOptions0;
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, memoryTreebank1, shiftReduceOptions0);
      EvoSuiteFile evoSuiteFile0 = null;
      FileSystemHandling.setPermissions((EvoSuiteFile) null, true, false, true);
      LexicalizedParser.getParserFromSerializedFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser.loadModel();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, true);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      // Undeclared exception!
      LexicalizedParser.getParserFromTreebank(filteringTreebank0, filteringTreebank0, 1, exactGrammarCompactor0, shiftReduceOptions0, filteringTreebank0, vector0);
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(1398);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.distance = true;
      LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      BobChrisTreeNormalizer.EmptyFilter bobChrisTreeNormalizer_EmptyFilter0 = new BobChrisTreeNormalizer.EmptyFilter();
      Filters.RandomFilter<Object> filters_RandomFilter0 = new Filters.RandomFilter<Object>(0.0);
      bobChrisTreeNormalizer_EmptyFilter0.or(filters_RandomFilter0);
      Predicate.isEqual(null);
      FilteringTreebank filteringTreebank0 = new FilteringTreebank(memoryTreebank0, bobChrisTreeNormalizer_EmptyFilter0);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("cZUHYzqZ5@U1HcShw#'");
      FileSystemHandling.appendLineToFile(evoSuiteFile0, "p.t3|H<NVSkwjT");
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-pseqcs";
      stringArray0[1] = "-sentences";
      stringArray0[2] = "p.t3|H<NVSkwjT";
      stringArray0[3] = "p.t3|H<NVSkwjT";
      stringArray0[4] = "p.t3|H<NVSkwjT";
      stringArray0[5] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[6] = "-tokenizeroptions";
      stringArray0[7] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[8] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray11()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-sentences";
      stringArray0[1] = "-sentences";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testParseThrowsNullPointerException()  throws Throwable  {
      Options options0 = new Options();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("xJrnFf`", false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("\u00EE", (FileFilter) extensionFileFilter0, options0);
      lexicalizedParser0.saveParserToSerialized("xJrnFf`");
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, true, true);
      lexicalizedParser0.getTLPParams();
      LexicalizedParser.getParserFromSerializedFile("\u00EE");
      LexicalizedParser.getParserFromTextFile("depig", options0);
      LexicalizedParser.getParserFromTextFile("T\"tJ?`S", options0);
      LexicalizedParser.loadModel();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      // Undeclared exception!
      try { 
        lexicalizedParser0.parse((List<? extends HasWord>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.common.ParserUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ReturningLexicalizedParserWhereRequiresTagsIsFalse1()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(1363);
      Options options0 = new Options();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("-savetraintrees", false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("cq+h|", (FileFilter) extensionFileFilter0, options0);
      lexicalizedParser0.saveParserToSerialized("3Uuz\"cMs");
      lexicalizedParser0.requiresTags();
      String[] stringArray0 = new String[0];
      LexicalizedParser.loadModel("3Uuz\"cMs", stringArray0);
      LexicalizedParser.main(stringArray0);
      assertEquals(0, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testParseStringsAndParseStringsThrowsNoClassDefFoundError()  throws Throwable  {
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      NegraPennTreebankParserParams negraPennTreebankParserParams0 = new NegraPennTreebankParserParams();
      DiskTreebank diskTreebank0 = negraPennTreebankParserParams0.diskTreebank();
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, options0);
      Filters.RandomFilter<Object> filters_RandomFilter0 = new Filters.RandomFilter<Object>(731.1394109007899);
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      BinaryGrammar binaryGrammar0 = new BinaryGrammar(lexicalizedParser1.stateIndex);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank((TreeNormalizer) null);
      BinaryGrammar binaryGrammar1 = new BinaryGrammar(lexicalizedParser1.stateIndex);
      Options.LexOptions options_LexOptions0 = options0.lexOptions;
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(diskTreebank0, diskTreebank0, memoryTreebank0, options0);
      lexicalizedParser0.requiresTags();
      Vector<Locale.LanguageRange> vector0 = new Vector<Locale.LanguageRange>();
      HashIndex<String> hashIndex0 = new HashIndex<String>(1);
      Locale.filterTags((List<Locale.LanguageRange>) vector0, (Collection<String>) hashIndex0);
      FrenchMorphoFeatureSpecification frenchMorphoFeatureSpecification0 = new FrenchMorphoFeatureSpecification();
      MorphoFeatureSpecification.MorphoFeatureType morphoFeatureSpecification_MorphoFeatureType0 = MorphoFeatureSpecification.MorphoFeatureType.NUM;
      List<String> list0 = frenchMorphoFeatureSpecification0.getValues(morphoFeatureSpecification_MorphoFeatureType0);
      // Undeclared exception!
      try { 
        lexicalizedParser1.parseStrings(list0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseStringsReturningTreeWhereScoreIsPositive()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(1398);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.distance = true;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      BobChrisTreeNormalizer.EmptyFilter bobChrisTreeNormalizer_EmptyFilter0 = new BobChrisTreeNormalizer.EmptyFilter();
      Filters.RandomFilter<Object> filters_RandomFilter0 = new Filters.RandomFilter<Object>(0.0);
      bobChrisTreeNormalizer_EmptyFilter0.or(filters_RandomFilter0);
      Predicate.isEqual(null);
      FilteringTreebank filteringTreebank0 = new FilteringTreebank(memoryTreebank0, bobChrisTreeNormalizer_EmptyFilter0);
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.trainFromTreebank((Treebank) filteringTreebank0, (Options) shiftReduceOptions0);
      BinaryGrammar binaryGrammar0 = new BinaryGrammar(lexicalizedParser0.tagIndex);
      lexicalizedParser0.bg = binaryGrammar0;
      MemoryTreebank memoryTreebank1 = new MemoryTreebank((TreeNormalizer) null);
      Options.LexOptions options_LexOptions0 = shiftReduceOptions0.lexOptions;
      shiftReduceOptions0.lexOptions = options_LexOptions0;
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, memoryTreebank1, shiftReduceOptions0);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, true, false, true);
      Vector<Locale.LanguageRange> vector0 = new Vector<Locale.LanguageRange>();
      HashIndex<String> hashIndex0 = new HashIndex<String>(1398);
      List<String> list0 = Locale.filterTags((List<Locale.LanguageRange>) vector0, (Collection<String>) hashIndex0);
      Tree tree0 = lexicalizedParser1.parseStrings(list0);
      assertEquals(Double.NaN, tree0.score(), 0.01);
  }

  @Test(timeout = 4000)
  public void testParseStringsAndParseStringsWithEmptyList()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      Stack<String> stack0 = new Stack<String>();
      Tree tree0 = lexicalizedParser0.parseStrings(stack0);
      assertEquals(Double.NaN, tree0.score(), 0.01);
  }

  @Test(timeout = 4000)
  public void testMainAndMain1()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      EnglishTreebankParserParams englishTreebankParserParams1 = new EnglishTreebankParserParams();
      TreeLemmatizer treeLemmatizer0 = new TreeLemmatizer();
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "-savetraintrees");
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-sentences";
      stringArray0[1] = "-savetraintrees";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException7()  throws Throwable  {
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-sentences";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankAndGetParserFromTreebankThrowsClassCastException()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      Stack<String> stack0 = new Stack<String>();
      MemoryTreebank memoryTreebank0 = englishTreebankParserParams0.memoryTreebank();
      NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new NPTmpRetainingTreeNormalizer();
      TransformingTreebank transformingTreebank0 = new TransformingTreebank(memoryTreebank0, nPTmpRetainingTreeNormalizer0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, true);
      LabeledWord labeledWord0 = new LabeledWord("sj;!OS3&?V%~ 5m#cL-");
      TreeGraphNode treeGraphNode0 = new TreeGraphNode(labeledWord0, memoryTreebank0);
      ArrayList<List<TaggedWord>> arrayList0 = new ArrayList<List<TaggedWord>>();
      List<List<TaggedWord>> list0 = treeGraphNode0.yield(arrayList0);
      // Undeclared exception!
      try { 
        LexicalizedParser.getParserFromTreebank(transformingTreebank0, transformingTreebank0, 0.0, exactGrammarCompactor0, shiftReduceOptions0, transformingTreebank0, list0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // class edu.stanford.nlp.ling.CoreLabel cannot be cast to class java.util.List (edu.stanford.nlp.ling.CoreLabel is in unnamed module of loader org.evosuite.instrumentation.InstrumentingClassLoader @4e80577e; java.util.List is in module java.base of loader 'bootstrap')
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankThrowsTooManyResourcesException()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, true);
      Stack<List<TaggedWord>> stack0 = new Stack<List<TaggedWord>>();
      DiskTreebank diskTreebank0 = new DiskTreebank();
      // Undeclared exception!
      LexicalizedParser.getParserFromTreebank(diskTreebank0, diskTreebank0, 100, exactGrammarCompactor0, shiftReduceOptions0, diskTreebank0, stack0);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileThrowsTooManyResourcesException()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(1363);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.distance = true;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      BobChrisTreeNormalizer.EmptyFilter bobChrisTreeNormalizer_EmptyFilter0 = new BobChrisTreeNormalizer.EmptyFilter();
      Filters.RandomFilter<Object> filters_RandomFilter0 = new Filters.RandomFilter<Object>(0.0);
      bobChrisTreeNormalizer_EmptyFilter0.or(filters_RandomFilter0);
      Predicate.isEqual(null);
      FilteringTreebank filteringTreebank0 = new FilteringTreebank(memoryTreebank0, bobChrisTreeNormalizer_EmptyFilter0);
      LexicalizedParser.trainFromTreebank((Treebank) filteringTreebank0, (Options) shiftReduceOptions0);
      BinaryGrammar binaryGrammar0 = new BinaryGrammar(lexicalizedParser0.tagIndex);
      lexicalizedParser0.bg = binaryGrammar0;
      MemoryTreebank memoryTreebank1 = new MemoryTreebank((TreeNormalizer) null);
      Options.LexOptions options_LexOptions0 = shiftReduceOptions0.lexOptions;
      shiftReduceOptions0.lexOptions = options_LexOptions0;
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, memoryTreebank1, shiftReduceOptions0);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, true, true);
      LexicalizedParser.getParserFromSerializedFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser.loadModel();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      List<CoreLabel> list0 = null;
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, true);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      // Undeclared exception!
      LexicalizedParser.getParserFromTreebank(filteringTreebank0, filteringTreebank0, 1, exactGrammarCompactor0, shiftReduceOptions0, filteringTreebank0, vector0);
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain6()  throws Throwable  {
      String[] stringArray0 = new String[6];
      stringArray0[0] = "-tagseparator";
      stringArray0[1] = "-tlpp";
      stringArray0[2] = "-savetraintrees";
      stringArray0[3] = "-tlpp";
      stringArray0[5] = "-savetraintrees";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsArrayIndexOutOfBoundsException3()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-savetraintrees";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetLexiconAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      Options options0 = new Options();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, options0);
      ArrayList<Word> arrayList0 = new ArrayList<Word>();
      Lexicon lexicon0 = lexicalizedParser0.getLexicon();
      assertEquals(0, lexicon0.numRules());
  }

  @Test(timeout = 4000)
  public void testGetLexiconAndGetLexicon()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("xJrnFf`", false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("\u00EE", (FileFilter) extensionFileFilter0, options0);
      lexicalizedParser0.saveParserToSerialized("xJrnFf`");
      boolean boolean0 = lexicalizedParser0.requiresTags();
      assertFalse(boolean0);
      
      lexicalizedParser0.getLexicon();
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndRequiresTags()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(1363);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.distance = true;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      BobChrisTreeNormalizer.EmptyFilter bobChrisTreeNormalizer_EmptyFilter0 = new BobChrisTreeNormalizer.EmptyFilter();
      Filters.RandomFilter<Object> filters_RandomFilter0 = new Filters.RandomFilter<Object>(0.0);
      bobChrisTreeNormalizer_EmptyFilter0.or(filters_RandomFilter0);
      Predicate.isEqual(null);
      FilteringTreebank filteringTreebank0 = new FilteringTreebank(memoryTreebank0, bobChrisTreeNormalizer_EmptyFilter0);
      LexicalizedParser.trainFromTreebank((Treebank) filteringTreebank0, (Options) shiftReduceOptions0);
      BinaryGrammar binaryGrammar0 = new BinaryGrammar(lexicalizedParser0.tagIndex);
      lexicalizedParser0.bg = binaryGrammar0;
      MemoryTreebank memoryTreebank1 = new MemoryTreebank((TreeNormalizer) null);
      Options.LexOptions options_LexOptions0 = shiftReduceOptions0.lexOptions;
      shiftReduceOptions0.lexOptions = options_LexOptions0;
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, memoryTreebank1, shiftReduceOptions0);
      lexicalizedParser0.requiresTags();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "-train2";
      stringArray0[1] = null;
      stringArray0[2] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[3] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[4] = "edu.stanford.nlp.parser.lexparser.EnglishUnknownWordModelTrainer";
      stringArray0[5] = null;
      stringArray0[6] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[7] = "/u/scr/nlp/deeplearning/datasets/turian/embeddings-scaled.EMBEDDING_SIZE=25.txt";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentException4()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-train2";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -train2
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsRuntimeExceptionAndMain1()  throws Throwable  {
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-tokenizerFactory";
      stringArray0[2] = "-tlpp";
      stringArray0[3] = "Taking ";
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      stringArray0[4] = "-tlpp";
      stringArray0[5] = "-tlpp";
      stringArray0[6] = "-tlpp";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.lang.ClassNotFoundException: Class 'Taking .class' should be in target project, but could not be found!
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException8()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-tlpp";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
      }
  }

  @Test(timeout = 4000)
  public void testGetExtraEvals()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      List<Eval> list0 = lexicalizedParser0.getExtraEvals();
      assertEquals(0, list0.size());
  }

  @Test(timeout = 4000)
  public void testGetExtraEvalsAndGetExtraEvals()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(1363);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.distance = true;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      BobChrisTreeNormalizer.EmptyFilter bobChrisTreeNormalizer_EmptyFilter0 = new BobChrisTreeNormalizer.EmptyFilter();
      Filters.RandomFilter<Object> filters_RandomFilter0 = new Filters.RandomFilter<Object>(0.0);
      bobChrisTreeNormalizer_EmptyFilter0.or(filters_RandomFilter0);
      Predicate.isEqual(null);
      FilteringTreebank filteringTreebank0 = new FilteringTreebank(memoryTreebank0, bobChrisTreeNormalizer_EmptyFilter0);
      LexicalizedParser.trainFromTreebank((Treebank) filteringTreebank0, (Options) shiftReduceOptions0);
      BinaryGrammar binaryGrammar0 = new BinaryGrammar(lexicalizedParser0.tagIndex);
      lexicalizedParser0.bg = binaryGrammar0;
      MemoryTreebank memoryTreebank1 = new MemoryTreebank((TreeNormalizer) null);
      Options.LexOptions options_LexOptions0 = shiftReduceOptions0.lexOptions;
      shiftReduceOptions0.lexOptions = options_LexOptions0;
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, memoryTreebank1, shiftReduceOptions0);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, true, true);
      lexicalizedParser0.getTLPParams();
      LexicalizedParser.getParserFromSerializedFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser.getParserFromTextFile("depig", shiftReduceOptions0);
      LexicalizedParser.getParserFromTextFile("/u/scr/nlp/deeplearning/datasets/turian/embeddings-scaled.EMBEDDING_SIZE=25.txt", shiftReduceOptions0);
      LexicalizedParser.loadModel();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      lexicalizedParser0.getExtraEvals();
      String string0 = "!`3oR`XE=*iX 8p%cz)";
      NumberRangesFileFilter numberRangesFileFilter0 = null;
      try {
        numberRangesFileFilter0 = new NumberRangesFileFilter("depig", true);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Constructor argument not valid list of number ranges: depig
         //
         verifyException("edu.stanford.nlp.io.NumberRangesFileFilter", e);
      }
  }

  @Test(timeout = 4000)
  public void testSetOptionFlagsThrowsIllegalArgumentException()  throws Throwable  {
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, (String) null);
      RegExFileFilter regExFileFilter0 = new RegExFileFilter("Missing path: -saveToSerialized filename");
      Options options0 = new Options();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, memoryTreebank0, options0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      String[] stringArray0 = new String[4];
      stringArray0[0] = "Missing path: -saveToSerialized filename";
      stringArray0[1] = "Missing path: -saveToSerialized filename";
      stringArray0[2] = null;
      stringArray0[3] = null;
      // Undeclared exception!
      try { 
        lexicalizedParser0.setOptionFlags(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Unknown option: Missing path: -saveToSerialized filename
         //
         verifyException("edu.stanford.nlp.parser.lexparser.Options", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileThrowsNullPointerException()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("xJrnFf`", false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("\u00EE", (FileFilter) extensionFileFilter0, options0);
      lexicalizedParser0.saveParserToSerialized("xJrnFf`");
      lexicalizedParser0.requiresTags();
      PennTreebankLanguagePack pennTreebankLanguagePack0 = new PennTreebankLanguagePack();
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams(pennTreebankLanguagePack0);
      DiskTreebank diskTreebank0 = hebrewTreebankParserParams0.diskTreebank();
      BobChrisTreeNormalizer bobChrisTreeNormalizer0 = new BobChrisTreeNormalizer();
      TransformingTreebank transformingTreebank0 = new TransformingTreebank(diskTreebank0, bobChrisTreeNormalizer0);
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(transformingTreebank0, transformingTreebank0, diskTreebank0, options0);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      lexicalizedParser0.getTLPParams();
      LexicalizedParser.getParserFromSerializedFile("xJrnFf`");
      // Undeclared exception!
      try { 
        LexicalizedParser.getParserFromTextFile((String) null, options0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Attempt to open file with null name
         //
         verifyException("edu.stanford.nlp.io.IOUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsRuntimeException3()  throws Throwable  {
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      Options options0 = spanishUnknownWordModelTrainer0.op;
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("cZUHYzqZ5@U1HcShw#'");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "useYetMoreCpCShapes");
      String[] stringArray0 = new String[1];
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("cZUHYzqZ5@U1HcShw#'");
      byte[] byteArray0 = new byte[2];
      byteArray0[0] = (byte) (-57);
      byteArray0[1] = (byte)32;
      FileSystemHandling.appendDataToFile(evoSuiteFile1, byteArray0);
      stringArray0[0] = "cZUHYzqZ5@U1HcShw#'";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // cZUHYzqZ5@U1HcShw#': expecting BEGIN block; got useYetMoreCpCShapes\uFFFD 
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ThrowsIllegalArgumentException()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("xJrnFf`", false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("\u00EE", (FileFilter) extensionFileFilter0, options0);
      lexicalizedParser0.saveParserToSerialized("xJrnFf`");
      lexicalizedParser0.requiresTags();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "xJrnFf`";
      stringArray0[1] = "xJrnFf`";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("xJrnFf`", stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Unknown option: xJrnFf`
         //
         verifyException("edu.stanford.nlp.parser.lexparser.Options", e);
      }
  }

  @Test(timeout = 4000)
  public void testSetOptionFlagsAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      MemoryTreebank memoryTreebank0 = englishTreebankParserParams0.testMemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      HashIndex<String> hashIndex0 = new HashIndex<String>();
      String[] stringArray0 = new String[0];
      lexicalizedParser0.setOptionFlags(stringArray0);
      assertEquals(0, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentExceptionAndMain2()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      TreeLemmatizer treeLemmatizer0 = new TreeLemmatizer();
      PennTreebankLanguagePack pennTreebankLanguagePack0 = new PennTreebankLanguagePack();
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams(pennTreebankLanguagePack0);
      Options options0 = new Options(hebrewTreebankParserParams0);
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-treebank";
      stringArray0[1] = "-treebank";
      stringArray0[2] = "Lexicon is ";
      stringArray0[3] = "m2<<";
      stringArray0[4] = "";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -test
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentException5()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-treebank";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -test
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetTLPParams()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      DiskTreebank diskTreebank0 = new DiskTreebank();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (Options) shiftReduceOptions0);
      TreebankLangParserParams treebankLangParserParams0 = lexicalizedParser0.getTLPParams();
      assertEquals("UTF-8", treebankLangParserParams0.getInputEncoding());
  }

  @Test(timeout = 4000)
  public void testGetTLPParamsAndParseThrowsNullPointerException()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(1363);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.distance = true;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      BobChrisTreeNormalizer.EmptyFilter bobChrisTreeNormalizer_EmptyFilter0 = new BobChrisTreeNormalizer.EmptyFilter();
      Filters.RandomFilter<Object> filters_RandomFilter0 = new Filters.RandomFilter<Object>(0.0);
      bobChrisTreeNormalizer_EmptyFilter0.or(filters_RandomFilter0);
      Predicate.isEqual(null);
      FilteringTreebank filteringTreebank0 = new FilteringTreebank(memoryTreebank0, bobChrisTreeNormalizer_EmptyFilter0);
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.trainFromTreebank((Treebank) filteringTreebank0, (Options) shiftReduceOptions0);
      BinaryGrammar binaryGrammar0 = new BinaryGrammar(lexicalizedParser0.tagIndex);
      lexicalizedParser0.bg = binaryGrammar0;
      MemoryTreebank memoryTreebank1 = new MemoryTreebank((TreeNormalizer) null);
      Options.LexOptions options_LexOptions0 = shiftReduceOptions0.lexOptions;
      shiftReduceOptions0.lexOptions = options_LexOptions0;
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, memoryTreebank1, shiftReduceOptions0);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, true, true);
      lexicalizedParser0.getTLPParams();
      LexicalizedParser.getParserFromSerializedFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser.getParserFromTextFile("depig", shiftReduceOptions0);
      LexicalizedParser.getParserFromTextFile("/u/scr/nlp/deeplearning/datasets/turian/embeddings-scaled.EMBEDDING_SIZE=25.txt", shiftReduceOptions0);
      LexicalizedParser.loadModel();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      // Undeclared exception!
      try { 
        lexicalizedParser1.parse((List<? extends HasWord>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.common.ParserUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException9()  throws Throwable  {
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-Mwn?Py{dpYR";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetOpThrowsRuntimeException()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      TreeReaderFactory treeReaderFactory0 = englishTreebankParserParams0.treeReaderFactory();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(treeReaderFactory0, "\u00EE");
      Options options0 = new Options();
      FileSystemHandling.shouldAllThrowIOExceptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("xJrnFf`", false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("\u00EE", (FileFilter) extensionFileFilter0, options0);
      // Undeclared exception!
      try { 
        lexicalizedParser0.saveParserToSerialized("xJrnFf`");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.io.IOException: Simulated IOException
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingObjectInputStreamThrowsNullPointerException()  throws Throwable  {
      ObjectInputStream objectInputStream0 = null;
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel((ObjectInputStream) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1AndTrainFromTreebankTaking11And1WithNonNull()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      DiskTreebank diskTreebank0 = new DiskTreebank(100);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (GrammarCompactor) exactGrammarCompactor0, (Options) shiftReduceOptions0);
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testGetParserQueryEvalsAndGetExtraEvals()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(100);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      lexicalizedParser0.getExtraEvals();
      List<ParserQueryEval> list0 = lexicalizedParser0.getParserQueryEvals();
      assertEquals(0, list0.size());
  }

  @Test(timeout = 4000)
  public void testGetParserQueryEvalsAndGetParserQueryEvals()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.forceCNF = false;
      LexicalizedParser.buildTrainTransformer((Options) shiftReduceOptions0);
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(pennTreeReaderFactory0, "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      MemoryTreebank memoryTreebank1 = new MemoryTreebank();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      lexicalizedParser0.getOp();
      List<ParserQueryEval> list0 = lexicalizedParser0.getParserQueryEvals();
      assertTrue(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testLexicalizedParserQueryThrowsNullPointerException()  throws Throwable  {
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      Options options0 = new Options();
      LexicalizedParser.buildTrainTransformer(options0);
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(pennTreeReaderFactory0, "w{5){t=OSMS^u4");
      MemoryTreebank memoryTreebank1 = new MemoryTreebank();
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank1, memoryTreebank0, memoryTreebank1, options0);
      LexicalizedParser.getParserFromTextFile("w{5){t=OSMS^u4", options0);
      // Undeclared exception!
      try { 
        LexicalizedParser.copyLexicalizedParser((LexicalizedParser) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException10()  throws Throwable  {
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-loadfromtextfile";
      stringArray0[1] = "-loadfromtextfile";
      stringArray0[2] = "Qte8stTre(ban7";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetTreePrintThrowsNoClassDefFoundError()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      NumberRangeFileFilter numberRangeFileFilter0 = new NumberRangeFileFilter(100, 100, true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) numberRangeFileFilter0, (Options) shiftReduceOptions0);
      // Undeclared exception!
      try { 
        lexicalizedParser0.getTreePrint();
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException11()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-loadfromtextfile";
      stringArray0[1] = "-loadfromtextfile";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNoClassDefFoundErrorAndRequiresTags()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      TreeReaderFactory treeReaderFactory0 = englishTreebankParserParams0.treeReaderFactory();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(treeReaderFactory0, "\u00EE");
      Options options0 = new Options();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("xJrnFf`", false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("\u00EE", (FileFilter) extensionFileFilter0, options0);
      lexicalizedParser0.saveParserToSerialized("xJrnFf`");
      lexicalizedParser0.requiresTags();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "xJrnFf`";
      stringArray0[1] = "xJrnFf`";
      stringArray0[2] = "\u00EE";
      stringArray0[3] = "xJrnFf`";
      stringArray0[4] = "\u00EE";
      stringArray0[5] = "\u00EE";
      stringArray0[6] = "xJrnFf`";
      stringArray0[7] = "xJrnFf`";
      stringArray0[8] = "xJrnFf`";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNoClassDefFoundErrorAndMain()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("\u00EE", false);
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "-traintreebank");
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-traintreebank";
      stringArray0[1] = "Couldn't instantiate escaper ";
      stringArray0[2] = "-sentences";
      stringArray0[3] = "-sentences";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking3Arguments()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      DiskTreebank diskTreebank0 = new DiskTreebank();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      String[] stringArray0 = new String[0];
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.loadModel("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (Options) shiftReduceOptions0, stringArray0);
      assertFalse(lexicalizedParser1.requiresTags());
  }

  @Test(timeout = 4000)
  public void testGetParserFromSerializedFile()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      assertFalse(lexicalizedParser0.requiresTags());
      
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromSerializedFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      assertFalse(lexicalizedParser1.requiresTags());
  }

  @Test(timeout = 4000)
  public void testParseStringsThrowsUnsupportedOperationException()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      DiskTreebank diskTreebank0 = englishTreebankParserParams0.diskTreebank();
      TreeLemmatizer treeLemmatizer0 = new TreeLemmatizer();
      TransformingTreebank transformingTreebank0 = new TransformingTreebank(diskTreebank0, treeLemmatizer0);
      PennTreebankLanguagePack pennTreebankLanguagePack0 = new PennTreebankLanguagePack();
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams(pennTreebankLanguagePack0);
      Options options0 = new Options(hebrewTreebankParserParams0);
      String[] stringArray0 = new String[0];
      LexicalizedParser.main(stringArray0);
      LexicalizedParser.loadModel(options0, stringArray0);
      NERClassifierCombiner.Language nERClassifierCombiner_Language0 = NERClassifierCombiner.Language.CHINESE;
      Properties properties0 = options0.testOptions.evals;
      NERClassifierCombiner nERClassifierCombiner0 = new NERClassifierCombiner(false, nERClassifierCombiner_Language0, true, properties0, stringArray0);
      // Undeclared exception!
      try { 
        nERClassifierCombiner0.segmentString("Chinese");
        fail("Expecting exception: UnsupportedOperationException");
      
      } catch(UnsupportedOperationException e) {
         //
         // Argument array lengths differ: [class edu.stanford.nlp.ling.CoreAnnotations$TextAnnotation, class edu.stanford.nlp.ling.CoreAnnotations$PartOfSpeechAnnotation, class edu.stanford.nlp.ling.CoreAnnotations$AnswerAnnotation] vs. [Chinese]
         //
         verifyException("edu.stanford.nlp.ling.CoreLabel", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileThrowsRuntimeException()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      // Undeclared exception!
      try { 
        LexicalizedParser.getParserFromTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", shiftReduceOptions0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory: expecting BEGIN block; got \uFFFD\uFFFD\u0000\u0005sr\u00003edu.stanford.nlp.parser.lexparser.LexicalizedParser\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0002\u0002\u0000\tL\u0000\u0002bgt\u00001Ledu/stanford/nlp/parser/lexparser/BinaryGrammar;L\u0000\u0002dgt\u00005Ledu/stanford/nlp/parser/lexparser/DependencyGrammar;L\u0000\u0003lext\u0000+Ledu/stanford/nlp/parser/lexparser/Lexicon;L\u0000\u0002opt\u0000+Ledu/stanford/nlp/parser/lexparser/Options;L\u0000\brerankert\u0000,Ledu/stanford/nlp/parser/lexparser/Reranker;L\u0000
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsRuntimeException4()  throws Throwable  {
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      Options options0 = spanishUnknownWordModelTrainer0.op;
      String[] stringArray0 = new String[1];
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("cZUHYzqZ5@U1HcShw#'");
      byte[] byteArray0 = new byte[2];
      byteArray0[0] = (byte) (-57);
      byteArray0[1] = (byte)32;
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      stringArray0[0] = "cZUHYzqZ5@U1HcShw#'";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // cZUHYzqZ5@U1HcShw#': expecting BEGIN block; got \uFFFD 
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking3ArgumentsReturningNull()  throws Throwable  {
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      Options options0 = spanishUnknownWordModelTrainer0.op;
      String[] stringArray0 = new String[0];
      LexicalizedParser.loadModel("", (Options) null, stringArray0);
      // Undeclared exception!
      try { 
        ParserGrammar.loadModelFromZip("-de3", "");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.io.FileNotFoundException: Could not find  inside -de3
         //
         verifyException("edu.stanford.nlp.parser.common.ParserGrammar", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      List<Eval> list0 = new LinkedList<Eval>();
      ShiftReduceOptions shiftReduceOptions1 = new ShiftReduceOptions();
      Triple<Treebank, Treebank, Treebank> triple0 = LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, (Treebank) null, shiftReduceOptions1);
      assertNotNull(triple0);
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankAndBuildTrainTransformerTakingOptions()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.forceCNF = false;
      LexicalizedParser.buildTrainTransformer((Options) shiftReduceOptions0);
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(pennTreeReaderFactory0, "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      MemoryTreebank memoryTreebank1 = new MemoryTreebank();
      Triple<Treebank, Treebank, Treebank> triple0 = LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, memoryTreebank1, shiftReduceOptions0);
      assertNotNull(triple0);
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebank1()  throws Throwable  {
      Options options0 = new Options();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      Triple<Treebank, Treebank, Treebank> triple0 = LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, memoryTreebank0, options0);
      assertNotNull(triple0);
  }

  @Test(timeout = 4000)
  public void testParserQuery()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      ParserQuery parserQuery0 = lexicalizedParser0.parserQuery();
      assertEquals(Double.NEGATIVE_INFINITY, parserQuery0.getBestScore(), 0.01);
  }

  @Test(timeout = 4000)
  public void testRequiresTagsAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      DiskTreebank diskTreebank0 = new DiskTreebank();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (Options) shiftReduceOptions0);
      boolean boolean0 = lexicalizedParser0.requiresTags();
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void testGetOpAndRequiresTagsAndSaveParserToSerialized()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      TreeReaderFactory treeReaderFactory0 = englishTreebankParserParams0.treeReaderFactory();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(treeReaderFactory0, "\u00EE");
      Options options0 = new Options();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("xJrnFf`", false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("\u00EE", (FileFilter) extensionFileFilter0, options0);
      lexicalizedParser0.saveParserToSerialized("xJrnFf`");
      boolean boolean0 = lexicalizedParser0.requiresTags();
      assertFalse(boolean0);
      
      lexicalizedParser0.getOp();
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithEmptyArray()  throws Throwable  {
      String[] stringArray0 = new String[0];
      LexicalizedParser.main(stringArray0);
      assertEquals(0, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testBuildTrainBinarizerReturningNonNull()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      englishTreebankParserParams0.treeReaderFactory();
      Options options0 = new Options();
      TreeAnnotatorAndBinarizer treeAnnotatorAndBinarizer0 = LexicalizedParser.buildTrainBinarizer(options0);
      assertNotNull(treeAnnotatorAndBinarizer0);
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And10()  throws Throwable  {
      String[] stringArray0 = new String[7];
      stringArray0[0] = "0T0l3";
      stringArray0[1] = "D}r%ex^;VT}";
      stringArray0[2] = "";
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("cZUHYzqZ5@U1HcShw#'", (FileFilter) null, options0);
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And11()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("T0", (FileFilter) null, (Options) shiftReduceOptions0);
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1ThrowsNullPointerException()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      String[] stringArray0 = new String[6];
      stringArray0[0] = "";
      UnaryOperator<String> unaryOperator0 = UnaryOperator.identity();
      options0.wordFunction = (Function<String, String>) unaryOperator0;
      stringArray0[1] = "";
      stringArray0[2] = "";
      stringArray0[3] = "";
      stringArray0[4] = "";
      stringArray0[5] = "";
      hebrewTreebankParserParams0.evalGF = false;
      LexicalizedParser.getParserFromTextFile("", (Options) null);
      Pattern pattern0 = Pattern.compile("", 100);
      RegExFileFilter regExFileFilter0 = new RegExFileFilter(pattern0);
      // Undeclared exception!
      try { 
        LexicalizedParser.trainFromTreebank("", (FileFilter) regExFileFilter0, (Options) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromFileAndGetParserFromFile()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      String[] stringArray0 = new String[0];
      String string0 = "Cou(o";
      LexicalizedParser.getParserFromFile("Cou(o", shiftReduceOptions0);
      SpanishTreebankParserParams spanishTreebankParserParams0 = null;
      try {
        spanishTreebankParserParams0 = new SpanishTreebankParserParams();
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.tregex.TregexParser
         //
         verifyException("edu.stanford.nlp.trees.tregex.TregexPatternCompiler", e);
      }
  }

  @Test(timeout = 4000)
  public void testBuildTrainBinarizerThrowsNullPointerException()  throws Throwable  {
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      Options options0 = spanishUnknownWordModelTrainer0.op;
      // Undeclared exception!
      try { 
        LexicalizedParser.buildTrainBinarizer((Options) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1AndTrainFromTreebankTaking11And1()  throws Throwable  {
      RegExFileFilter regExFileFilter0 = new RegExFileFilter("Missing path: -saveToSerialized filename");
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("Missing path: -saveToSerialized filename", (FileFilter) regExFileFilter0, options0);
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1AndLoadModelTaking1And1ThrowsNullPointerException0()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "[}";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("[}", stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking3ArgumentsThrowsNullPointerException()  throws Throwable  {
      LexicalizedParser.getParserFromSerializedFile("SBARQ");
      Options options0 = new Options();
      String[] stringArray0 = new String[9];
      stringArray0[0] = ",.h2ERD[A_`nF";
      stringArray0[1] = "SBARQ";
      stringArray0[2] = "SBARQ";
      stringArray0[3] = "SBARQ";
      stringArray0[4] = "BFelsd*d+,>*<96";
      stringArray0[5] = "SBARQ";
      stringArray0[6] = "SBARQ";
      stringArray0[7] = "SBARQ";
      stringArray0[8] = "SBARQ";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("SBARQ", options0, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain7()  throws Throwable  {
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-PPFrien&dly";
      stringArray0[1] = "-PPFrien&dly";
      stringArray0[2] = "-";
      stringArray0[3] = "-PPFrien&dly";
      stringArray0[4] = "-PPFrien&dly";
      stringArray0[5] = "quotes";
      stringArray0[6] = "-PPFrien&dly";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain8()  throws Throwable  {
      TreeLemmatizer treeLemmatizer0 = new TreeLemmatizer();
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, true);
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-loadfromtextfile";
      stringArray0[1] = "-maxentDepGramar";
      stringArray0[2] = "}";
      stringArray0[3] = "-maxentDepGramar";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMain2()  throws Throwable  {
      TreeLemmatizer treeLemmatizer0 = new TreeLemmatizer();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("cZUHYzqZ5@U1HcShw#'");
      byte[] byteArray0 = new byte[1];
      byteArray0[0] = (byte)32;
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-tlpp";
      LexicalizedParser.main(stringArray0);
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentExceptionAndMain3()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options();
      Options options1 = new Options();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-train";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -train
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException12()  throws Throwable  {
      String[] stringArray0 = new String[7];
      stringArray0[0] = "0T0l3";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainAndMainWithEmptyArray()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      ChineseTreebankParserParams chineseTreebankParserParams0 = new ChineseTreebankParserParams();
      Options options0 = new Options(chineseTreebankParserParams0);
      String[] stringArray0 = new String[0];
      LexicalizedParser.main(stringArray0);
      assertEquals(0, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentExceptionAndMain4()  throws Throwable  {
      Options options0 = new Options();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("xJrnFf`", true);
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-tune";
      stringArray0[1] = "-model";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -tune
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain9()  throws Throwable  {
      String[] stringArray0 = new String[7];
      stringArray0[0] = "0T0l3";
      stringArray0[1] = "D}r%ex^;VT}";
      stringArray0[2] = "";
      stringArray0[3] = "cZUHYzqZ5@U1HcShw#'";
      stringArray0[4] = "THwA\"PY`cly";
      stringArray0[5] = "?-Vu!=WK!y.@92";
      stringArray0[6] = "";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException13()  throws Throwable  {
      String[] stringArray0 = new String[1];
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testCopyLexicalizedParser()  throws Throwable  {
      Properties properties0 = new Properties();
      SeqClassifierFlags seqClassifierFlags0 = new SeqClassifierFlags(properties0);
      List<String> list0 = seqClassifierFlags0.gazettes;
      LexicalizedParser.loadModel("", list0);
      // Undeclared exception!
      try { 
        LexicalizedParser.copyLexicalizedParser((LexicalizedParser) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testCopyLexicalizedParserThrowsNullPointerException()  throws Throwable  {
      LexicalizedParser.loadModel();
      // Undeclared exception!
      try { 
        LexicalizedParser.copyLexicalizedParser((LexicalizedParser) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingNoArgumentsAndLoadModelTakingNoArguments()  throws Throwable  {
      LexicalizedParser.loadModel();
      TestOptions testOptions0 = new TestOptions();
      Properties properties0 = testOptions0.evals;
      NERClassifierCombiner nERClassifierCombiner0 = null;
      try {
        nERClassifierCombiner0 = new NERClassifierCombiner(properties0);
        fail("Expecting exception: IOException");
      
      } catch(Throwable e) {
         //
         // Couldn't load classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz
         //
         verifyException("edu.stanford.nlp.ie.ClassifierCombiner", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1ReturningLexicalizedParserWhereRequiresTagsIsFalse()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      LexicalizedParser.loadModel();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank("k&$K&Ol!4fn6");
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (GrammarCompactor) exactGrammarCompactor0, (Options) shiftReduceOptions0);
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking2ArgumentsAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      NPTmpRetainingTreeNormalizer.NPTmpAdvRetainingTreeReaderFactory nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0 = new NPTmpRetainingTreeNormalizer.NPTmpAdvRetainingTreeReaderFactory();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0, "Rw");
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      NERClassifierCombiner.Language nERClassifierCombiner_Language0 = NERClassifierCombiner.Language.CHINESE;
      Properties properties0 = shiftReduceOptions0.testOptions.evals;
      String[] stringArray0 = new String[5];
      stringArray0[0] = "Chinese";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[3] = "Chinese";
      stringArray0[4] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      NERClassifierCombiner nERClassifierCombiner0 = null;
      try {
        nERClassifierCombiner0 = new NERClassifierCombiner(true, nERClassifierCombiner_Language0, false, properties0, stringArray0);
        fail("Expecting exception: IOException");
      
      } catch(Throwable e) {
         //
         // Couldn't load classifier from Chinese
         //
         verifyException("edu.stanford.nlp.ie.ClassifierCombiner", e);
      }
  }

  @Test(timeout = 4000)
  public void testBuildTrainBinarizer()  throws Throwable  {
      Options options0 = new Options();
      TreeAnnotatorAndBinarizer treeAnnotatorAndBinarizer0 = LexicalizedParser.buildTrainBinarizer(options0);
      assertNotNull(treeAnnotatorAndBinarizer0);
  }

  @Test(timeout = 4000)
  public void testGetParserFromSerializedFileThrowsNullPointerException()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.forceCNF = false;
      LexicalizedParser.buildTrainTransformer((Options) shiftReduceOptions0);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      Options options0 = spanishUnknownWordModelTrainer0.op;
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor((Options) null, true, true);
      // Undeclared exception!
      try { 
        LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (GrammarCompactor) exactGrammarCompactor0, (Options) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testBuildTrainTransformerTakingOptions()  throws Throwable  {
      Options options0 = new Options();
      CompositeTreeTransformer compositeTreeTransformer0 = LexicalizedParser.buildTrainTransformer(options0);
      assertNotNull(compositeTreeTransformer0);
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1AndLoadModelTaking1And1WithNonEmptyStringAndLoadModelTaking1And1WithEmptyList()  throws Throwable  {
      ArrayList<String> arrayList0 = new ArrayList<String>();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.loadModel("A;+R?1gwb)9O7GTI=8", (List<String>) arrayList0);
      assertNull(lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ThrowsNullPointerExceptionAndLoadModelTaking1And1()  throws Throwable  {
      String string0 = "[u$~N:m!i/v`";
      ArabicMorphoFeatureSpecification arabicMorphoFeatureSpecification0 = new ArabicMorphoFeatureSpecification();
      MorphoFeatureSpecification.MorphoFeatureType morphoFeatureSpecification_MorphoFeatureType0 = MorphoFeatureSpecification.MorphoFeatureType.POSS;
      List<String> list0 = arabicMorphoFeatureSpecification0.getValues(morphoFeatureSpecification_MorphoFeatureType0);
      List<String> list1 = OutsideRuleFilter.reverse(list0);
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("[u$~N:m!i/v`", list1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1AndLoadModelTaking1And1WithNonEmptyStringAndLoadModelTaking1And1WithEmptyArray()  throws Throwable  {
      String[] stringArray0 = new String[0];
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.loadModel("-sentences", stringArray0);
      assertNull(lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ThrowsNullPointerExceptionAndLoadModelTaking1And1WithNonEmptyString()  throws Throwable  {
      String[] stringArray0 = new String[1];
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("-sentences", stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1AndLoadModelTaking1And1ThrowsNullPointerException1()  throws Throwable  {
      Options options0 = new Options();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "I+s";
      stringArray0[1] = ".;V^";
      stringArray0[2] = "O!5 ";
      stringArray0[3] = "Compiling grammar...";
      stringArray0[4] = "@";
      stringArray0[5] = "";
      stringArray0[6] = "{8kjE\"s,Oy";
      stringArray0[7] = "BmAX$hmRs],c&?J`W^";
      stringArray0[8] = "sTL>=zeg9$ih@+#By_";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel(options0, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankWithNull()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      TreeReaderFactory treeReaderFactory0 = englishTreebankParserParams0.treeReaderFactory();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(treeReaderFactory0, "\u00EE");
      // Undeclared exception!
      try { 
        LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, memoryTreebank0, (Options) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }
}
