/**
 * Scaffolding file used to store all the setups needed to run 
 * tests automatically generated by EvoSuite
 * Mon Apr 21 18:09:06 GMT 2025
 */

package edu.stanford.nlp.parser.lexparser;

import org.evosuite.runtime.annotation.EvoSuiteClassExclude;
import org.junit.BeforeClass;
import org.junit.Before;
import org.junit.After;

@EvoSuiteClassExclude
public class ChineseTreebankParserParams_4_ESTest_scaffolding {

  @org.junit.Rule
  public org.evosuite.runtime.vnet.NonFunctionalRequirementRule nfr = new org.evosuite.runtime.vnet.NonFunctionalRequirementRule();

  private org.evosuite.runtime.thread.ThreadStopper threadStopper =  new org.evosuite.runtime.thread.ThreadStopper (org.evosuite.runtime.thread.KillSwitchHandler.getInstance(), 3000);


  @BeforeClass
  public static void initEvoSuiteFramework() { 
    org.evosuite.runtime.RuntimeSettings.className = "edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams"; 
    org.evosuite.runtime.GuiSupport.initialize(); 
    org.evosuite.runtime.RuntimeSettings.maxNumberOfThreads = 100; 
    org.evosuite.runtime.RuntimeSettings.maxNumberOfIterationsPerLoop = 10000; 
    org.evosuite.runtime.RuntimeSettings.mockSystemIn = true; 
    org.evosuite.runtime.Runtime.getInstance().resetRuntime(); 
  } 

  @Before
  public void initTestCase(){ 
    threadStopper.storeCurrentThreads();
    threadStopper.startRecordingTime();
    org.evosuite.runtime.jvm.ShutdownHookHandler.getInstance().initHandler(); 
    org.evosuite.runtime.GuiSupport.setHeadless(); 
    org.evosuite.runtime.Runtime.getInstance().resetRuntime(); 
    org.evosuite.runtime.agent.InstrumentingAgent.activate(); 
  } 

  @After
  public void doneWithTestCase(){ 
    threadStopper.killAndJoinClientThreads();
    org.evosuite.runtime.jvm.ShutdownHookHandler.getInstance().safeExecuteAddedHooks(); 
    org.evosuite.runtime.agent.InstrumentingAgent.deactivate(); 
    org.evosuite.runtime.GuiSupport.restoreHeadlessMode(); 
  } 

  public static void setSystemProperties() {
 
    /*No java.lang.System property to set*/
  }

  private static void initializeClasses() {
    org.evosuite.runtime.classhandling.ClassStateSupport.initializeClasses(ChineseTreebankParserParams_4_ESTest_scaffolding.class.getClassLoader() ,
      "edu.stanford.nlp.util.logging.Redwood$ConsoleHandler",
      "edu.stanford.nlp.ling.SentenceUtils",
      "edu.stanford.nlp.trees.BobChrisTreeNormalizer",
      "edu.stanford.nlp.international.morph.MorphoFeatureSpecification$MorphoFeatureType",
      "edu.stanford.nlp.international.arabic.process.ArabicTokenizer$ArabicTokenizerFactory",
      "edu.stanford.nlp.ling.CoreAnnotations$TextAnnotation",
      "edu.stanford.nlp.util.MapFactory",
      "edu.stanford.nlp.util.logging.VisibilityHandler",
      "edu.stanford.nlp.parser.lexparser.Options",
      "edu.stanford.nlp.util.IntPair",
      "edu.stanford.nlp.parser.lexparser.TrainOptions",
      "edu.stanford.nlp.trees.ModCollinsHeadFinder",
      "edu.stanford.nlp.trees.HeadFinder",
      "edu.stanford.nlp.ling.AbstractCoreLabel",
      "edu.stanford.nlp.trees.tregex.TregexParserConstants",
      "edu.stanford.nlp.stats.ClassicCounter",
      "edu.stanford.nlp.ling.CategoryWordTagFactory",
      "edu.stanford.nlp.util.ArrayCoreMap",
      "edu.stanford.nlp.ling.IndexedWord$1",
      "edu.stanford.nlp.trees.EnglishPatterns",
      "edu.stanford.nlp.util.logging.RepeatedRecordHandler$ExactRepeatSemantics",
      "edu.stanford.nlp.trees.tregex.TokenMgrError",
      "edu.stanford.nlp.util.ReflectionLoading",
      "edu.stanford.nlp.util.ArrayCoreMap$1$1",
      "edu.stanford.nlp.ling.BasicDocument",
      "edu.stanford.nlp.trees.CompositeTreeTransformer",
      "edu.stanford.nlp.util.logging.VisibilityHandler$State",
      "edu.stanford.nlp.trees.CopulaHeadFinder",
      "edu.stanford.nlp.util.Filters",
      "edu.stanford.nlp.util.StringUtils",
      "edu.stanford.nlp.stats.Sampler",
      "edu.stanford.nlp.io.EncodingPrintWriter",
      "edu.stanford.nlp.util.MetaClass$ClassFactory",
      "edu.stanford.nlp.util.logging.Redwood$Flag",
      "edu.stanford.nlp.util.logging.OutputHandler",
      "edu.stanford.nlp.trees.international.pennchinese.ChineseGrammaticalRelations",
      "edu.stanford.nlp.trees.international.negra.NegraPennTreeNormalizer",
      "edu.stanford.nlp.ling.WordFactory",
      "edu.stanford.nlp.trees.international.pennchinese.UniversalChineseGrammaticalRelations",
      "edu.stanford.nlp.util.logging.Redwood$RedwoodChannels",
      "edu.stanford.nlp.trees.TreeGraphNode",
      "edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams$EnglishTrain",
      "edu.stanford.nlp.parser.lexparser.Lexicon",
      "edu.stanford.nlp.util.Filters$CollectionAcceptFilter",
      "edu.stanford.nlp.trees.Tree",
      "edu.stanford.nlp.ling.HasLemma",
      "edu.stanford.nlp.parser.lexparser.AbstractTreebankParserParams$SubcategoryStripper",
      "edu.stanford.nlp.trees.international.arabic.ArabicHeadFinder$TagSet",
      "edu.stanford.nlp.international.morph.MorphoFeatureSpecification",
      "edu.stanford.nlp.util.HashIndex$2",
      "edu.stanford.nlp.util.HashIndex$1",
      "edu.stanford.nlp.util.logging.RedirectOutputHandler",
      "edu.stanford.nlp.util.logging.RepeatedRecordHandler",
      "edu.stanford.nlp.util.HashIndex",
      "edu.stanford.nlp.trees.TreeReaderFactory",
      "edu.stanford.nlp.trees.international.arabic.ArabicHeadFinder",
      "edu.stanford.nlp.util.MapFactory$ConcurrentMapFactory",
      "edu.stanford.nlp.ling.Label",
      "edu.stanford.nlp.ling.IndexedWord",
      "edu.stanford.nlp.international.arabic.ArabicMorphoFeatureSpecification$ArabicMorphoFeatures",
      "edu.stanford.nlp.ling.CoreLabel",
      "edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer",
      "edu.stanford.nlp.international.arabic.process.ArabicTokenizer",
      "edu.stanford.nlp.util.Filters$DisjFilter",
      "edu.stanford.nlp.ling.CoreAnnotations$DocIDAnnotation",
      "edu.stanford.nlp.ling.TaggedWord",
      "edu.stanford.nlp.util.logging.VisibilityHandler$1",
      "edu.stanford.nlp.parser.lexparser.AbstractTreebankParserParams",
      "edu.stanford.nlp.trees.TreeLeafLabelTransformer",
      "edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams$1",
      "edu.stanford.nlp.parser.lexparser.BaseLexicon",
      "edu.stanford.nlp.util.TypesafeMap$Key",
      "edu.stanford.nlp.util.IdentityHashSet",
      "edu.stanford.nlp.util.logging.RepeatedRecordHandler$PendingType",
      "edu.stanford.nlp.parser.lexparser.DependencyGrammar",
      "edu.stanford.nlp.sentiment.CollapseUnaryTransformer",
      "edu.stanford.nlp.util.logging.SLF4JHandler$1",
      "edu.stanford.nlp.parser.lexparser.ChineseMarkovWordSegmenter",
      "edu.stanford.nlp.trees.Treebank",
      "edu.stanford.nlp.ling.HasOffset",
      "edu.stanford.nlp.ling.WordTag",
      "edu.stanford.nlp.util.logging.BooleanLogRecordHandler",
      "edu.stanford.nlp.trees.tregex.TregexParser",
      "edu.stanford.nlp.parser.lexparser.AbstractUnknownWordModelTrainer",
      "edu.stanford.nlp.ling.StringLabel",
      "edu.stanford.nlp.trees.international.pennchinese.UniversalChineseSemanticHeadFinder",
      "edu.stanford.nlp.trees.MemoryTreebank",
      "edu.stanford.nlp.trees.PennTreebankLanguagePack",
      "edu.stanford.nlp.util.logging.RedwoodConfiguration$Handlers$5",
      "edu.stanford.nlp.util.logging.RedwoodConfiguration$Handlers$6",
      "edu.stanford.nlp.trees.PennTreeReaderFactory",
      "edu.stanford.nlp.util.logging.RedwoodConfiguration$Handlers$7",
      "edu.stanford.nlp.process.WordSegmenter",
      "edu.stanford.nlp.util.CoreMap",
      "edu.stanford.nlp.trees.TreebankFactory",
      "edu.stanford.nlp.util.logging.RedwoodConfiguration$Handlers$2",
      "edu.stanford.nlp.util.logging.RedwoodConfiguration$Handlers$3",
      "edu.stanford.nlp.util.logging.RedwoodConfiguration$Handlers$4",
      "edu.stanford.nlp.util.MapFactory$TreeMapFactory",
      "edu.stanford.nlp.parser.lexparser.AbstractTreebankParserParams$RemoveGFSubcategoryStripper",
      "edu.stanford.nlp.util.logging.Redwood$Util",
      "edu.stanford.nlp.parser.lexparser.HebrewTreebankParserParams",
      "edu.stanford.nlp.trees.international.pennchinese.ChineseTreebankLanguagePack",
      "edu.stanford.nlp.ling.TaggedWordFactory",
      "edu.stanford.nlp.process.Tokenizer",
      "edu.stanford.nlp.trees.international.hebrew.HebrewTreeReaderFactory",
      "edu.stanford.nlp.trees.international.pennchinese.UniversalChineseGrammaticalStructure",
      "edu.stanford.nlp.trees.GrammaticalStructure$1",
      "edu.stanford.nlp.util.logging.JavaUtilLoggingHandler",
      "edu.stanford.nlp.util.Factory",
      "edu.stanford.nlp.parser.lexparser.Options$LexOptions",
      "edu.stanford.nlp.parser.lexparser.ChineseLexicon",
      "edu.stanford.nlp.process.SerializableFunction",
      "edu.stanford.nlp.trees.EnglishGrammaticalStructure",
      "edu.stanford.nlp.trees.AbstractCollinsHeadFinder",
      "edu.stanford.nlp.util.IntTuple",
      "edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure",
      "edu.stanford.nlp.trees.tregex.TregexParser$LookaheadSuccess",
      "edu.stanford.nlp.util.logging.RedwoodConfiguration",
      "edu.stanford.nlp.trees.international.hebrew.HebrewTreeNormalizer",
      "edu.stanford.nlp.util.logging.Redwood$MessageType",
      "edu.stanford.nlp.ling.CoreAnnotations$CategoryAnnotation",
      "edu.stanford.nlp.parser.lexparser.Extractor",
      "edu.stanford.nlp.trees.TreeReader",
      "edu.stanford.nlp.process.PTBTokenizer",
      "edu.stanford.nlp.ling.ValueLabel",
      "edu.stanford.nlp.trees.tregex.ParseException",
      "edu.stanford.nlp.trees.AbstractTreebankLanguagePack",
      "edu.stanford.nlp.trees.UnnamedDependency",
      "edu.stanford.nlp.util.Filters$NegatedFilter",
      "edu.stanford.nlp.ling.CoreLabel$1",
      "edu.stanford.nlp.stats.Counter",
      "edu.stanford.nlp.ling.StringLabelFactory",
      "edu.stanford.nlp.io.RuntimeIOException",
      "edu.stanford.nlp.trees.LabeledScoredTreeNode",
      "edu.stanford.nlp.trees.ConstituentFactory",
      "edu.stanford.nlp.util.logging.Redwood$1",
      "edu.stanford.nlp.parser.lexparser.UnknownWordModelTrainer",
      "edu.stanford.nlp.trees.TransformingTreebank",
      "edu.stanford.nlp.trees.tregex.DescriptionPattern",
      "edu.stanford.nlp.ling.HasCategory",
      "edu.stanford.nlp.parser.metrics.Eval",
      "edu.stanford.nlp.parser.lexparser.AbstractTreeExtractor",
      "edu.stanford.nlp.util.MapFactory$ArrayMapFactory",
      "edu.stanford.nlp.util.logging.SLF4JHandler",
      "edu.stanford.nlp.ling.WordLemmaTag",
      "edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams$ItalianSubcategoryStripper",
      "edu.stanford.nlp.util.logging.Redwood$Record",
      "edu.stanford.nlp.international.arabic.ArabicMorphoFeatureSpecification",
      "edu.stanford.nlp.util.logging.Color",
      "edu.stanford.nlp.process.WordSegmentingTokenizer$WordSegmentingTokenizerFactory",
      "edu.stanford.nlp.parser.lexparser.ChineseSimWordAvgDepGrammar",
      "edu.stanford.nlp.trees.RecursiveTreeTransformer",
      "edu.stanford.nlp.objectbank.IteratorFromReaderFactory",
      "edu.stanford.nlp.trees.SimpleTreeFactory",
      "edu.stanford.nlp.parser.lexparser.MLEDependencyGrammarExtractor",
      "edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams",
      "edu.stanford.nlp.trees.LabeledScoredTreeFactory",
      "edu.stanford.nlp.util.MetaClass$ConstructorNotFoundException",
      "edu.stanford.nlp.io.EncodingPrintWriter$err",
      "edu.stanford.nlp.ling.CoreAnnotations$PartOfSpeechAnnotation",
      "edu.stanford.nlp.process.LexedTokenFactory",
      "edu.stanford.nlp.parser.lexparser.AbstractCollinizer",
      "edu.stanford.nlp.ling.CoreAnnotations$EmptyIndexAnnotation",
      "edu.stanford.nlp.parser.lexparser.TreebankLangParserParams",
      "edu.stanford.nlp.util.logging.Style",
      "edu.stanford.nlp.ling.CoreAnnotation",
      "edu.stanford.nlp.trees.GrammaticalStructure",
      "edu.stanford.nlp.trees.international.arabic.ArabicHeadFinder$TagSet$2",
      "edu.stanford.nlp.trees.international.arabic.ArabicHeadFinder$TagSet$1",
      "edu.stanford.nlp.process.CoreTokenFactory",
      "edu.stanford.nlp.trees.TreeTransformer",
      "edu.stanford.nlp.parser.lexparser.AbstractTreebankParserParams$AnnotatePunctuationFunction",
      "edu.stanford.nlp.trees.TreeNormalizer",
      "edu.stanford.nlp.trees.international.negra.NegraPennTreeReaderFactory",
      "edu.stanford.nlp.trees.GrammaticalStructureFromDependenciesFactory",
      "edu.stanford.nlp.util.logging.RepeatedRecordHandler$RepeatSemantics",
      "edu.stanford.nlp.trees.international.negra.NegraPennLanguagePack",
      "edu.stanford.nlp.trees.tregex.TregexParseException",
      "edu.stanford.nlp.trees.international.hebrew.HebrewTreebankLanguagePack",
      "edu.stanford.nlp.trees.Labeled",
      "edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexicon",
      "edu.stanford.nlp.ling.Word",
      "edu.stanford.nlp.ling.LabelFactory",
      "edu.stanford.nlp.util.logging.Redwood$RecordHandlerTree",
      "edu.stanford.nlp.parser.lexparser.ChineseLexiconAndWordSegmenter",
      "edu.stanford.nlp.util.DeltaIndex",
      "edu.stanford.nlp.trees.BasicCategoryTreeTransformer",
      "edu.stanford.nlp.util.Scored",
      "edu.stanford.nlp.trees.international.pennchinese.CTBErrorCorrectingTreeNormalizer",
      "edu.stanford.nlp.util.logging.RerouteChannel",
      "edu.stanford.nlp.parser.lexparser.UnknownWordModel",
      "edu.stanford.nlp.parser.lexparser.ArabicTreebankParserParams",
      "edu.stanford.nlp.util.ErasureUtils",
      "edu.stanford.nlp.parser.metrics.AbstractEval",
      "edu.stanford.nlp.util.logging.RepeatedRecordHandler$ApproximateRepeatSemantics",
      "edu.stanford.nlp.trees.international.pennchinese.BikelChineseHeadFinder",
      "edu.stanford.nlp.trees.CollinsHeadFinder",
      "edu.stanford.nlp.parser.lexparser.SisterAnnotationStats",
      "edu.stanford.nlp.trees.UniversalSemanticHeadFinder",
      "edu.stanford.nlp.util.MapFactory$LinkedHashMapFactory",
      "edu.stanford.nlp.ling.WordTag$LabelFactoryHolder",
      "edu.stanford.nlp.util.logging.RedwoodConfiguration$Thunk",
      "edu.stanford.nlp.util.logging.RedwoodConfiguration$2",
      "edu.stanford.nlp.trees.Dependency",
      "edu.stanford.nlp.util.logging.RedwoodConfiguration$3",
      "edu.stanford.nlp.util.Filters$RandomFilter",
      "edu.stanford.nlp.ling.Featurizable",
      "edu.stanford.nlp.util.Pair",
      "edu.stanford.nlp.ling.LabeledWord",
      "edu.stanford.nlp.process.TokenizerFactory",
      "edu.stanford.nlp.util.MutableInteger",
      "edu.stanford.nlp.util.MapFactory$WeakHashMapFactory",
      "edu.stanford.nlp.trees.TreebankLanguagePack",
      "edu.stanford.nlp.ling.Document",
      "edu.stanford.nlp.stats.ProbabilityDistribution",
      "edu.stanford.nlp.trees.international.pennchinese.ChineseHeadFinder",
      "edu.stanford.nlp.util.logging.FilterHandler",
      "edu.stanford.nlp.trees.TreeFactory",
      "edu.stanford.nlp.ling.HasIndex",
      "edu.stanford.nlp.ling.Labeled",
      "edu.stanford.nlp.process.PTBTokenizer$PTBTokenizerFactory",
      "edu.stanford.nlp.util.MapFactory$IdentityHashMapFactory",
      "edu.stanford.nlp.trees.international.arabic.ArabicTreebankLanguagePack",
      "edu.stanford.nlp.ling.HasNER",
      "edu.stanford.nlp.util.logging.RedwoodConfiguration$Handlers",
      "edu.stanford.nlp.ling.HasOriginalText",
      "edu.stanford.nlp.ling.CategoryWordTag",
      "edu.stanford.nlp.util.TypesafeMap",
      "edu.stanford.nlp.ling.Tag",
      "edu.stanford.nlp.util.MetaClass$ClassCreationException",
      "edu.stanford.nlp.trees.DiskTreebank",
      "edu.stanford.nlp.international.Language",
      "edu.stanford.nlp.parser.lexparser.TrainOptions$TransformMatrixType",
      "edu.stanford.nlp.process.CoreLabelTokenFactory",
      "edu.stanford.nlp.ling.HasTag",
      "edu.stanford.nlp.trees.UnnamedConcreteDependency",
      "edu.stanford.nlp.ling.CoreAnnotations$IndexAnnotation",
      "edu.stanford.nlp.util.logging.RedwoodConfiguration$Handlers$2$1",
      "edu.stanford.nlp.util.ReflectionLoading$ReflectionLoadingException",
      "edu.stanford.nlp.trees.AbstractTreebankLanguagePack$BasicCategoryStringFunction",
      "edu.stanford.nlp.parser.lexparser.TestOptions",
      "edu.stanford.nlp.util.logging.Redwood",
      "edu.stanford.nlp.parser.lexparser.IntTaggedWord",
      "edu.stanford.nlp.trees.tregex.TregexPattern",
      "edu.stanford.nlp.ling.CoreAnnotations$CharacterOffsetBeginAnnotation",
      "edu.stanford.nlp.util.logging.RepeatedRecordHandler$RepeatedRecordInfo",
      "edu.stanford.nlp.ling.Datum",
      "edu.stanford.nlp.ling.WordLemmaTagFactory",
      "edu.stanford.nlp.trees.tregex.TregexPatternCompiler",
      "edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams",
      "edu.stanford.nlp.trees.international.pennchinese.ChineseGrammaticalStructure",
      "edu.stanford.nlp.trees.international.negra.NegraHeadFinder",
      "edu.stanford.nlp.process.WordSegmentingTokenizer",
      "edu.stanford.nlp.util.logging.PrettyLoggable",
      "edu.stanford.nlp.ling.WordTagFactory",
      "edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams$EnglishTest",
      "edu.stanford.nlp.trees.HasParent",
      "edu.stanford.nlp.trees.international.pennchinese.ChineseCollinizer",
      "edu.stanford.nlp.trees.international.pennchinese.SunJurafskyChineseHeadFinder",
      "edu.stanford.nlp.trees.LeftHeadFinder",
      "edu.stanford.nlp.ling.CoreLabel$OutputFormat",
      "edu.stanford.nlp.process.AbstractTokenizer",
      "edu.stanford.nlp.international.morph.MorphoFeatures",
      "edu.stanford.nlp.util.MetaClass",
      "edu.stanford.nlp.parser.lexparser.SpanishUnknownWordModelTrainer",
      "edu.stanford.nlp.parser.lexparser.AbstractDependencyGrammar",
      "edu.stanford.nlp.util.MapFactory$HashMapFactory",
      "edu.stanford.nlp.trees.GrammaticalStructureFactory",
      "edu.stanford.nlp.trees.TreeVisitor",
      "edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams",
      "edu.stanford.nlp.ling.CoreAnnotations$SentenceIndexAnnotation",
      "edu.stanford.nlp.trees.international.italian.ItalianTreebankLanguagePack",
      "edu.stanford.nlp.ling.CoreLabel$CoreLabelFactory",
      "edu.stanford.nlp.ling.AbstractToken",
      "edu.stanford.nlp.ling.CoreAnnotations$CharacterOffsetEndAnnotation",
      "edu.stanford.nlp.trees.TreeGraphNodeFactory",
      "edu.stanford.nlp.util.Filters$ConjFilter",
      "edu.stanford.nlp.ling.CoreAnnotations$ValueAnnotation",
      "edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams",
      "edu.stanford.nlp.stats.Distribution",
      "edu.stanford.nlp.util.logging.Redwood$FileHandler",
      "edu.stanford.nlp.util.logging.RedwoodPrintStream",
      "edu.stanford.nlp.trees.SimpleTree",
      "edu.stanford.nlp.trees.GrammaticalRelation",
      "edu.stanford.nlp.ling.HasWord",
      "edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar",
      "edu.stanford.nlp.trees.international.pennchinese.ChineseSemanticHeadFinder",
      "edu.stanford.nlp.util.RuntimeInterruptedException",
      "edu.stanford.nlp.util.ArrayCoreMap$1",
      "edu.stanford.nlp.ling.HasContext",
      "edu.stanford.nlp.util.logging.LogRecordHandler",
      "edu.stanford.nlp.util.Pair$MutableInternedPair",
      "edu.stanford.nlp.util.FileProcessor",
      "edu.stanford.nlp.util.Index",
      "edu.stanford.nlp.util.Generics",
      "edu.stanford.nlp.trees.tregex.CoordinationPattern"
    );
  } 
}
