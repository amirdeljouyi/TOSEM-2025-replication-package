/*
 * This file was automatically generated by UTestGen and EvoSuite
 * Mon Apr 21 13:39:37 GMT 2025
 */

package edu.stanford.nlp.pipeline;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import edu.stanford.nlp.ling.CoreAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.pipeline.Annotation;
import edu.stanford.nlp.pipeline.TokenizerAnnotator;
import edu.stanford.nlp.process.CoreLabelTokenFactory;
import edu.stanford.nlp.process.Tokenizer;
import edu.stanford.nlp.sequences.TrueCasingForNISTDocumentReaderAndWriter;
import edu.stanford.nlp.util.ArrayCoreMap;
import edu.stanford.nlp.util.CoreMap;
import java.io.BufferedReader;
import java.io.OutputStream;
import java.io.Reader;
import java.io.StringReader;
import java.io.UnsupportedEncodingException;
import java.net.MalformedURLException;
import java.nio.CharBuffer;
import java.nio.ReadOnlyBufferException;
import java.util.ArrayList;
import java.util.LinkedList;
import java.util.List;
import java.util.Properties;
import java.util.Set;
import java.util.Stack;
import java.util.Vector;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.System;
import org.evosuite.runtime.mock.java.net.MockURL;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, separateClassLoader = true) 
public class TokenizerAnnotator_1_ESTest extends TokenizerAnnotator_1_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void test()  throws Throwable  {
      Properties properties0 = new Properties();
      String string0 = "tokenize.language";
      CoreLabelTokenFactory coreLabelTokenFactory0 = new CoreLabelTokenFactory();
      int int0 = 784;
      CoreLabel coreLabel0 = coreLabelTokenFactory0.makeToken("tokenize.language", "tokenize.language", (-4879), 784);
      coreLabel0.keySetNotNull();
      properties0.put("tokenize.language", coreLabel0);
      properties0.setProperty("tokenize.language", "<");
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property <
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3ArgumentsAndAdjustFinalToken()  throws Throwable  {
      CoreLabelTokenFactory coreLabelTokenFactory0 = new CoreLabelTokenFactory();
      CoreLabel coreLabel0 = coreLabelTokenFactory0.makeToken("Reading initial LOP scales from file ", "Reading initial LOP scales from file ", (-1155459824), (-1155459824));
      coreLabel0.setAfter("Reading initial LOP scales from file ");
      coreLabel0.setIsMWT(false);
      CoreLabel coreLabel1 = coreLabelTokenFactory0.makeToken("", (-1155459824), (-1534));
      List<CoreLabel> list0 = List.of(coreLabel0, coreLabel0, coreLabel1, coreLabel1, coreLabel1, coreLabel0);
      TokenizerAnnotator.adjustFinalToken(list0);
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0, "");
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3Arguments0()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0, ",");
  }

  @Test(timeout = 4000)
  public void testGetTokenizerType()  throws Throwable  {
      StringReader stringReader0 = new StringReader("/A_WL7");
      stringReader0.close();
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Unspecified;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      tokenizerAnnotator0.requirementsSatisfied();
      Properties properties0 = new Properties();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      System.setCurrentTimeMillis(0L);
      System.setCurrentTimeMillis(0L);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString0()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("Unspecified");
  }

  @Test(timeout = 4000)
  public void testRequires()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator1 = new TokenizerAnnotator(false, properties0, "language");
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.German;
      TokenizerAnnotator tokenizerAnnotator2 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
      tokenizerAnnotator1.requires();
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requires();
      assertTrue(set0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testRequiresThrowsRuntimeException()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Arabic;
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ArabicSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsRuntimeException0()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("Arabic");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ArabicSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testRequirementsSatisfiedThrowsRuntimeException()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Chinese;
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsRuntimeException1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("Chinese");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndRequires()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.French;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType1 = TokenizerAnnotator.TokenizerType.Spanish;
      TokenizerAnnotator tokenizerAnnotator1 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType1);
      tokenizerAnnotator0.requires();
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator1.requires();
      assertTrue(set0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("es");
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingBooleanAndRequirementsSatisfied()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Annotation annotation0 = new Annotation("[C]");
      ArrayCoreMap.listener = null;
      tokenizerAnnotator0.annotate(annotation0);
      StringReader stringReader0 = new StringReader("[C]");
      stringReader0.mark(798);
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator1 = new TokenizerAnnotator(true, properties0, "[C]");
      ArrayList<CoreMap> arrayList0 = new ArrayList<CoreMap>();
      OutputStream.nullOutputStream();
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.French;
      tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      TokenizerAnnotator tokenizerAnnotator2 = new TokenizerAnnotator(false);
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator2.requirementsSatisfied();
      Set<Class<? extends CoreAnnotation>> set1 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator2.requirementsSatisfied();
      assertTrue(set1.equals((Object)set0));
  }

  @Test(timeout = 4000)
  public void testRequirementsSatisfiedAndCreatesTokenizerAnnotatorTaking3Arguments()  throws Throwable  {
      TokenizerAnnotator.TokenizerType.values();
      TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0 = new TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser();
      trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0.apply("");
      List<CoreLabel> list0 = trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0.apply("esjk?r");
      TokenizerAnnotator.adjustFinalToken(list0);
      StringReader stringReader0 = new StringReader("");
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.French;
      tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      tokenizerAnnotator0.requirementsSatisfied();
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator1 = new TokenizerAnnotator(false, properties0, "");
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator1.requirementsSatisfied();
      assertFalse(set0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString2()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("French");
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsNullPointerExceptionAndAnnotateWithAnnotationWhereSizeIsPositive()  throws Throwable  {
      Annotation annotation0 = new Annotation((String) null);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator((String) null);
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate(annotation0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.WordsToSentencesAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAdjustFinalTokenWithNull()  throws Throwable  {
      TokenizerAnnotator.adjustFinalToken((List<CoreLabel>) null);
  }

  @Test(timeout = 4000)
  public void testGetTokenizerReturningNonNull()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Annotation annotation0 = new Annotation("[C]");
      ArrayCoreMap.listener = null;
      tokenizerAnnotator0.annotate(annotation0);
      StringReader stringReader0 = new StringReader("[C]");
      stringReader0.mark(798);
      stringReader0.close();
      Tokenizer<CoreLabel> tokenizer0 = tokenizerAnnotator0.getTokenizer(stringReader0);
      StringReader stringReader1 = new StringReader("=\tLf@F3]L");
      char[] charArray0 = new char[6];
      charArray0[0] = '/';
      charArray0[1] = '?';
      charArray0[2] = '`';
      charArray0[3] = '>';
      charArray0[4] = '@';
      charArray0[5] = '#';
      stringReader1.read(charArray0);
      Tokenizer<CoreLabel> tokenizer1 = tokenizerAnnotator0.getTokenizer(stringReader1);
      assertNotSame(tokenizer1, tokenizer0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingStringAndFailsToCreateTokenizerAnnotatorTakingStringThrowsIllegalArgumentException()  throws Throwable  {
      String string0 = "g|A}Ue!VAr";
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("g|A}Ue!VAr");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property g|A}Ue!VAr
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString3()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator((String) null);
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndGetTokenizerType()  throws Throwable  {
      TokenizerAnnotator.TokenizerType.values();
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0);
      TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0 = new TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser();
      trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0.apply("");
      List<CoreLabel> list0 = trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0.apply("esjk?r");
      TokenizerAnnotator.adjustFinalToken(list0);
      tokenizerAnnotator0.requirementsSatisfied();
      tokenizerAnnotator0.requirementsSatisfied();
      tokenizerAnnotator0.requires();
      tokenizerAnnotator0.requires();
      StringReader stringReader0 = new StringReader("");
      tokenizerAnnotator0.getTokenizer(stringReader0);
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.valueOf("80BQ,t<*Zi<1}");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // No enum constant edu.stanford.nlp.pipeline.TokenizerAnnotator.TokenizerType.80BQ,t<*Zi<1}
         //
         verifyException("java.lang.Enum", e);
      }
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsIllegalArgumentException()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.keySet();
      String string0 = "adjustFinalToken: Unexpected final char: |";
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0, "adjustFinalToken: Unexpected final char: |");
      Annotation annotation0 = new Annotation("No valid tokenizer type provided.\nUse -tokenize.language, -tokenize.class, or -tokenize.whitespace \nto specify a tokenizer.");
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate(annotation0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // PTBLexer: Invalid options key in constructor: adjustFinalToken: Unexpected final char: |
         //
         verifyException("edu.stanford.nlp.process.PTBLexer", e);
      }
  }

  @Test(timeout = 4000)
  public void testAnnotateAndGetTokenizer()  throws Throwable  {
      TokenizerAnnotator.TokenizerType.values();
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0);
      TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0 = new TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser();
      trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0.apply("");
      List<CoreLabel> list0 = trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0.apply("esjk?r");
      TokenizerAnnotator.adjustFinalToken(list0);
      tokenizerAnnotator0.requirementsSatisfied();
      tokenizerAnnotator0.requirementsSatisfied();
      tokenizerAnnotator0.requires();
      tokenizerAnnotator0.requires();
      StringReader stringReader0 = new StringReader("");
      Tokenizer<CoreLabel> tokenizer0 = tokenizerAnnotator0.getTokenizer(stringReader0);
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      Annotation annotation0 = new Annotation("");
      tokenizerAnnotator0.annotate(annotation0);
      BufferedReader bufferedReader0 = new BufferedReader(stringReader0, 349);
      bufferedReader0.read();
      Tokenizer<CoreLabel> tokenizer1 = tokenizerAnnotator0.getTokenizer(bufferedReader0);
      assertNotSame(tokenizer1, tokenizer0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArgumentsAndAnnotate0()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Annotation annotation0 = new Annotation("?quub]-A+HI");
      tokenizerAnnotator0.annotate(annotation0);
      assertEquals(3, annotation0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArgumentsAndAnnotate1()  throws Throwable  {
      ArrayList<CoreMap> arrayList0 = new ArrayList<CoreMap>();
      Annotation annotation0 = new Annotation(arrayList0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      tokenizerAnnotator0.annotate(annotation0);
      assertEquals(3, annotation0.size());
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsNullPointerExceptionAndCreatesTokenizerAnnotatorTakingNoArguments()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate((Annotation) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAnnotateAndCreatesTokenizerAnnotatorTakingProperties()  throws Throwable  {
      Properties properties0 = new Properties(1379);
      CoreAnnotations.StateAnnotation coreAnnotations_StateAnnotation0 = new CoreAnnotations.StateAnnotation();
      properties0.put(coreAnnotations_StateAnnotation0, coreAnnotations_StateAnnotation0);
      CoreAnnotations.OriginalTextAnnotation coreAnnotations_OriginalTextAnnotation0 = new CoreAnnotations.OriginalTextAnnotation();
      properties0.put(coreAnnotations_OriginalTextAnnotation0, coreAnnotations_OriginalTextAnnotation0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.requirementsSatisfied();
      Annotation annotation0 = new Annotation("RoW8TUc+o(|;V_uGd");
      annotation0.compact();
      annotation0.copy();
      tokenizerAnnotator0.annotate(annotation0);
      annotation0.toString();
      String string0 = ",T-d\"";
      StringReader stringReader0 = new StringReader(",T-d\"");
      tokenizerAnnotator0.annotate(annotation0);
      tokenizerAnnotator0.requires();
      CharBuffer charBuffer0 = CharBuffer.wrap((CharSequence) ",T-d\"");
      // Undeclared exception!
      try { 
        charBuffer0.put("\"M)z=|/*9{jn<");
        fail("Expecting exception: ReadOnlyBufferException");
      
      } catch(ReadOnlyBufferException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.nio.CharBuffer", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetTokenizerThrowsIllegalArgumentException()  throws Throwable  {
      Properties properties0 = new Properties();
      Properties properties1 = new Properties(properties0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties1, "tokenize.cleanxml");
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.getTokenizer((Reader) null);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // PTBLexer: Invalid options key in constructor: tokenize.cleanxml
         //
         verifyException("edu.stanford.nlp.process.PTBLexer", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArgumentsAndGetTokenizer()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Reader reader0 = Reader.nullReader();
      Tokenizer<CoreLabel> tokenizer0 = tokenizerAnnotator0.getTokenizer(reader0);
      assertNotNull(tokenizer0);
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking3ArgumentsThrowsIllegalArgumentException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(true, "", "");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property 
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testRequirementsSatisfiedAndCreatesTokenizerAnnotatorTakingProperties()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.French;
      tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      tokenizerAnnotator0.requirementsSatisfied();
      Reader reader0 = Reader.nullReader();
      BufferedReader bufferedReader0 = new BufferedReader(reader0, 2904);
      bufferedReader0.readLine();
      // Undeclared exception!
      try { 
        CharBuffer.wrap((char[]) null, 2904, (-3775));
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.nio.HeapCharBuffer", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArgumentsAndRequires()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requires();
      assertEquals(0, set0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndCallsRequires()  throws Throwable  {
      Properties properties0 = new Properties();
      Properties properties1 = new Properties(properties0);
      properties0.containsValue(properties1);
      properties1.toString();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties1);
      tokenizerAnnotator0.requires();
      tokenizerAnnotator0.requires();
      tokenizerAnnotator0.requirementsSatisfied();
      LinkedList<CoreLabel> linkedList0 = new LinkedList<CoreLabel>();
      TokenizerAnnotator.adjustFinalToken(linkedList0);
      TokenizerAnnotator.adjustFinalToken(linkedList0);
      CoreAnnotations.StateAnnotation coreAnnotations_StateAnnotation0 = new CoreAnnotations.StateAnnotation();
      properties0.put(coreAnnotations_StateAnnotation0, properties1);
      String string0 = "";
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.valueOf("");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // No enum constant edu.stanford.nlp.pipeline.TokenizerAnnotator.TokenizerType.
         //
         verifyException("java.lang.Enum", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsIllegalArgumentException()  throws Throwable  {
      String string0 = "";
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(true, "");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property 
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsIllegalArgumentException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(">{B)BWK7#aKx`,");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property >{B)BWK7#aKx`,
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndCreatesTokenizerAnnotatorTaking2Arguments()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0);
      properties0.elements();
      Annotation annotation0 = new Annotation("\u5143");
      Annotation annotation1 = new Annotation(annotation0);
      try { 
        MockURL.URL("\u5143");
        fail("Expecting exception: MalformedURLException");
      
      } catch(MalformedURLException e) {
         //
         // no protocol: \u5143
         //
         verifyException("java.net.URL", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3ArgumentsAndCreatesTokenizerAnnotatorTaking3Arguments()  throws Throwable  {
      Properties properties0 = new Properties(0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0, ":* 6uzN");
      ArrayList<CoreMap> arrayList0 = new ArrayList<CoreMap>();
      OutputStream outputStream0 = OutputStream.nullOutputStream();
      OutputStream.nullOutputStream();
      try { 
        properties0.storeToXML(outputStream0, ":* 6uzN", "");
        fail("Expecting exception: UnsupportedEncodingException");
      
      } catch(UnsupportedEncodingException e) {
         //
         // 
         //
         verifyException("java.util.Properties", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3Arguments1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, "German", "German");
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAdjustFinalTokenWithNonEmptyList()  throws Throwable  {
      CoreLabel coreLabel0 = new CoreLabel();
      List<CoreLabel> list0 = List.of(coreLabel0, coreLabel0, coreLabel0, coreLabel0, coreLabel0, coreLabel0);
      TokenizerAnnotator.adjustFinalToken(list0);
      assertFalse(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenThrowsNullPointerException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Stack<CoreLabel> stack0 = new Stack<CoreLabel>();
      tokenizerAnnotator0.requirementsSatisfied();
      tokenizerAnnotator0.requirementsSatisfied();
      stack0.add((CoreLabel) null);
      // Undeclared exception!
      try { 
        TokenizerAnnotator.adjustFinalToken(stack0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArgumentsAndRequirementsSatisfied()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requirementsSatisfied();
      assertFalse(set0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingBoolean()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true);
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndCreatesTokenizerAnnotatorTaking2Arguments()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Whitespace;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
      TokenizerAnnotator.adjustFinalToken((List<CoreLabel>) null);
      tokenizerAnnotator0.requires();
      tokenizerAnnotator0.requires();
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.valueOf("spam");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // No enum constant edu.stanford.nlp.pipeline.TokenizerAnnotator.TokenizerType.spam
         //
         verifyException("java.lang.Enum", e);
      }
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsNullPointerException()  throws Throwable  {
      String string0 = null;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator((String) null);
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate((Annotation) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenThrowsIllegalArgumentException()  throws Throwable  {
      CoreLabel coreLabel0 = new CoreLabel();
      String string0 = "FB";
      coreLabel0.setAfter("FB");
      List<CoreLabel> list0 = List.of(coreLabel0, coreLabel0, coreLabel0, coreLabel0, coreLabel0, coreLabel0);
      // Undeclared exception!
      try { 
        TokenizerAnnotator.adjustFinalToken(list0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // adjustFinalToken: Unexpected final char: |B| (66)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAnnotateAndCreatesTokenizerAnnotatorTaking3Arguments()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      CoreAnnotations.AnswerObjectAnnotation coreAnnotations_AnswerObjectAnnotation0 = new CoreAnnotations.AnswerObjectAnnotation();
      Class<Object> class0 = coreAnnotations_AnswerObjectAnnotation0.getType();
      properties0.put(class0, class0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0, ",");
      Annotation annotation0 = new Annotation(",");
      Annotation annotation1 = new Annotation(annotation0);
      tokenizerAnnotator0.annotate(annotation1);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString4()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("german");
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString5()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("Whitespace");
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenWithEmptyList()  throws Throwable  {
      Vector<CoreLabel> vector0 = new Vector<CoreLabel>();
      TokenizerAnnotator.adjustFinalToken(vector0);
      assertEquals(0, vector0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndCallsAdjustFinalToken()  throws Throwable  {
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      ArrayList<CoreLabel> arrayList1 = new ArrayList<CoreLabel>();
      arrayList1.removeAll(arrayList0);
      arrayList1.add((CoreLabel) null);
      CoreLabel coreLabel0 = new CoreLabel(0);
      coreLabel0.toShorterString((String[]) null);
      arrayList1.add(coreLabel0);
      arrayList0.retainAll(arrayList1);
      TokenizerAnnotator.adjustFinalToken(arrayList0);
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Whitespace;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
      TokenizerAnnotator.TokenizerType.values();
      Properties properties0 = new Properties();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.valueOf("$]#o/d;hjnERS\"");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // No enum constant edu.stanford.nlp.pipeline.TokenizerAnnotator.TokenizerType.$]#o/d;hjnERS\"
         //
         verifyException("java.lang.Enum", e);
      }
  }
}
