/*
 * This file was automatically generated by UTestGen and EvoSuite
 * Mon Apr 21 13:39:44 GMT 2025
 */

package edu.stanford.nlp.pipeline;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import edu.stanford.nlp.ie.PresetSequenceClassifier;
import edu.stanford.nlp.ling.CoreAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.ling.IndexedWord;
import edu.stanford.nlp.pipeline.Annotation;
import edu.stanford.nlp.pipeline.TokenizerAnnotator;
import edu.stanford.nlp.process.CoreLabelTokenFactory;
import edu.stanford.nlp.sequences.TrueCasingForNISTDocumentReaderAndWriter;
import edu.stanford.nlp.trees.ConstituentFactory;
import edu.stanford.nlp.trees.LabeledScoredConstituentFactory;
import edu.stanford.nlp.trees.Tree;
import edu.stanford.nlp.trees.TreeGraphNode;
import edu.stanford.nlp.util.CoreMap;
import java.io.BufferedReader;
import java.io.Reader;
import java.io.StringWriter;
import java.util.LinkedList;
import java.util.List;
import java.util.Properties;
import java.util.Set;
import java.util.Stack;
import java.util.Vector;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.System;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, separateClassLoader = true) 
public class TokenizerAnnotator_3_ESTest extends TokenizerAnnotator_3_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void testAdjustFinalToken0()  throws Throwable  {
      CoreLabelTokenFactory coreLabelTokenFactory0 = new CoreLabelTokenFactory();
      CoreLabel coreLabel0 = coreLabelTokenFactory0.makeToken((String) null, "=", 1635, 6);
      coreLabel0.setAfter("HeadFinder ");
      List<CoreLabel> list0 = List.of(coreLabel0, coreLabel0, coreLabel0);
      TokenizerAnnotator.adjustFinalToken(list0);
      assertEquals(3, list0.size());
  }

  @Test(timeout = 4000)
  public void test()  throws Throwable  {
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "tokenize.language");
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property tokenize.language
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3ArgumentsAndAdjustFinalToken()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, (Properties) null, "\u5143|\u5200|(?:\u7F8E|\u6B27|\u6FB3|\u52A0|\u65E5|\u97E9)\u5143|\u82F1?\u9551|\u6CD5\u90CE|\u5362\u6BD4|\u5362\u5E03|\u9A6C\u514B|\u5148\u4EE4|\u514B\u6717|\u6CF0?\u94E2|(?:\u8D8A\u5357)?\u76FE|\u7F8E\u5206|\u4FBF\u58EB|\u5757\u94B1|\u6BDB\u94B1|\u89D2\u94B1,");
      IndexedWord indexedWord0 = new IndexedWord("\u5143|\u5200|(?:\u7F8E|\u6B27|\u6FB3|\u52A0|\u65E5|\u97E9)\u5143|\u82F1?\u9551|\u6CD5\u90CE|\u5362\u6BD4|\u5362\u5E03|\u9A6C\u514B|\u5148\u4EE4|\u514B\u6717|\u6CF0?\u94E2|(?:\u8D8A\u5357)?\u76FE|\u7F8E\u5206|\u4FBF\u58EB|\u5757\u94B1|\u6BDB\u94B1|\u89D2\u94B1,", 3309, 7);
      TreeGraphNode treeGraphNode0 = new TreeGraphNode(indexedWord0);
      TreeGraphNode treeGraphNode1 = treeGraphNode0.highestNodeWithSameHead();
      List<Tree> list0 = treeGraphNode1.getChildrenAsList();
      LabeledScoredConstituentFactory labeledScoredConstituentFactory0 = new LabeledScoredConstituentFactory();
      treeGraphNode0.constituents((ConstituentFactory) labeledScoredConstituentFactory0);
      LinkedList<Tree> linkedList0 = new LinkedList<Tree>();
      TreeGraphNode treeGraphNode2 = new TreeGraphNode(treeGraphNode0, list0);
      List<CoreLabel> list1 = treeGraphNode1.taggedLabeledYield();
      TokenizerAnnotator.adjustFinalToken(list1);
      System.setCurrentTimeMillis(3309);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3Arguments0()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0, "MldmU;8@&]OV7,");
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndCreatesTokenizerAnnotatorTaking3Arguments()  throws Throwable  {
      TokenizerAnnotator.TokenizerType.values();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, (Properties) null, "2p;7IgY-UMH?s75>(;");
      IndexedWord indexedWord0 = new IndexedWord("2p;7IgY-UMH?s75>(;", 3309, 3);
      TreeGraphNode treeGraphNode0 = new TreeGraphNode(indexedWord0);
      TreeGraphNode treeGraphNode1 = treeGraphNode0.highestNodeWithSameHead();
      Tree tree0 = treeGraphNode1.deepCopy();
      List<Tree> list0 = treeGraphNode1.getChildrenAsList();
      LabeledScoredConstituentFactory labeledScoredConstituentFactory0 = new LabeledScoredConstituentFactory();
      tree0.constituents((ConstituentFactory) labeledScoredConstituentFactory0);
      LinkedList<Tree> linkedList0 = new LinkedList<Tree>();
      TreeGraphNode treeGraphNode2 = new TreeGraphNode(indexedWord0, list0);
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Spanish;
      TokenizerAnnotator tokenizerAnnotator1 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      assertFalse(tokenizerAnnotator1.equals((Object)tokenizerAnnotator0));
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString0()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("Spanish");
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2Arguments0()  throws Throwable  {
      Stack<CoreMap> stack0 = new Stack<CoreMap>();
      Annotation annotation0 = new Annotation(stack0);
      TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0 = new TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser();
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.German;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsRuntimeException()  throws Throwable  {
      TokenizerAnnotator.TokenizerType.values();
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Arabic;
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ArabicSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndGetTokenizerType()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.French;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
      Reader reader0 = Reader.nullReader();
      BufferedReader bufferedReader0 = new BufferedReader(reader0, 2364);
      StringWriter stringWriter0 = new StringWriter(2364);
      bufferedReader0.transferTo(stringWriter0);
      bufferedReader0.markSupported();
      Reader reader1 = Reader.nullReader();
      tokenizerAnnotator0.getTokenizer(bufferedReader0);
      tokenizerAnnotator0.getTokenizer(bufferedReader0);
      TokenizerAnnotator.TokenizerType.values();
      Annotation annotation0 = new Annotation("N\"\"Vr|v2");
      tokenizerAnnotator0.annotate(annotation0);
      Properties properties0 = new Properties();
      PresetSequenceClassifier<CoreLabel> presetSequenceClassifier0 = new PresetSequenceClassifier<CoreLabel>(properties0);
      LinkedList<CoreLabel> linkedList0 = new LinkedList<CoreLabel>();
      CoreLabel coreLabel0 = new CoreLabel(annotation0);
      linkedList0.add(coreLabel0);
      presetSequenceClassifier0.classifyWithGlobalInformation(linkedList0, annotation0, annotation0);
      TokenizerAnnotator.adjustFinalToken((List<CoreLabel>) null);
      tokenizerAnnotator0.getTokenizer(reader1);
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType1 = TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      assertEquals(TokenizerAnnotator.TokenizerType.English, tokenizerAnnotator_TokenizerType1);
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenWithNull()  throws Throwable  {
      TokenizerAnnotator.adjustFinalToken((List<CoreLabel>) null);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2Arguments1()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Unspecified;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("Unspecified");
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString2()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("French");
  }

  @Test(timeout = 4000)
  public void testGetTokenizerType()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.French;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
      Reader reader0 = Reader.nullReader();
      BufferedReader bufferedReader0 = new BufferedReader(reader0, 2364);
      StringWriter stringWriter0 = new StringWriter(2364);
      bufferedReader0.transferTo(stringWriter0);
      bufferedReader0.markSupported();
      Reader.nullReader();
      tokenizerAnnotator0.getTokenizer(bufferedReader0);
      tokenizerAnnotator0.getTokenizer(bufferedReader0);
      TokenizerAnnotator.TokenizerType.values();
      Annotation annotation0 = new Annotation("N\"\"Vr|v2");
      tokenizerAnnotator0.annotate(annotation0);
      Properties properties0 = new Properties();
      PresetSequenceClassifier<CoreLabel> presetSequenceClassifier0 = new PresetSequenceClassifier<CoreLabel>(properties0);
      LinkedList<CoreLabel> linkedList0 = new LinkedList<CoreLabel>();
      CoreLabel coreLabel0 = new CoreLabel(annotation0);
      linkedList0.add(coreLabel0);
      List<CoreLabel> list0 = presetSequenceClassifier0.classifyWithGlobalInformation(linkedList0, annotation0, annotation0);
      TokenizerAnnotator.adjustFinalToken(list0);
      tokenizerAnnotator0.getTokenizer(reader0);
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
  }

  @Test(timeout = 4000)
  public void testRequiresAndCreatesTokenizerAnnotatorTakingString()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator((String) null);
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requires();
      assertTrue(set0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArguments()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requires();
      assertTrue(set0.isEmpty());
      
      Properties properties0 = new Properties();
      Object object0 = new Object();
      CoreAnnotations.OriginalTextAnnotation coreAnnotations_OriginalTextAnnotation0 = new CoreAnnotations.OriginalTextAnnotation();
      properties0.put(object0, coreAnnotations_OriginalTextAnnotation0);
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.valueOf((String) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Name is null
         //
         verifyException("java.lang.Enum", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndAnnotateThrowsNullPointerException()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0);
      properties0.elements();
      tokenizerAnnotator0.requires();
      tokenizerAnnotator0.requirementsSatisfied();
      tokenizerAnnotator0.requirementsSatisfied();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      tokenizerAnnotator0.requires();
      properties0.isEmpty();
      String string0 = null;
      Annotation annotation0 = new Annotation((String) null);
      annotation0.toString();
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate(annotation0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.WordsToSentencesAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalToken1()  throws Throwable  {
      CoreLabel coreLabel0 = new CoreLabel();
      List<CoreLabel> list0 = List.of(coreLabel0, coreLabel0, coreLabel0);
      TokenizerAnnotator.adjustFinalToken(list0);
      assertFalse(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testRequiresAndAnnotate()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("hG@fHu;B)bgG#", "\u5143|\u5200|(?:\u7F8E|\u6B27|\u6FB3|\u52A0|\u65E5|\u97E9)\u5143|\u82F1?\u9551|\u6CD5\u90CE|\u5362\u6BD4|\u5362\u5E03|\u9A6C\u514B|\u5148\u4EE4|\u514B\u6717|\u6CF0?\u94E2|(?:\u8D8A\u5357)?\u76FE|\u7F8E\u5206|\u4FBF\u58EB|\u5757\u94B1|\u6BDB\u94B1|\u89D2\u94B1");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Reader reader0 = Reader.nullReader();
      tokenizerAnnotator0.getTokenizer(reader0);
      tokenizerAnnotator0.requires();
      tokenizerAnnotator0.requires();
      Annotation annotation0 = new Annotation("KHcv%Ac+ab} cfp");
      tokenizerAnnotator0.annotate(annotation0);
      assertEquals(3, annotation0.size());
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsRuntimeException0()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("zh");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsRuntimeException1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("ar");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ArabicSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking3ArgumentsThrowsRuntimeException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(true, "zh", "Unspecified");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString3()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("German");
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString4()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("whitespace");
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndCreatesTokenizerAnnotatorTaking2Arguments()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Whitespace;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingProperties()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingStringAndFailsToCreateTokenizerAnnotatorTakingStringThrowsIllegalArgumentException()  throws Throwable  {
      String string0 = "nameToTokenizerMap";
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("nameToTokenizerMap");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property nameToTokenizerMap
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsNullPointerException()  throws Throwable  {
      Annotation annotation0 = new Annotation((String) null);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator((String) null);
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate(annotation0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.WordsToSentencesAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAnnotateAndCreatesTokenizerAnnotatorTakingNoArguments()  throws Throwable  {
      Annotation annotation0 = new Annotation("ab");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      tokenizerAnnotator0.annotate(annotation0);
      assertEquals(3, annotation0.size());
  }

  @Test(timeout = 4000)
  public void testAnnotateWithNull()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate((Annotation) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingBooleanAndAnnotateThrowsNullPointerException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true);
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate((Annotation) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAnnotateAndCreatesTokenizerAnnotatorTakingBooleanAndAnnotate()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true);
      Stack<CoreMap> stack0 = new Stack<CoreMap>();
      Annotation annotation0 = new Annotation(stack0);
      stack0.clear();
      Annotation annotation1 = new Annotation(annotation0);
      tokenizerAnnotator0.annotate(annotation1);
      assertNotSame(annotation1, annotation0);
  }

  @Test(timeout = 4000)
  public void testGetTokenizer()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Reader reader0 = Reader.nullReader();
      tokenizerAnnotator0.getTokenizer(reader0);
  }

  @Test(timeout = 4000)
  public void testRequirementsSatisfiedAndGetTokenizerType()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true);
      tokenizerAnnotator0.requirementsSatisfied();
      Properties properties0 = new Properties();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      Object object0 = properties0.clone();
      CoreAnnotations.NumericCompositeObjectAnnotation coreAnnotations_NumericCompositeObjectAnnotation0 = new CoreAnnotations.NumericCompositeObjectAnnotation();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      Class<Object> class0 = coreAnnotations_NumericCompositeObjectAnnotation0.getType();
      properties0.put(class0, object0);
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.valueOf("");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // No enum constant edu.stanford.nlp.pipeline.TokenizerAnnotator.TokenizerType.
         //
         verifyException("java.lang.Enum", e);
      }
  }

  @Test(timeout = 4000)
  public void testRequirementsSatisfiedAndCreatesTokenizerAnnotatorTakingNoArguments()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requirementsSatisfied();
      assertEquals(15, set0.size());
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenThrowsIllegalArgumentException()  throws Throwable  {
      CoreLabel coreLabel0 = new CoreLabel();
      coreLabel0.setAfter("hours");
      List<CoreLabel> list0 = List.of(coreLabel0, coreLabel0, coreLabel0);
      // Undeclared exception!
      try { 
        TokenizerAnnotator.adjustFinalToken(list0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // adjustFinalToken: Unexpected final char: |s| (115)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingBooleanAndGetTokenizerType()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false);
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.German;
      tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      Properties properties0 = new Properties();
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType1 = TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      assertEquals(TokenizerAnnotator.TokenizerType.English, tokenizerAnnotator_TokenizerType1);
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAdjustFinalTokenWithEmptyList()  throws Throwable  {
      Vector<CoreLabel> vector0 = new Vector<CoreLabel>();
      TokenizerAnnotator.adjustFinalToken(vector0);
      assertTrue(vector0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3Arguments1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, "English", "English");
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsIllegalArgumentException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("vNK1WXdXmVeEX_b");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property vNK1WXdXmVeEX_b
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3ArgumentsAndCallsAdjustFinalToken()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, (Properties) null, "");
      IndexedWord indexedWord0 = new IndexedWord("", 248, 248);
      TreeGraphNode treeGraphNode0 = new TreeGraphNode(indexedWord0);
      TreeGraphNode treeGraphNode1 = treeGraphNode0.highestNodeWithSameHead();
      Tree tree0 = treeGraphNode1.deepCopy();
      List<Tree> list0 = treeGraphNode0.getChildrenAsList();
      LabeledScoredConstituentFactory labeledScoredConstituentFactory0 = new LabeledScoredConstituentFactory();
      tree0.constituents((ConstituentFactory) labeledScoredConstituentFactory0);
      TreeGraphNode treeGraphNode2 = new TreeGraphNode(tree0, list0);
      List<CoreLabel> list1 = treeGraphNode2.taggedLabeledYield();
      TokenizerAnnotator.adjustFinalToken(list1);
      assertTrue(list1.isEmpty());
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsIllegalArgumentException()  throws Throwable  {
      String string0 = "S7EAtw`C";
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(true, "S7EAtw`C");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property S7EAtw`C
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }
}
