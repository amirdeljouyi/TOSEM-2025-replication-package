/*
 * This file was automatically generated by UTestGen and EvoSuite
 * Mon Apr 21 14:14:45 GMT 2025
 */

package edu.stanford.nlp.pipeline;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import edu.stanford.nlp.ie.AbstractSequenceClassifier;
import edu.stanford.nlp.ie.NERClassifierCombiner;
import edu.stanford.nlp.ling.CoreAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.ling.Label;
import edu.stanford.nlp.ling.WordLemmaTag;
import edu.stanford.nlp.ling.WordLemmaTagFactory;
import edu.stanford.nlp.ling.WordTag;
import edu.stanford.nlp.pipeline.Annotation;
import edu.stanford.nlp.pipeline.TokenizerAnnotator;
import edu.stanford.nlp.process.CoreLabelTokenFactory;
import edu.stanford.nlp.process.Tokenizer;
import edu.stanford.nlp.sequences.SeqClassifierFlags;
import edu.stanford.nlp.sequences.TrueCasingForNISTDocumentReaderAndWriter;
import edu.stanford.nlp.trees.LabeledScoredTreeNode;
import edu.stanford.nlp.trees.TreeGraphNode;
import edu.stanford.nlp.util.CoreMap;
import java.io.BufferedReader;
import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;
import java.io.EOFException;
import java.io.IOException;
import java.io.ObjectInputStream;
import java.io.OutputStream;
import java.io.PipedInputStream;
import java.io.PipedOutputStream;
import java.io.Reader;
import java.io.StringReader;
import java.io.Writer;
import java.lang.reflect.Array;
import java.util.ArrayList;
import java.util.LinkedHashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Properties;
import java.util.Set;
import java.util.Stack;
import java.util.Vector;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.Random;
import org.evosuite.runtime.mock.java.io.MockPrintWriter;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.evosuite.runtime.util.SystemInUtil;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, separateClassLoader = true) 
public class TokenizerAnnotator_2_ESTest extends TokenizerAnnotator_2_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void testGetTokenizer()  throws Throwable  {
      Properties properties0 = new Properties();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0);
      tokenizerAnnotator0.requires();
      StringReader stringReader0 = new StringReader("[Us'5|g7'r13Kp");
      tokenizerAnnotator0.getTokenizer(stringReader0);
      Properties properties1 = new Properties();
      Writer writer0 = Writer.nullWriter();
      MockPrintWriter mockPrintWriter0 = new MockPrintWriter(writer0);
      WordLemmaTag wordLemmaTag0 = new WordLemmaTag("columns", "[Us'5|g7'r13Kp", "array");
      Object object0 = new Object();
      CoreAnnotations.StateAnnotation coreAnnotations_StateAnnotation0 = new CoreAnnotations.StateAnnotation();
      properties0.put(object0, coreAnnotations_StateAnnotation0);
      Properties properties2 = new Properties();
      properties2.put("tokenize.language", "array");
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.getTokenizerType(properties2);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property array
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAdjustFinalTokenWithEmptyListAndAdjustFinalTokenWithNonEmptyList()  throws Throwable  {
      Properties properties0 = new Properties();
      Reader.nullReader();
      Stack<CoreLabel> stack0 = new Stack<CoreLabel>();
      TokenizerAnnotator.adjustFinalToken(stack0);
      SeqClassifierFlags seqClassifierFlags0 = new SeqClassifierFlags(properties0);
      FileSystemHandling.shouldAllThrowIOExceptions();
      CoreLabel coreLabel0 = seqClassifierFlags0.pad;
      coreLabel0.setAfter("");
      stack0.add(coreLabel0);
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, (String) null);
      TokenizerAnnotator.adjustFinalToken(stack0);
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.valueOf((String) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Name is null
         //
         verifyException("java.lang.Enum", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetTokenizerType()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.class", "FrenchTokenizer");
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      LabeledScoredTreeNode labeledScoredTreeNode0 = new LabeledScoredTreeNode();
      TreeGraphNode treeGraphNode0 = new TreeGraphNode(labeledScoredTreeNode0);
      TreeGraphNode treeGraphNode1 = treeGraphNode0.highestNodeWithSameHead();
      TreeGraphNode treeGraphNode2 = treeGraphNode1.highestNodeWithSameHead();
      TreeGraphNode treeGraphNode3 = treeGraphNode2.highestNodeWithSameHead();
      SystemInUtil.addInputLine(",");
      ArrayList<CoreLabel> arrayList0 = treeGraphNode3.yieldHasWord();
      TokenizerAnnotator.adjustFinalToken(arrayList0);
      Random.setNextRandom((-1445790696));
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.ssplit", "");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Annotation annotation0 = new Annotation("");
      tokenizerAnnotator0.annotate(annotation0);
      assertEquals(2, annotation0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingProperties0()  throws Throwable  {
      Properties properties0 = new Properties();
      CoreAnnotations.SectionTagAnnotation coreAnnotations_SectionTagAnnotation0 = new CoreAnnotations.SectionTagAnnotation();
      properties0.put("tokenize.class", coreAnnotations_SectionTagAnnotation0);
      properties0.setProperty("tokenize.class", "PTBTokenizer");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingProperties1()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.class", "PTBTokenizer");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingProperties2()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.options", "tokenize.options");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingProperties3()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.ssplit", "tokenize.ssplit");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingPropertiesThrowsRuntimeException0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("cdc_tokenize.model", "cdc_tokenize.model");
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // org.evosuite.runtime.mock.java.lang.MockThrowable: Unable to open \"cdc_tokenize.model\" as class path, filename or URL
         //
         verifyException("edu.stanford.nlp.process.stattok.StatTokSent", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArguments()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Properties properties0 = new Properties();
      properties0.equals(tokenizerAnnotator0);
      Object object0 = new Object();
      properties0.keys();
      Object object1 = new Object();
      properties0.put(tokenizerAnnotator0, object0);
      properties0.put(object0, object1);
      properties0.put(tokenizerAnnotator0, object0);
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      PipedOutputStream pipedOutputStream0 = new PipedOutputStream();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      PipedInputStream pipedInputStream0 = new PipedInputStream(pipedOutputStream0);
      try { 
        pipedInputStream0.connect(pipedOutputStream0);
        fail("Expecting exception: IOException");
      
      } catch(IOException e) {
         //
         // Already connected
         //
         verifyException("java.io.PipedOutputStream", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingPropertiesThrowsRuntimeException1()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.postProcessor", "tokenize.postProcessor");
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Loading: tokenize.postProcessor failed with: Error creating tokenize.postProcessor
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingPropertiesThrowsRuntimeException2()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.postProcessor", "classToTokenizerMap");
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Loading: classToTokenizerMap failed with: Error creating classToTokenizerMap
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void test()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.class", ",");
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.class property ,
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingPropertiesThrowsIllegalArgumentException()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.class", "tokenize.class");
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.class property tokenize.class
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsRuntimeException0()  throws Throwable  {
      Properties properties0 = new Properties();
      CoreLabel coreLabel0 = CoreLabel.wordFromString("adjustFinFlToken: Unexpected final char: |");
      coreLabel0.setAfter("Find marked head method returned ");
      LinkedList<CoreLabel> linkedList0 = new LinkedList<CoreLabel>();
      CoreLabelTokenFactory coreLabelTokenFactory0 = new CoreLabelTokenFactory();
      String[] stringArray0 = new String[9];
      stringArray0[0] = null;
      stringArray0[1] = "adjustFinFlToken: Unexpected final char: |";
      stringArray0[2] = "!J+";
      stringArray0[3] = "!J+";
      stringArray0[4] = "adjustFinFlToken: Unexpected final char: |";
      stringArray0[5] = "adjustFinFlToken: Unexpected final char: |";
      stringArray0[6] = "adjustFinFlToken: Unexpected final char: |";
      stringArray0[7] = "!J+";
      stringArray0[8] = "!J+";
      CoreLabel coreLabel1 = coreLabelTokenFactory0.makeToken();
      linkedList0.add(coreLabel1);
      coreLabel0.nerConfidence();
      linkedList0.add(coreLabel0);
      TokenizerAnnotator.adjustFinalToken(linkedList0);
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Chinese;
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenThrowsIllegalArgumentException()  throws Throwable  {
      LinkedList<CoreLabel> linkedList0 = new LinkedList<CoreLabel>();
      CoreLabel coreLabel0 = CoreLabel.wordFromString((String) null);
      coreLabel0.setAfter("K==pjnE,N%A2");
      linkedList0.add(coreLabel0);
      // Undeclared exception!
      try { 
        TokenizerAnnotator.adjustFinalToken(linkedList0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // adjustFinalToken: Unexpected final char: |2| (50)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testRequirementsSatisfiedThrowsIllegalArgumentException()  throws Throwable  {
      FileSystemHandling.setPermissions((EvoSuiteFile) null, true, true, false);
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      LinkedList<CoreLabel> linkedList0 = new LinkedList<CoreLabel>();
      CoreLabel coreLabel0 = CoreLabel.wordFromString((String) null);
      coreLabel0.setAfter("JJ+");
      linkedList0.add(coreLabel0);
      coreLabel0.nerConfidence();
      linkedList0.add(coreLabel0);
      // Undeclared exception!
      try { 
        TokenizerAnnotator.adjustFinalToken(linkedList0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // adjustFinalToken: Unexpected final char: |+| (43)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsIllegalArgumentException0()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.French;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      tokenizerAnnotator0.requirementsSatisfied();
      TokenizerAnnotator tokenizerAnnotator1 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
      LinkedHashSet<Class<CoreAnnotations.OriginalTextAnnotation>> linkedHashSet0 = new LinkedHashSet<Class<CoreAnnotations.OriginalTextAnnotation>>();
      TokenizerAnnotator tokenizerAnnotator2 = null;
      try {
        tokenizerAnnotator2 = new TokenizerAnnotator(">7K\"):B=e");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property >7K\"):B=e
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString0()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("French");
  }

  @Test(timeout = 4000)
  public void testRequirementsSatisfiedAndCreatesTokenizerAnnotatorTaking2ArgumentsAndAdjustFinalToken()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Spanish;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      LinkedHashSet<Class<CoreAnnotations.OriginalTextAnnotation>> linkedHashSet0 = new LinkedHashSet<Class<CoreAnnotations.OriginalTextAnnotation>>();
      TokenizerAnnotator.adjustFinalToken((List<CoreLabel>) null);
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requirementsSatisfied();
      assertEquals(15, set0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("es");
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsRuntimeException1()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Arabic;
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ArabicSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAdjustFinalTokenWithNonEmptyList()  throws Throwable  {
      TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0 = new TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser();
      List<CoreLabel> list0 = trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0.apply("m");
      TokenizerAnnotator.adjustFinalToken(list0);
      assertFalse(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate()  throws Throwable  {
      List<CoreLabel> list0 = null;
      Properties properties0 = new Properties(1644);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Annotation annotation0 = new Annotation("M");
      Annotation annotation1 = new Annotation(annotation0);
      tokenizerAnnotator0.annotate(annotation1);
      TokenizerAnnotator.adjustFinalToken((List<CoreLabel>) null);
      Vector<CoreMap> vector0 = new Vector<CoreMap>();
      Annotation annotation2 = new Annotation(vector0);
      Annotation annotation3 = new Annotation(annotation2);
      BufferedReader bufferedReader0 = null;
      try {
        bufferedReader0 = new BufferedReader((Reader) null, 0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.io.Reader", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAdjustFinalTokenWithNull()  throws Throwable  {
      TokenizerAnnotator.adjustFinalToken((List<CoreLabel>) null);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndRequirementsSatisfied()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Whitespace;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      tokenizerAnnotator0.requirementsSatisfied();
      byte[] byteArray0 = new byte[2];
      byteArray0[0] = (byte)10;
      byteArray0[1] = (byte) (-81);
      ByteArrayInputStream byteArrayInputStream0 = new ByteArrayInputStream(byteArray0, (-1459), (byte) (-81));
      ObjectInputStream objectInputStream0 = null;
      try {
        objectInputStream0 = new ObjectInputStream(byteArrayInputStream0);
        fail("Expecting exception: EOFException");
      
      } catch(Throwable e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.io.ObjectInputStream$PeekInputStream", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsRuntimeException0()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("zh");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsRuntimeException2()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Chinese;
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsRuntimeException1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("Arabic");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ArabicSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndCreatesTokenizerAnnotatorTaking2ArgumentsAndGetTokenizer()  throws Throwable  {
      Vector<CoreLabel> vector0 = new Vector<CoreLabel>();
      TokenizerAnnotator.adjustFinalToken(vector0);
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Unspecified;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      Reader reader0 = Reader.nullReader();
      BufferedReader bufferedReader0 = new BufferedReader(reader0);
      tokenizerAnnotator0.getTokenizer(bufferedReader0);
      AbstractSequenceClassifier<CoreLabel>[] abstractSequenceClassifierArray0 = (AbstractSequenceClassifier<CoreLabel>[]) Array.newInstance(AbstractSequenceClassifier.class, 4);
      NERClassifierCombiner nERClassifierCombiner0 = null;
      try {
        nERClassifierCombiner0 = new NERClassifierCombiner(abstractSequenceClassifierArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.ie.ClassifierCombiner", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString2()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("Unspecified");
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString3()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("Whitespace");
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString4()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("de");
  }

  @Test(timeout = 4000)
  public void testGetDefaultOptions()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.isEmpty();
      WordLemmaTagFactory wordLemmaTagFactory0 = new WordLemmaTagFactory('X');
      WordTag wordTag0 = WordTag.valueOf("aw");
      Label label0 = wordLemmaTagFactory0.newLabel((Label) wordTag0);
      CoreLabel coreLabel0 = new CoreLabel(label0);
      properties0.get(coreLabel0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0, ",");
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Chinese;
      String string0 = tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      assertEquals("", string0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3Arguments0()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0, "SBAR=r=,");
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsNullPointerExceptionAndCreatesTokenizerAnnotatorTakingString()  throws Throwable  {
      Annotation annotation0 = new Annotation((String) null);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator((String) null);
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate(annotation0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.WordsToSentencesAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2Arguments()  throws Throwable  {
      Properties properties0 = new Properties();
      ByteArrayOutputStream byteArrayOutputStream0 = new ByteArrayOutputStream();
      properties0.storeToXML((OutputStream) byteArrayOutputStream0, "garrot");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0);
      tokenizerAnnotator0.requirementsSatisfied();
      tokenizerAnnotator0.requires();
      String string0 = "Unknown Redwood flag for slf4j integration: ";
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.valueOf("Unknown Redwood flag for slf4j integration: ");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // No enum constant edu.stanford.nlp.pipeline.TokenizerAnnotator.TokenizerType.Unknown Redwood flag for slf4j integration: 
         //
         verifyException("java.lang.Enum", e);
      }
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsNullPointerExceptionAndAdjustFinalToken()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0);
      tokenizerAnnotator0.requirementsSatisfied();
      TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0 = new TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser();
      List<CoreLabel> list0 = trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0.apply(">");
      TokenizerAnnotator.adjustFinalToken(list0);
      tokenizerAnnotator0.requires();
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate((Annotation) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetTokenizerThrowsIllegalArgumentException()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.equals("m@KT`)*");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0, "m@KT`)*");
      properties0.stringPropertyNames();
      Reader reader0 = Reader.nullReader();
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.getTokenizer(reader0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // PTBLexer: Invalid options key in constructor: m@KT`)*
         //
         verifyException("edu.stanford.nlp.process.PTBLexer", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3Arguments1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, "de", "de");
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingStringAndFailsToCreateTokenizerAnnotatorTakingStringThrowsIllegalArgumentException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("#a]&2l5v37x");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property #a]&2l5v37x
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotateThrowsNullPointerException()  throws Throwable  {
      Properties properties0 = new Properties();
      Object object0 = new Object();
      Object object1 = new Object();
      properties0.put(object0, object1);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      String string0 = "Invalid annotation to tag pattern: ";
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate((Annotation) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingProperties4()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
  }

  @Test(timeout = 4000)
  public void testAnnotateAndCreatesTokenizerAnnotatorTaking2Arguments()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0);
      Annotation annotation0 = new Annotation("");
      String[] stringArray0 = new String[4];
      stringArray0[0] = "";
      stringArray0[1] = "";
      stringArray0[2] = "";
      stringArray0[3] = "";
      annotation0.toShorterString(stringArray0);
      Annotation annotation1 = new Annotation(annotation0);
      tokenizerAnnotator0.annotate(annotation1);
      assertEquals(3, annotation1.size());
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAdjustFinalTokenWithEmptyList()  throws Throwable  {
      Stack<CoreLabel> stack0 = new Stack<CoreLabel>();
      TokenizerAnnotator.adjustFinalToken(stack0);
      assertTrue(stack0.empty());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArgumentsAndRequires()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requires();
      assertEquals(0, set0.size());
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsNullPointerExceptionAndAnnotateWithAnnotationWhereSizeIsPositive()  throws Throwable  {
      Annotation annotation0 = new Annotation((String) null);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate(annotation0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.WordsToSentencesAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArgumentsAndAnnotate()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      List<CoreMap> list0 = List.of();
      Annotation annotation0 = new Annotation(list0);
      tokenizerAnnotator0.annotate(annotation0);
      assertEquals(3, annotation0.size());
  }

  @Test(timeout = 4000)
  public void testGetTokenizerWithNull()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Tokenizer<CoreLabel> tokenizer0 = tokenizerAnnotator0.getTokenizer((Reader) null);
      assertNotNull(tokenizer0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArgumentsAndRequirementsSatisfied()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requirementsSatisfied();
      assertFalse(set0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testRequirementsSatisfiedAndRequires()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false);
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Spanish;
      tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      Properties properties0 = new Properties();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      tokenizerAnnotator0.requirementsSatisfied();
      tokenizerAnnotator0.requirementsSatisfied();
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requirementsSatisfied();
      Annotation annotation0 = new Annotation("WhitespaceTokenizer");
      annotation0.copy();
      tokenizerAnnotator0.annotate(annotation0);
      tokenizerAnnotator0.annotate(annotation0);
      tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      tokenizerAnnotator0.getTokenizer((Reader) null);
      TokenizerAnnotator.TokenizerType.values();
      tokenizerAnnotator0.requires();
      Set<Class<? extends CoreAnnotation>> set1 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requirementsSatisfied();
      assertNotSame(set1, set0);
  }

  @Test(timeout = 4000)
  public void testAnnotateAndCreatesTokenizerAnnotatorTakingProperties()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.ssplit", "hHTL&B*");
      Properties properties1 = new Properties(properties0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties1);
      Vector<CoreMap> vector0 = new Vector<CoreMap>();
      Annotation annotation0 = new Annotation(vector0);
      tokenizerAnnotator0.annotate(annotation0);
      assertEquals(2, annotation0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndRequirementsSatisfied()  throws Throwable  {
      Properties properties0 = new Properties();
      Object object0 = new Object();
      CoreLabel.OutputFormat coreLabel_OutputFormat0 = CoreLabel.OutputFormat.WORD;
      properties0.put(object0, coreLabel_OutputFormat0);
      properties0.setProperty("tokenize.options", "tokenize.options");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requirementsSatisfied();
      assertFalse(set0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsNullPointerExceptionAndAnnotateWithNull()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate((Annotation) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingBoolean()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true);
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate((Annotation) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingBooleanAndCallsAnnotate()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true);
      Annotation annotation0 = null;
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate((Annotation) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsIllegalArgumentException()  throws Throwable  {
      String string0 = " gz[UyiEic:M";
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(false, " gz[UyiEic:M");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property  gz[UyiEic:M
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsIllegalArgumentException1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("YpC`i&e2Aabh<+16I7");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property YpC`i&e2Aabh<+16I7
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString5()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator((String) null);
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking3ArgumentsThrowsIllegalArgumentException()  throws Throwable  {
      String string0 = "";
      String string1 = null;
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(true, "", (String) null);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property 
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }
}
