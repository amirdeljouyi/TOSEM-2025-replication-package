/*
 * This file was automatically generated by UTestGen and EvoSuite
 * Mon Apr 21 14:06:07 GMT 2025
 */

package edu.stanford.nlp.pipeline;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import edu.stanford.nlp.ie.AbstractSequenceClassifier;
import edu.stanford.nlp.ie.NERClassifierCombiner;
import edu.stanford.nlp.ie.PresetSequenceClassifier;
import edu.stanford.nlp.ling.CoreAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.ling.Label;
import edu.stanford.nlp.pipeline.Annotation;
import edu.stanford.nlp.pipeline.TokenizerAnnotator;
import edu.stanford.nlp.sequences.TrueCasingForNISTDocumentReaderAndWriter;
import edu.stanford.nlp.trees.TreeGraphNode;
import edu.stanford.nlp.util.CoreMap;
import java.io.BufferedReader;
import java.io.Reader;
import java.io.StringReader;
import java.lang.reflect.Array;
import java.util.ArrayList;
import java.util.Enumeration;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Properties;
import java.util.Set;
import java.util.Vector;
import java.util.function.UnaryOperator;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.evosuite.runtime.util.SystemInUtil;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, separateClassLoader = true) 
public class TokenizerAnnotator_4_ESTest extends TokenizerAnnotator_4_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndCreatesTokenizerAnnotatorTakingNoArguments()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      SystemInUtil.addInputLine("tokenize.ssplit");
      Properties properties0 = new Properties();
      properties0.put("tokenize.ssplit", "tokenize.ssplit");
      TokenizerAnnotator tokenizerAnnotator1 = new TokenizerAnnotator(true);
      tokenizerAnnotator1.requirementsSatisfied();
      TokenizerAnnotator tokenizerAnnotator2 = new TokenizerAnnotator(properties0);
      assertFalse(tokenizerAnnotator2.equals((Object)tokenizerAnnotator0));
  }

  @Test(timeout = 4000)
  public void testAnnotateAndCreatesTokenizerAnnotatorTakingProperties()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.put("tokenize.ssplit", "tokenize.ssplit");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      TokenizerAnnotator.TokenizerType.values();
      Annotation annotation0 = new Annotation("tokenize.ssplit");
      tokenizerAnnotator0.annotate(annotation0);
      assertEquals(2, annotation0.size());
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking3ArgumentsThrowsIllegalArgumentException0()  throws Throwable  {
      Annotation annotation0 = new Annotation("*NL*");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      TokenizerAnnotator tokenizerAnnotator1 = null;
      try {
        tokenizerAnnotator1 = new TokenizerAnnotator(false, "*NL*", "*NL*");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property *NL*
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingPropertiesThrowsRuntimeException()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.put("tokenize.postProcessor", "tokenize.postProcessor");
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Loading: tokenize.postProcessor failed with: Error creating tokenize.postProcessor
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void test0()  throws Throwable  {
      SystemInUtil.addInputLine("tokenize.class");
      TokenizerAnnotator.TokenizerType.values();
      boolean boolean0 = false;
      Properties properties0 = new Properties();
      properties0.put("tokenize.class", "tokenize.class");
      String string0 = "H[FDv6@z,RT";
      Object object0 = new Object();
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.class property tokenize.class
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking3ArgumentsThrowsIllegalArgumentException1()  throws Throwable  {
      String string0 = "tokenize.class";
      SystemInUtil.addInputLine("tokenize.class");
      TokenizerAnnotator.TokenizerType.values();
      TokenizerAnnotator.TokenizerType.values();
      Properties properties0 = new Properties();
      properties0.put("tokenize.class", "tokenize.class");
      String string1 = "Hr[FDv6@z,RT";
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0, "Hr[FDv6@z,RT");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.class property tokenize.class
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingPropertiesThrowsIllegalArgumentException()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.put("tokenize.class", "tokenize.class");
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.class property tokenize.class
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void test1()  throws Throwable  {
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "tokenize.language");
      TokenizerAnnotator.TokenizerType.values();
      TokenizerAnnotator.TokenizerType.values();
      Properties properties0 = new Properties();
      properties0.put("tokenize.language", "tokenize.language");
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property tokenize.language
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testRequires()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Spanish;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
      Vector<CoreMap> vector0 = new Vector<CoreMap>();
      Annotation annotation0 = new Annotation(vector0);
      tokenizerAnnotator0.annotate(annotation0);
      tokenizerAnnotator0.requires();
      AbstractSequenceClassifier<CoreLabel>[] abstractSequenceClassifierArray0 = (AbstractSequenceClassifier<CoreLabel>[]) Array.newInstance(AbstractSequenceClassifier.class, 1);
      Properties properties0 = new Properties();
      PresetSequenceClassifier<CoreLabel> presetSequenceClassifier0 = new PresetSequenceClassifier<CoreLabel>(properties0);
      abstractSequenceClassifierArray0[0] = (AbstractSequenceClassifier<CoreLabel>) presetSequenceClassifier0;
      // Undeclared exception!
      try { 
        NERClassifierCombiner.createNERClassifierCombiner("Tokenizer unable to find text in annotation: ", properties0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // org.evosuite.runtime.mock.java.lang.MockThrowable: Couldn't load classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz
         //
         verifyException("edu.stanford.nlp.ie.NERClassifierCombiner", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString0()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("es");
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndAdjustFinalToken()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.French;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      HashSet<Class<CoreAnnotations.OriginalTextAnnotation>> hashSet0 = new HashSet<Class<CoreAnnotations.OriginalTextAnnotation>>();
      Vector<CoreMap> vector0 = new Vector<CoreMap>();
      LinkedList<CoreLabel> linkedList0 = new LinkedList<CoreLabel>();
      TokenizerAnnotator.adjustFinalToken(linkedList0);
      assertEquals(0, linkedList0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3ArgumentsAndGetTokenizerType()  throws Throwable  {
      Properties properties0 = new Properties();
      Reader.nullReader();
      properties0.elements();
      Annotation annotation0 = new Annotation("fPY|H+,5'L-$^U{x");
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0, ":QG4Lxm,");
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3Arguments0()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0, ":QG4Lxm,,");
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndGetDefaultOptions()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Unspecified;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      tokenizerAnnotator0.requirementsSatisfied();
      tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      StringReader stringReader0 = new StringReader("invertible,ptb3Escaping=true");
      Properties properties1 = new Properties();
      TokenizerAnnotator tokenizerAnnotator1 = new TokenizerAnnotator(properties0);
      assertFalse(tokenizerAnnotator1.equals((Object)tokenizerAnnotator0));
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("Unspecified");
  }

  @Test(timeout = 4000)
  public void testAnnotateAndAdjustFinalToken()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      assertEquals(TokenizerAnnotator.TokenizerType.English, tokenizerAnnotator_TokenizerType0);
      
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType1 = TokenizerAnnotator.TokenizerType.Whitespace;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType1);
      tokenizerAnnotator0.requirementsSatisfied();
      tokenizerAnnotator_TokenizerType1.getDefaultOptions();
      StringReader stringReader0 = new StringReader("");
      BufferedReader bufferedReader0 = new BufferedReader(stringReader0);
      TokenizerAnnotator tokenizerAnnotator1 = new TokenizerAnnotator(false, properties0, "");
      LinkedList<CoreLabel> linkedList0 = new LinkedList<CoreLabel>();
      TokenizerAnnotator.adjustFinalToken(linkedList0);
      Annotation annotation0 = new Annotation("les");
      tokenizerAnnotator0.annotate(annotation0);
      assertNotSame(tokenizerAnnotator_TokenizerType1, tokenizerAnnotator_TokenizerType0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingStringAndAnnotate()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("Whitespace");
      Annotation annotation0 = new Annotation("Whitespace");
      tokenizerAnnotator0.annotate(annotation0);
      assertEquals(3, annotation0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingStringAndAdjustFinalToken()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("English");
      LinkedList<CoreLabel> linkedList0 = new LinkedList<CoreLabel>();
      TokenizerAnnotator.adjustFinalToken(linkedList0);
      assertEquals(0, linkedList0.size());
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsNullPointerExceptionAndCreatesTokenizerAnnotatorTakingBoolean()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true);
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate((Annotation) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetTokenizerReturningNonNull()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0);
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      arrayList0.spliterator();
      TokenizerAnnotator.adjustFinalToken(arrayList0);
      TokenizerAnnotator.TokenizerType.valueOf("Whitespace");
      CoreAnnotations.OriginalTextAnnotation coreAnnotations_OriginalTextAnnotation0 = new CoreAnnotations.OriginalTextAnnotation();
      properties0.put(tokenizerAnnotator0, coreAnnotations_OriginalTextAnnotation0);
      TokenizerAnnotator.TokenizerType.valueOf("Whitespace");
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      tokenizerAnnotator0.requires();
      TokenizerAnnotator.adjustFinalToken(arrayList0);
      Reader reader0 = Reader.nullReader();
      tokenizerAnnotator0.getTokenizer(reader0);
      tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      tokenizerAnnotator0.requirementsSatisfied();
      TokenizerAnnotator.TokenizerType.values();
      TreeGraphNode treeGraphNode0 = null;
      try {
        treeGraphNode0 = new TreeGraphNode((Label) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.ling.CoreLabel$CoreLabelFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString2()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("fr");
  }

  @Test(timeout = 4000)
  public void testAnnotateAndRequires()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.German;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      tokenizerAnnotator0.requires();
      Vector<CoreMap> vector0 = new Vector<CoreMap>();
      Annotation annotation0 = new Annotation(vector0);
      tokenizerAnnotator0.annotate(annotation0);
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.getTokenizerType((Properties) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString3()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("de");
  }

  @Test(timeout = 4000)
  public void testRequirementsSatisfiedThrowsRuntimeException()  throws Throwable  {
      TokenizerAnnotator.TokenizerType.values();
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Chinese;
      Properties properties0 = new Properties();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      Properties properties1 = new Properties();
      properties1.propertyNames();
      CoreAnnotations.NumericCompositeObjectAnnotation coreAnnotations_NumericCompositeObjectAnnotation0 = new CoreAnnotations.NumericCompositeObjectAnnotation();
      Class<Object> class0 = coreAnnotations_NumericCompositeObjectAnnotation0.getType();
      properties1.remove((Object) class0);
      Properties properties2 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties2);
      TokenizerAnnotator tokenizerAnnotator1 = null;
      try {
        tokenizerAnnotator1 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenWithNull()  throws Throwable  {
      TokenizerAnnotator.adjustFinalToken((List<CoreLabel>) null);
      boolean boolean0 = true;
      Properties properties0 = new Properties();
      // Undeclared exception!
      try { 
        properties0.replace((Object) null, (Object) null, (Object) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.util.concurrent.ConcurrentHashMap", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsRuntimeException0()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("Chinese");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsRuntimeException1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("Arabic");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ArabicSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsNullPointerExceptionAndCreatesTokenizerAnnotatorTakingNoArguments()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate((Annotation) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testRequirementsSatisfiedThrowsNullPointerException()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.requires();
      tokenizerAnnotator0.requires();
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate((Annotation) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2Arguments0()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndCallsAdjustFinalToken()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0);
      String string0 = "Whitespace";
      properties0.entrySet();
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      arrayList0.spliterator();
      TokenizerAnnotator.adjustFinalToken(arrayList0);
      TokenizerAnnotator.TokenizerType.valueOf("Whitespace");
      // Undeclared exception!
      try { 
        properties0.contains((Object) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.util.concurrent.ConcurrentHashMap", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAnnotate()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.keys();
      UnaryOperator.identity();
      LinkedList<CoreLabel> linkedList0 = new LinkedList<CoreLabel>();
      UnaryOperator<CoreLabel> unaryOperator0 = UnaryOperator.identity();
      linkedList0.replaceAll(unaryOperator0);
      linkedList0.spliterator();
      TokenizerAnnotator.adjustFinalToken(linkedList0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true);
      Properties properties1 = new Properties();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties1);
      Annotation annotation0 = new Annotation("f5g-:vTT");
      tokenizerAnnotator0.annotate(annotation0);
      tokenizerAnnotator0.requires();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      tokenizerAnnotator0.requirementsSatisfied();
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requires();
      assertTrue(set0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testAdjustFinalToken()  throws Throwable  {
      TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0 = new TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser();
      List<CoreLabel> list0 = trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0.apply("Tokenized: ");
      TokenizerAnnotator.adjustFinalToken(list0);
      assertFalse(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenThrowsIllegalArgumentException()  throws Throwable  {
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      CoreLabel coreLabel0 = new CoreLabel();
      coreLabel0.setAfter(" words, with an average length of ");
      arrayList0.add(coreLabel0);
      TokenizerAnnotator.adjustFinalToken(arrayList0);
      // Undeclared exception!
      try { 
        TokenizerAnnotator.adjustFinalToken(arrayList0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // adjustFinalToken: Unexpected final char: |f| (102)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArgumentsAndAnnotate()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Annotation annotation0 = new Annotation("C>inese");
      tokenizerAnnotator0.annotate(annotation0);
      assertEquals(3, annotation0.size());
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndRequirementsSatisfied()  throws Throwable  {
      LinkedList<CoreLabel> linkedList0 = new LinkedList<CoreLabel>();
      CoreLabel coreLabel0 = CoreLabel.wordFromString("BbEthW*|r2-");
      CoreLabel coreLabel1 = new CoreLabel(coreLabel0);
      linkedList0.add(coreLabel1);
      String[] stringArray0 = new String[7];
      stringArray0[0] = "";
      stringArray0[1] = "BbEthW*|r2-";
      stringArray0[2] = "BbEthW*|r2-";
      stringArray0[3] = "BbEthW*|r2-";
      stringArray0[4] = "BbEthW*|r2-";
      stringArray0[5] = "BbEthW*|r2-";
      stringArray0[6] = "BbEthW*|r2-";
      coreLabel0.toShorterString(stringArray0);
      UnaryOperator<CoreLabel> unaryOperator0 = UnaryOperator.identity();
      unaryOperator0.apply(coreLabel0);
      UnaryOperator.identity();
      linkedList0.replaceAll(unaryOperator0);
      linkedList0.spliterator();
      TokenizerAnnotator.adjustFinalToken(linkedList0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true);
      Properties properties0 = new Properties();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      tokenizerAnnotator0.requires();
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      assertEquals(TokenizerAnnotator.TokenizerType.English, tokenizerAnnotator_TokenizerType0);
      
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requirementsSatisfied();
      assertEquals(15, set0.size());
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAdjustFinalTokenWithEmptyList()  throws Throwable  {
      LinkedList<CoreLabel> linkedList0 = new LinkedList<CoreLabel>();
      TokenizerAnnotator.adjustFinalToken(linkedList0);
      assertEquals(0, linkedList0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArgumentsAndRequires()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requires();
      assertEquals(0, set0.size());
  }

  @Test(timeout = 4000)
  public void testGetTokenizerThrowsIllegalArgumentException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, (Properties) null, "FrenchTokenizer");
      tokenizerAnnotator0.requirementsSatisfied();
      tokenizerAnnotator0.requires();
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.getTokenizer((Reader) null);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // PTBLexer: Invalid options key in constructor: FrenchTokenizer
         //
         verifyException("edu.stanford.nlp.process.PTBLexer", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3Arguments1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, "Whitespace", "Whitespace");
  }

  @Test(timeout = 4000)
  public void testGetTokenizer()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Reader reader0 = Reader.nullReader();
      tokenizerAnnotator0.getTokenizer(reader0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingStringAndFailsToCreateTokenizerAnnotatorTakingStringThrowsIllegalArgumentException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("R%in$>F4");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property R%in$>F4
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2Arguments1()  throws Throwable  {
      String string0 = null;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, (String) null);
      Annotation annotation0 = new Annotation((String) null);
      String[] stringArray0 = new String[8];
      // Undeclared exception!
      try { 
        annotation0.toShortString(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.util.ArrayCoreMap", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString4()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator((String) null);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingBoolean()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false);
      tokenizerAnnotator0.requirementsSatisfied();
      TokenizerAnnotator.TokenizerType.values();
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Chinese;
      Properties properties0 = new Properties();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      TokenizerAnnotator.TokenizerType.values();
      List<CoreMap> list0 = null;
      Annotation annotation0 = null;
      try {
        annotation0 = new Annotation((List<CoreMap>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.Annotation", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArgumentsAndRequirementsSatisfied()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requirementsSatisfied();
      assertEquals(15, set0.size());
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsIllegalArgumentException()  throws Throwable  {
      String string0 = "u7By>5";
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(false, "u7By>5");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property u7By>5
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetDefaultOptions()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Spanish;
      String string0 = tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      assertEquals("invertible,ellipses=ascii,splitAll=false", string0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingProperties()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.put("tokenize.options", "tokenize.options");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsRuntimeException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false);
      TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0 = new TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser();
      List<CoreLabel> list0 = trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0.apply("invertible,splitCompounds=false,splitContractions=false,quotes=ORIGINAL");
      TokenizerAnnotator.adjustFinalToken(list0);
      Properties properties0 = new Properties();
      Enumeration<?> enumeration0 = properties0.propertyNames();
      CoreAnnotations.NumericCompositeObjectAnnotation coreAnnotations_NumericCompositeObjectAnnotation0 = new CoreAnnotations.NumericCompositeObjectAnnotation();
      coreAnnotations_NumericCompositeObjectAnnotation0.getType();
      properties0.remove((Object) enumeration0);
      Properties properties1 = new Properties();
      TokenizerAnnotator tokenizerAnnotator1 = new TokenizerAnnotator(properties0);
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Arabic;
      TokenizerAnnotator tokenizerAnnotator2 = null;
      try {
        tokenizerAnnotator2 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ArabicSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArguments()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      StringReader stringReader0 = new StringReader("tokenize.codepoint");
      BufferedReader bufferedReader0 = null;
      try {
        bufferedReader0 = new BufferedReader(stringReader0, (-1321));
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Buffer size <= 0
         //
         verifyException("java.io.BufferedReader", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingPropertiesThrowsNullPointerException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator((Properties) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsIllegalArgumentException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("u@`X~aso");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property u@`X~aso
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testRequiresThrowsIllegalArgumentException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(true, "<SbFL./^s=*d!o6J(", "S");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property <SbFL./^s=*d!o6J(
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }
}
