/*
 * This file was automatically generated by UTestGen and EvoSuite
 * Sun Jul 13 21:42:21 GMT 2025
 */

package opennlp.tools.tokenize;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.EOFException;
import java.io.IOException;
import java.io.StringReader;
import java.util.HashMap;
import java.util.LinkedHashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.Stack;
import java.util.regex.Pattern;
import java.util.regex.PatternSyntaxException;
import opennlp.tools.dictionary.Dictionary;
import opennlp.tools.doccat.DoccatFactory;
import opennlp.tools.doccat.FeatureGenerator;
import opennlp.tools.ml.maxent.GISModel;
import opennlp.tools.ml.model.Context;
import opennlp.tools.ml.model.UniformPrior;
import opennlp.tools.ml.perceptron.PerceptronModel;
import opennlp.tools.namefind.TokenNameFinderFactory;
import opennlp.tools.tokenize.TokenSample;
import opennlp.tools.tokenize.TokenizerFactory;
import opennlp.tools.tokenize.TokenizerME;
import opennlp.tools.tokenize.TokenizerModel;
import opennlp.tools.tokenize.lang.Factory;
import opennlp.tools.util.CollectionObjectStream;
import opennlp.tools.util.ObjectStream;
import opennlp.tools.util.Span;
import opennlp.tools.util.TrainingParameters;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.System;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.EvoSuiteURL;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.evosuite.runtime.testdata.NetworkHandling;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, separateClassLoader = true) 
public class TokenizerME_3_ESTest extends TokenizerME_3_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETakingTokenizerModelAndTokenizePos0()  throws Throwable  {
      Context[] contextArray0 = new Context[14];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "T";
      stringArray0[1] = "T";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray0, uniformPrior0);
      HashMap<String, String> hashMap0 = new HashMap<String, String>();
      Dictionary dictionary0 = new Dictionary();
      Pattern pattern0 = Pattern.compile("T");
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("T", dictionary0, true, pattern0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, hashMap0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      Span[] spanArray0 = tokenizerME0.tokenizePos("?Q7iq'(;(S9jXqGBEG");
      assertTrue(tokenizerME0.useAlphaNumericOptimization());
      assertEquals(18, spanArray0.length);
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerMETakingStringThrowsIOException0()  throws Throwable  {
      Context[] contextArray0 = new Context[10];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "F";
      stringArray0[1] = "F";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray0, uniformPrior0);
      Pattern pattern0 = Pattern.compile("45FJAn90FqQD|]");
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("ar^-s", (Dictionary) null, true, pattern0);
      Map<String, String> map0 = tokenizerFactory0.createManifestEntries();
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, map0, tokenizerFactory0);
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      TokenizerME tokenizerME1 = new TokenizerME(tokenizerModel0, factory0);
      TokenizerME tokenizerME2 = new TokenizerME(tokenizerModel0);
      tokenizerME1.getTokenProbabilities();
      tokenizerME1.getTokenProbabilities();
      tokenizerME2.tokenizePos("ar^-s");
      tokenizerME2.isAcceptableAbbreviation("45FJAn90FqQD|]");
      tokenizerME1.isAcceptableAbbreviation("F");
      System.setCurrentTimeMillis((-1L));
      LinkedHashSet<TokenSample> linkedHashSet0 = new LinkedHashSet<TokenSample>();
      TokenizerME tokenizerME3 = new TokenizerME(tokenizerModel0, factory0);
      TokenizerME tokenizerME4 = null;
      try {
        tokenizerME4 = new TokenizerME("45FJAn90FqQD|]");
        fail("Expecting exception: IOException");
      
      } catch(Throwable e) {
         //
         // Invalid model.
         //
         verifyException("opennlp.tools.util.DownloadUtil", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETakingTokenizerModelAndCreatesTokenizerMETaking2Arguments()  throws Throwable  {
      Context[] contextArray0 = new Context[10];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "F";
      stringArray0[1] = "F";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray0, uniformPrior0);
      DoccatFactory doccatFactory0 = new DoccatFactory();
      HashMap<String, String> hashMap0 = new HashMap<String, String>();
      Pattern pattern0 = Factory.DEFAULT_ALPHANUMERIC;
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("F", (Dictionary) null, true, pattern0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, hashMap0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      Factory factory0 = new Factory();
      TokenizerME tokenizerME1 = new TokenizerME(tokenizerModel0, factory0);
      assertFalse(tokenizerME1.equals((Object)tokenizerME0));
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETakingTokenizerModelAndTokenizePos1()  throws Throwable  {
      Context[] contextArray0 = new Context[10];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "T";
      stringArray0[1] = "T";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray0, uniformPrior0);
      HashMap<String, String> hashMap0 = new HashMap<String, String>();
      Pattern pattern0 = Factory.DEFAULT_ALPHANUMERIC;
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("$+L", (Dictionary) null, true, pattern0);
      PerceptronModel perceptronModel0 = new PerceptronModel(contextArray0, stringArray0, stringArray0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(perceptronModel0, hashMap0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      Span[] spanArray0 = tokenizerME0.tokenizePos("RhD:3gH7KVt@");
      assertTrue(tokenizerME0.useAlphaNumericOptimization());
      assertEquals(12, spanArray0.length);
  }

  @Test(timeout = 4000)
  public void testTrainThrowsEOFException()  throws Throwable  {
      TrainingParameters trainingParameters0 = new TrainingParameters();
      Factory factory0 = new Factory();
      Context[] contextArray0 = new Context[7];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "F";
      stringArray0[1] = "F";
      String[] stringArray1 = new String[2];
      UniformPrior uniformPrior0 = new UniformPrior();
      StringReader stringReader0 = new StringReader("F");
      Dictionary dictionary0 = Dictionary.parseOneEntryPerLine(stringReader0);
      Pattern pattern0 = Pattern.compile("null elements are not allowed in tags!");
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("F", dictionary0, false, pattern0);
      GISModel gISModel0 = new GISModel(contextArray0, stringArray1, stringArray0);
      HashMap<String, String> hashMap0 = new HashMap<String, String>();
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, hashMap0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      tokenizerME0.getTokenProbabilities();
      tokenizerME0.getTokenProbabilities();
      tokenizerME0.tokenizePos("F");
      tokenizerME0.isAcceptableAbbreviation("F");
      TokenSample tokenSample0 = TokenSample.parse("%7r", "T");
      tokenizerME0.isAcceptableAbbreviation("F");
      List<TokenSample> list0 = List.of(tokenSample0);
      CollectionObjectStream<TokenSample> collectionObjectStream0 = new CollectionObjectStream<TokenSample>(list0);
      TokenNameFinderFactory tokenNameFinderFactory0 = new TokenNameFinderFactory();
      Map<String, Object> map0 = tokenNameFinderFactory0.createArtifactMap();
      TrainingParameters trainingParameters1 = new TrainingParameters(map0);
      try { 
        TokenizerME.train(collectionObjectStream0, tokenizerFactory0, trainingParameters0);
        fail("Expecting exception: EOFException");
      
      } catch(EOFException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.io.DataInputStream", e);
      }
  }

  @Test(timeout = 4000)
  public void testTokenizePosAndTokenizePos()  throws Throwable  {
      TrainingParameters trainingParameters0 = new TrainingParameters();
      Factory factory0 = new Factory();
      Factory factory1 = new Factory();
      Context[] contextArray0 = new Context[7];
      int[] intArray0 = new int[16];
      intArray0[1] = (-892);
      intArray0[2] = 0;
      intArray0[3] = 1606;
      intArray0[1] = 0;
      contextArray0[3] = contextArray0[1];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "F";
      stringArray0[1] = "_1wE";
      String[] stringArray1 = new String[2];
      stringArray1[0] = "F";
      stringArray1[1] = "F";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray1, uniformPrior0);
      DoccatFactory doccatFactory0 = new DoccatFactory((FeatureGenerator[]) null);
      Map<String, String> map0 = doccatFactory0.createManifestEntries();
      Dictionary dictionary0 = new Dictionary(true);
      Pattern pattern0 = Pattern.compile("_1wE");
      doccatFactory0.createManifestEntries();
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("_1wE", dictionary0, true, pattern0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, map0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory1);
      tokenizerME0.getTokenProbabilities();
      Span[] spanArray0 = tokenizerME0.tokenizePos("Computing model parameters ...");
      assertTrue(tokenizerME0.useAlphaNumericOptimization());
      assertEquals(4, spanArray0.length);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETakingTokenizerModelAndTokenizePos2()  throws Throwable  {
      Context[] contextArray0 = new Context[4];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "F";
      stringArray0[1] = "F";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray0, uniformPrior0);
      HashMap<String, String> hashMap0 = new HashMap<String, String>();
      Dictionary dictionary0 = new Dictionary();
      Pattern pattern0 = Factory.DEFAULT_ALPHANUMERIC;
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("F", dictionary0, true, pattern0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, hashMap0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      Span[] spanArray0 = tokenizerME0.tokenizePos("NX");
      assertEquals(1, spanArray0.length);
      assertTrue(tokenizerME0.useAlphaNumericOptimization());
  }

  @Test(timeout = 4000)
  public void testTokenizePosReturningEmptyArray()  throws Throwable  {
      TrainingParameters trainingParameters0 = new TrainingParameters();
      Factory factory0 = new Factory();
      Factory factory1 = new Factory();
      Context[] contextArray0 = new Context[7];
      int[] intArray0 = new int[16];
      intArray0[2] = 0;
      intArray0[3] = 1606;
      intArray0[1] = 0;
      contextArray0[3] = contextArray0[1];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "F";
      stringArray0[1] = "_1wE";
      String[] stringArray1 = new String[2];
      stringArray1[0] = "F";
      stringArray1[1] = "F";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray1, uniformPrior0);
      DoccatFactory doccatFactory0 = new DoccatFactory((FeatureGenerator[]) null);
      Dictionary dictionary0 = new Dictionary(true);
      // Undeclared exception!
      try { 
        Pattern.compile("\"H%c;\")MI$");
        fail("Expecting exception: PatternSyntaxException");
      
      } catch(PatternSyntaxException e) {
         //
         // Unmatched closing ')' near index 5
         // \"H%c;\")MI$
         //      ^
         //
         verifyException("java.util.regex.Pattern", e);
      }
  }

  @Test(timeout = 4000)
  public void testTokenizePos()  throws Throwable  {
      TrainingParameters trainingParameters0 = new TrainingParameters();
      Factory factory0 = new Factory();
      Factory factory1 = new Factory();
      Context[] contextArray0 = new Context[7];
      int[] intArray0 = new int[16];
      intArray0[2] = 0;
      intArray0[3] = 1606;
      intArray0[1] = 0;
      contextArray0[3] = contextArray0[1];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "F";
      stringArray0[1] = "_1wE";
      String[] stringArray1 = new String[2];
      stringArray1[0] = "F";
      stringArray1[1] = "F";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray1, uniformPrior0);
      DoccatFactory doccatFactory0 = new DoccatFactory((FeatureGenerator[]) null);
      Dictionary dictionary0 = new Dictionary(false);
      // Undeclared exception!
      try { 
        Pattern.compile("\"H%c;\")MI$");
        fail("Expecting exception: PatternSyntaxException");
      
      } catch(PatternSyntaxException e) {
         //
         // Unmatched closing ')' near index 5
         // \"H%c;\")MI$
         //      ^
         //
         verifyException("java.util.regex.Pattern", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETakingTokenizerModelAndTokenizePos3()  throws Throwable  {
      Context[] contextArray0 = new Context[4];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "F";
      stringArray0[1] = "F";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray0, uniformPrior0);
      HashMap<String, String> hashMap0 = new HashMap<String, String>();
      Dictionary dictionary0 = new Dictionary();
      Pattern pattern0 = Pattern.compile("F");
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("F", dictionary0, false, pattern0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, hashMap0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      Span[] spanArray0 = tokenizerME0.tokenizePos("NP.*");
      assertEquals(1, spanArray0.length);
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerMETakingStringThrowsIOExceptionAndTokenizePos()  throws Throwable  {
      Factory factory0 = new Factory();
      NetworkHandling.createRemoteTextFile((EvoSuiteURL) null, "T");
      Context[] contextArray0 = new Context[7];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "T";
      stringArray0[1] = "T";
      String[] stringArray1 = new String[2];
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray1, stringArray0, uniformPrior0);
      DoccatFactory doccatFactory0 = new DoccatFactory();
      HashMap<String, String> hashMap0 = new HashMap<String, String>();
      Dictionary dictionary0 = new Dictionary(false);
      Pattern pattern0 = Pattern.compile("T");
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("cDzlXcf+29(", dictionary0, true, pattern0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, hashMap0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      Set<String> set0 = dictionary0.asStringSet();
      factory0.createTokenContextGenerator("cDzlXcf+29(", set0);
      TokenizerME tokenizerME1 = new TokenizerME(tokenizerModel0, factory0);
      TokenizerME tokenizerME2 = new TokenizerME(tokenizerModel0);
      tokenizerME1.getTokenProbabilities();
      tokenizerME2.tokenizePos("at");
      tokenizerME2.isAcceptableAbbreviation("T");
      tokenizerME2.isAcceptableAbbreviation("T");
      TokenizerME tokenizerME3 = new TokenizerME(tokenizerModel0);
      TokenizerME tokenizerME4 = null;
      try {
        tokenizerME4 = new TokenizerME("T");
        fail("Expecting exception: IOException");
      
      } catch(Throwable e) {
         //
         // Invalid model.
         //
         verifyException("opennlp.tools.util.DownloadUtil", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetTokenProbabilities()  throws Throwable  {
      Context[] contextArray0 = new Context[10];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "T";
      stringArray0[1] = "T";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray0, uniformPrior0);
      HashMap<String, String> hashMap0 = new HashMap<String, String>();
      Dictionary dictionary0 = new Dictionary();
      Pattern pattern0 = Factory.DEFAULT_ALPHANUMERIC;
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("T", dictionary0, true, pattern0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, hashMap0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      tokenizerME0.tokenizePos("T");
      double[] doubleArray0 = tokenizerME0.getTokenProbabilities();
      assertArrayEquals(new double[] {1.0}, doubleArray0, 0.01);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETakingTokenizerModelAndTokenizePos4()  throws Throwable  {
      Context[] contextArray0 = new Context[10];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "F";
      stringArray0[1] = "F";
      UniformPrior uniformPrior0 = new UniformPrior();
      HashMap<String, String> hashMap0 = new HashMap<String, String>();
      Dictionary dictionary0 = new Dictionary();
      Pattern pattern0 = Factory.DEFAULT_ALPHANUMERIC;
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("F", dictionary0, false, pattern0);
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, hashMap0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      Span[] spanArray0 = tokenizerME0.tokenizePos("F");
      assertEquals(1, spanArray0.length);
  }

  @Test(timeout = 4000)
  public void testGetTokenProbabilitiesReturningNonEmptyArray()  throws Throwable  {
      TrainingParameters trainingParameters0 = new TrainingParameters();
      Factory factory0 = new Factory();
      Factory factory1 = new Factory();
      Context[] contextArray0 = new Context[7];
      int[] intArray0 = new int[16];
      intArray0[2] = 0;
      intArray0[3] = 1606;
      intArray0[1] = 0;
      contextArray0[3] = contextArray0[1];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "F";
      stringArray0[1] = "_1wE";
      String[] stringArray1 = new String[2];
      stringArray1[0] = "F";
      stringArray1[1] = "F";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray1, uniformPrior0);
      DoccatFactory doccatFactory0 = new DoccatFactory((FeatureGenerator[]) null);
      Map<String, String> map0 = doccatFactory0.createManifestEntries();
      Dictionary dictionary0 = new Dictionary(true);
      Pattern pattern0 = Pattern.compile("_1wE");
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("_1wE", dictionary0, true, pattern0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, map0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory1);
      tokenizerME0.tokenizePos("F");
      assertTrue(tokenizerME0.useAlphaNumericOptimization());
      
      tokenizerME0.keepNewLines = true;
      tokenizerME0.keepNewLines = true;
      tokenizerME0.useAlphaNumericOptimization();
      tokenizerME0.isAcceptableAbbreviation("_1wE");
      double[] doubleArray0 = tokenizerME0.getTokenProbabilities();
      assertArrayEquals(new double[] {1.0}, doubleArray0, 0.01);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETakingTokenizerModelAndGetTokenProbabilities()  throws Throwable  {
      Context[] contextArray0 = new Context[3];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "F";
      stringArray0[1] = "F";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray0, uniformPrior0);
      HashMap<String, String> hashMap0 = new HashMap<String, String>();
      Dictionary dictionary0 = new Dictionary();
      Pattern pattern0 = Pattern.compile("F");
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("F", dictionary0, false, pattern0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, hashMap0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      double[] doubleArray0 = tokenizerME0.getTokenProbabilities();
      assertEquals(0, doubleArray0.length);
  }

  @Test(timeout = 4000)
  public void testGetTokenProbabilitiesAndIsAcceptableAbbreviation()  throws Throwable  {
      TrainingParameters trainingParameters0 = new TrainingParameters();
      Factory factory0 = new Factory();
      Factory factory1 = new Factory();
      Context[] contextArray0 = new Context[7];
      int[] intArray0 = new int[16];
      intArray0[2] = 0;
      intArray0[3] = 1606;
      intArray0[1] = 0;
      contextArray0[3] = contextArray0[1];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "F";
      stringArray0[1] = "_1wE";
      String[] stringArray1 = new String[2];
      stringArray1[0] = "F";
      stringArray1[1] = "F";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray1, uniformPrior0);
      DoccatFactory doccatFactory0 = new DoccatFactory((FeatureGenerator[]) null);
      Map<String, String> map0 = doccatFactory0.createManifestEntries();
      Dictionary dictionary0 = new Dictionary(true);
      Pattern pattern0 = Pattern.compile("_1wE");
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("_1wE", dictionary0, true, pattern0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, map0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory1);
      boolean boolean0 = tokenizerME0.useAlphaNumericOptimization();
      assertTrue(boolean0);
      
      tokenizerME0.isAcceptableAbbreviation("_1wE");
      tokenizerME0.getTokenProbabilities();
      assertTrue(tokenizerME0.useAlphaNumericOptimization());
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerMETakingStringThrowsIOException1()  throws Throwable  {
      Context[] contextArray0 = new Context[4];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "F";
      stringArray0[1] = "F";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray0, uniformPrior0);
      HashMap<String, String> hashMap0 = new HashMap<String, String>();
      Dictionary dictionary0 = new Dictionary();
      Pattern pattern0 = Pattern.compile("F");
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("F", dictionary0, false, pattern0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, hashMap0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      tokenizerME0.isAcceptableAbbreviation("F");
      TokenizerME tokenizerME1 = null;
      try {
        tokenizerME1 = new TokenizerME("F");
        fail("Expecting exception: IOException");
      
      } catch(Throwable e) {
         //
         // Invalid model.
         //
         verifyException("opennlp.tools.util.DownloadUtil", e);
      }
  }

  @Test(timeout = 4000)
  public void testIsAcceptableAbbreviationWithCharSequenceWhereLengthIsZero()  throws Throwable  {
      Factory factory0 = new Factory();
      Context[] contextArray0 = new Context[14];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "F";
      stringArray0[1] = "F";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray0, uniformPrior0);
      DoccatFactory doccatFactory0 = new DoccatFactory((FeatureGenerator[]) null);
      Map<String, String> map0 = doccatFactory0.createManifestEntries();
      Pattern pattern0 = Factory.DEFAULT_ALPHANUMERIC;
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("", (Dictionary) null, true, pattern0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, map0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      tokenizerME0.isAcceptableAbbreviation("");
      tokenizerME0.tokenizePos("F");
      TokenizerME tokenizerME1 = new TokenizerME(tokenizerModel0);
      double[] doubleArray0 = tokenizerME1.getTokenProbabilities();
      assertEquals(0, doubleArray0.length);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETakingString()  throws Throwable  {
      TrainingParameters trainingParameters0 = new TrainingParameters();
      Factory factory0 = new Factory();
      Factory factory1 = new Factory();
      Context[] contextArray0 = new Context[7];
      int[] intArray0 = new int[16];
      intArray0[1] = (-899);
      intArray0[2] = 0;
      intArray0[3] = 1606;
      intArray0[1] = 0;
      contextArray0[3] = contextArray0[1];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "F";
      stringArray0[1] = "_1wE";
      String[] stringArray1 = new String[2];
      stringArray1[0] = "F";
      stringArray1[1] = "F";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray1, uniformPrior0);
      DoccatFactory doccatFactory0 = new DoccatFactory((FeatureGenerator[]) null);
      Map<String, String> map0 = doccatFactory0.createManifestEntries();
      Dictionary dictionary0 = new Dictionary(true);
      Pattern pattern0 = Pattern.compile("_1wE");
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("_1wE", dictionary0, true, pattern0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, map0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory1);
      TokenizerME tokenizerME1 = null;
      try {
        tokenizerME1 = new TokenizerME("");
        fail("Expecting exception: IOException");
      
      } catch(Throwable e) {
         //
         // Invalid model.
         //
         verifyException("opennlp.tools.util.DownloadUtil", e);
      }
  }

  @Test(timeout = 4000)
  public void testUseAlphaNumericOptimizationReturningTrue()  throws Throwable  {
      TrainingParameters trainingParameters0 = new TrainingParameters();
      Factory factory0 = new Factory();
      Factory factory1 = new Factory();
      Context[] contextArray0 = new Context[7];
      int[] intArray0 = new int[16];
      intArray0[1] = (-899);
      intArray0[2] = 0;
      intArray0[3] = 1606;
      intArray0[1] = 0;
      contextArray0[3] = contextArray0[1];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "F";
      stringArray0[1] = "_1wE";
      String[] stringArray1 = new String[2];
      stringArray1[0] = "F";
      stringArray1[1] = "F";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray1, uniformPrior0);
      DoccatFactory doccatFactory0 = new DoccatFactory((FeatureGenerator[]) null);
      Map<String, String> map0 = doccatFactory0.createManifestEntries();
      Dictionary dictionary0 = new Dictionary(true);
      Pattern pattern0 = Pattern.compile("_1wE");
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("_1wE", dictionary0, true, pattern0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, map0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory1);
      boolean boolean0 = tokenizerME0.useAlphaNumericOptimization();
      assertTrue(boolean0);
  }

  @Test(timeout = 4000)
  public void testUseAlphaNumericOptimizationAndCreatesTokenizerMETakingTokenizerModel()  throws Throwable  {
      TrainingParameters trainingParameters0 = new TrainingParameters();
      Factory factory0 = new Factory();
      Factory factory1 = new Factory();
      Context[] contextArray0 = new Context[7];
      int[] intArray0 = new int[16];
      intArray0[1] = (-899);
      intArray0[2] = 52;
      intArray0[3] = 1606;
      double[] doubleArray0 = new double[9];
      doubleArray0[2] = (double) 0;
      doubleArray0[3] = (double) 1606;
      doubleArray0[4] = (double) 52;
      intArray0[1] = 52;
      doubleArray0[7] = (double) (-899);
      doubleArray0[8] = (double) 52;
      Context context0 = new Context(intArray0, doubleArray0);
      contextArray0[1] = context0;
      Context context1 = new Context(intArray0, doubleArray0);
      contextArray0[1] = context1;
      Context context2 = new Context(intArray0, doubleArray0);
      contextArray0[2] = context2;
      contextArray0[3] = context1;
      Context context3 = new Context(intArray0, doubleArray0);
      contextArray0[4] = context3;
      contextArray0[5] = context0;
      Context context4 = new Context(intArray0, doubleArray0);
      contextArray0[6] = context4;
      String[] stringArray0 = new String[2];
      stringArray0[0] = "F";
      stringArray0[1] = "_1wE";
      String[] stringArray1 = new String[2];
      stringArray1[0] = "F";
      stringArray1[1] = "F";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray1, uniformPrior0);
      DoccatFactory doccatFactory0 = new DoccatFactory((FeatureGenerator[]) null);
      Map<String, String> map0 = doccatFactory0.createManifestEntries();
      Dictionary dictionary0 = new Dictionary(true);
      Pattern pattern0 = Pattern.compile("_1wE");
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("_1wE", dictionary0, false, pattern0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, map0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      boolean boolean0 = tokenizerME0.useAlphaNumericOptimization();
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETakingTokenizerModelAndTokenizePos5()  throws Throwable  {
      Context[] contextArray0 = new Context[4];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "F";
      stringArray0[1] = "F";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray0, uniformPrior0);
      HashMap<String, String> hashMap0 = new HashMap<String, String>();
      Dictionary dictionary0 = new Dictionary();
      Pattern pattern0 = Pattern.compile("F");
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("F", dictionary0, true, pattern0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, hashMap0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      Span[] spanArray0 = tokenizerME0.tokenizePos("NP.*");
      assertEquals(1, spanArray0.length);
      assertTrue(tokenizerME0.useAlphaNumericOptimization());
  }

  @Test(timeout = 4000)
  public void testUseAlphaNumericOptimizationAndCreatesTokenizerMETaking2ArgumentsAndUseAlphaNumericOptimization()  throws Throwable  {
      TrainingParameters trainingParameters0 = new TrainingParameters();
      Factory factory0 = new Factory();
      Factory factory1 = new Factory();
      Context[] contextArray0 = new Context[7];
      int[] intArray0 = new int[5];
      intArray0[0] = (-2399);
      intArray0[1] = (-899);
      intArray0[2] = 0;
      intArray0[3] = 1606;
      intArray0[4] = 0;
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = (double) (-2399);
      doubleArray0[1] = (double) 1606;
      doubleArray0[2] = (double) 0;
      doubleArray0[3] = (double) 1606;
      doubleArray0[4] = (double) 0;
      doubleArray0[5] = (double) 1606;
      doubleArray0[6] = (double) 0;
      doubleArray0[7] = (double) 0;
      doubleArray0[8] = (double) 0;
      Context context0 = new Context(intArray0, doubleArray0);
      contextArray0[0] = context0;
      Context context1 = new Context(intArray0, doubleArray0);
      contextArray0[1] = context1;
      Context context2 = new Context(intArray0, doubleArray0);
      contextArray0[2] = context2;
      Context context3 = new Context(intArray0, doubleArray0);
      contextArray0[3] = context3;
      Context context4 = new Context(intArray0, doubleArray0);
      contextArray0[4] = context4;
      Context context5 = new Context(intArray0, doubleArray0);
      contextArray0[5] = context5;
      Context context6 = new Context(intArray0, doubleArray0);
      contextArray0[6] = context6;
      String[] stringArray0 = new String[2];
      stringArray0[0] = "F";
      stringArray0[1] = "_1wE";
      String[] stringArray1 = new String[2];
      stringArray1[0] = "F";
      stringArray1[1] = "F";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray1, uniformPrior0);
      DoccatFactory doccatFactory0 = new DoccatFactory((FeatureGenerator[]) null);
      Map<String, String> map0 = doccatFactory0.createManifestEntries();
      Dictionary dictionary0 = new Dictionary(true);
      Pattern pattern0 = Pattern.compile("_1wE");
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("_1wE", dictionary0, false, pattern0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, map0, tokenizerFactory0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory1);
      boolean boolean0 = tokenizerME0.useAlphaNumericOptimization();
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETaking2ArgumentsAndTokenizePos()  throws Throwable  {
      Context[] contextArray0 = new Context[10];
      String[] stringArray0 = new String[2];
      stringArray0[0] = "T";
      stringArray0[1] = "T";
      UniformPrior uniformPrior0 = new UniformPrior();
      GISModel gISModel0 = new GISModel(contextArray0, stringArray0, stringArray0, uniformPrior0);
      HashMap<String, String> hashMap0 = new HashMap<String, String>();
      Dictionary dictionary0 = new Dictionary();
      Pattern pattern0 = Factory.DEFAULT_ALPHANUMERIC;
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("T", dictionary0, true, pattern0);
      TokenizerModel tokenizerModel0 = new TokenizerModel(gISModel0, hashMap0, tokenizerFactory0);
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      Span[] spanArray0 = tokenizerME0.tokenizePos("T");
      assertEquals(1, spanArray0.length);
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerMETaking2ArgumentsThrowsNullPointerException()  throws Throwable  {
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = null;
      try {
        tokenizerME0 = new TokenizerME((TokenizerModel) null, factory0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.tokenize.TokenizerModel.getLanguage()\" because \"model\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETaking2Arguments()  throws Throwable  {
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      System.setCurrentTimeMillis(1245L);
      LinkedHashSet<TokenSample> linkedHashSet0 = new LinkedHashSet<TokenSample>();
      CollectionObjectStream<TokenSample> collectionObjectStream0 = new CollectionObjectStream<TokenSample>(linkedHashSet0);
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory();
      TrainingParameters trainingParameters0 = new TrainingParameters();
      collectionObjectStream0.reset();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = null;
      try {
        tokenizerME0 = new TokenizerME((TokenizerModel) null, factory0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.tokenize.TokenizerModel.getLanguage()\" because \"model\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerMETakingTokenizerModelThrowsNullPointerException()  throws Throwable  {
      TokenizerME tokenizerME0 = null;
      try {
        tokenizerME0 = new TokenizerME((TokenizerModel) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.tokenize.TokenizerModel.getFactory()\" because \"model\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainThrowsIOException()  throws Throwable  {
      Stack<TokenSample> stack0 = new Stack<TokenSample>();
      CollectionObjectStream<TokenSample> collectionObjectStream0 = new CollectionObjectStream<TokenSample>(stack0);
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory();
      tokenizerFactory0.getContextGenerator();
      TrainingParameters trainingParameters0 = TrainingParameters.defaultParams();
      try { 
        TokenizerME.train(collectionObjectStream0, tokenizerFactory0, trainingParameters0);
        fail("Expecting exception: IOException");
      
      } catch(IOException e) {
         //
         // Insufficient training data to create model.
         //
         verifyException("opennlp.tools.ml.model.AbstractDataIndexer", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainThrowsNullPointerException()  throws Throwable  {
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory();
      TrainingParameters trainingParameters0 = TrainingParameters.defaultParams();
      // Undeclared exception!
      try { 
        TokenizerME.train((ObjectStream<TokenSample>) null, tokenizerFactory0, trainingParameters0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.util.ObjectStream.read()\" because \"this.samples\" is null
         //
         verifyException("opennlp.tools.util.AbstractEventStream", e);
      }
  }
}
