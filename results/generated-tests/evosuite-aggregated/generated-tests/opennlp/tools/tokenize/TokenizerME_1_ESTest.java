/*
 * This file was automatically generated by UTestGen and EvoSuite
 * Sun Jul 13 21:42:39 GMT 2025
 */

package opennlp.tools.tokenize;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.IOException;
import java.util.LinkedHashSet;
import java.util.Stack;
import opennlp.tools.tokenize.TokenSample;
import opennlp.tools.tokenize.TokenizerFactory;
import opennlp.tools.tokenize.TokenizerME;
import opennlp.tools.tokenize.TokenizerModel;
import opennlp.tools.tokenize.lang.Factory;
import opennlp.tools.util.CollectionObjectStream;
import opennlp.tools.util.ObjectStream;
import opennlp.tools.util.TrainingParameters;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, separateClassLoader = true) 
public class TokenizerME_1_ESTest extends TokenizerME_1_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void testTrainThrowsIOException()  throws Throwable  {
      LinkedHashSet<TokenSample> linkedHashSet0 = new LinkedHashSet<TokenSample>();
      CollectionObjectStream<TokenSample> collectionObjectStream0 = new CollectionObjectStream<TokenSample>(linkedHashSet0);
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory();
      String[] stringArray0 = new String[9];
      linkedHashSet0.add((TokenSample) null);
      stringArray0[0] = "T";
      stringArray0[1] = "T";
      stringArray0[2] = "T";
      stringArray0[3] = "T";
      stringArray0[4] = "T";
      stringArray0[5] = "T";
      stringArray0[6] = "T";
      stringArray0[7] = "T";
      stringArray0[8] = "T";
      collectionObjectStream0.reset();
      TrainingParameters trainingParameters0 = TrainingParameters.setParams(stringArray0);
      try { 
        TokenizerME.train(collectionObjectStream0, tokenizerFactory0, trainingParameters0);
        fail("Expecting exception: IOException");
      
      } catch(IOException e) {
         //
         // Insufficient training data to create model.
         //
         verifyException("opennlp.tools.ml.model.AbstractDataIndexer", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerMETakingTokenizerModelThrowsNullPointerException()  throws Throwable  {
      TokenizerME tokenizerME0 = null;
      try {
        tokenizerME0 = new TokenizerME((TokenizerModel) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.tokenize.TokenizerModel.getFactory()\" because \"model\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETakingTokenizerModel()  throws Throwable  {
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = null;
      try {
        tokenizerME0 = new TokenizerME((TokenizerModel) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.tokenize.TokenizerModel.getFactory()\" because \"model\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerMETaking2ArgumentsThrowsNullPointerException()  throws Throwable  {
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = null;
      try {
        tokenizerME0 = new TokenizerME((TokenizerModel) null, factory0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.tokenize.TokenizerModel.getLanguage()\" because \"model\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrain()  throws Throwable  {
      Stack<TokenSample> stack0 = new Stack<TokenSample>();
      CollectionObjectStream<TokenSample> collectionObjectStream0 = new CollectionObjectStream<TokenSample>(stack0);
      collectionObjectStream0.reset();
      TrainingParameters trainingParameters0 = new TrainingParameters();
      // Undeclared exception!
      try { 
        TokenizerME.train(collectionObjectStream0, (TokenizerFactory) null, trainingParameters0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.tokenize.TokenizerFactory.isUseAlphaNumericOptimization()\" because \"factory\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainWithNull()  throws Throwable  {
      TrainingParameters trainingParameters0 = TrainingParameters.defaultParams();
      // Undeclared exception!
      try { 
        TokenizerME.train((ObjectStream<TokenSample>) null, (TokenizerFactory) null, trainingParameters0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.tokenize.TokenizerFactory.isUseAlphaNumericOptimization()\" because \"factory\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }
}
