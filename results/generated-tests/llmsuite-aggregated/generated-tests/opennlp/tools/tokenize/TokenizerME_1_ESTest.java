/*
 * This file was automatically generated by UTestGen and EvoSuite
 * Sun Jul 13 21:12:52 GMT 2025
 */

package opennlp.tools.tokenize;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.shaded.org.mockito.Mockito.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.IOException;
import java.io.Reader;
import java.io.StringReader;
import java.util.LinkedHashSet;
import java.util.LinkedList;
import java.util.Locale;
import java.util.Set;
import java.util.regex.Pattern;
import opennlp.tools.dictionary.Dictionary;
import opennlp.tools.ml.model.MaxentModel;
import opennlp.tools.tokenize.TokenContextGenerator;
import opennlp.tools.tokenize.TokenSample;
import opennlp.tools.tokenize.TokenizerFactory;
import opennlp.tools.tokenize.TokenizerME;
import opennlp.tools.tokenize.TokenizerModel;
import opennlp.tools.tokenize.lang.Factory;
import opennlp.tools.util.CollectionObjectStream;
import opennlp.tools.util.ObjectStream;
import opennlp.tools.util.Span;
import opennlp.tools.util.TrainingParameters;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.ViolatedAssumptionAnswer;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, separateClassLoader = true) 
public class TokenizerME_1_ESTest extends TokenizerME_1_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void testIsAcceptableAbbreviationReturningTrue()  throws Throwable  {
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = (-1250.61711);
      doubleArray0[1] = 0.0;
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      Pattern pattern0 = Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      StringReader stringReader0 = new StringReader("9f'&?My");
      Dictionary dictionary0 = Dictionary.parseOneEntryPerLine(stringReader0);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null, dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(true).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn("[a-zA-Z]+").when(tokenizerModel0).getLanguage();
      pattern0.asPredicate();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      tokenizerME0.isAcceptableAbbreviation("9f'&?My");
      tokenizerME0.tokenizePos("T");
      double[] doubleArray1 = tokenizerME0.getTokenProbabilities();
      assertArrayEquals(new double[] {1.0}, doubleArray1, 0.01);
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerMETakingStringThrowsIOException()  throws Throwable  {
      double[] doubleArray0 = new double[2];
      doubleArray0[1] = 0.0;
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      Pattern pattern0 = Pattern.compile("T");
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null, (Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(true).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn("T").when(tokenizerModel0).getLanguage();
      pattern0.asPredicate();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      tokenizerME0.isAcceptableAbbreviation("9f'&?My");
      tokenizerME0.tokenizePos("T");
      tokenizerME0.tokenizePos("T");
      TokenizerME tokenizerME1 = null;
      try {
        tokenizerME1 = new TokenizerME("9f'&?My");
        fail("Expecting exception: IOException");
      
      } catch(Throwable e) {
         //
         // Invalid model.
         //
         verifyException("opennlp.tools.util.DownloadUtil", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetTokenProbabilitiesAndIsAcceptableAbbreviation()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      Reader reader0 = Reader.nullReader();
      Dictionary dictionary0 = Dictionary.parseOneEntryPerLine(reader0);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null, dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(true).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn("9f'&?My").when(tokenizerModel0).getLanguage();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      tokenizerME0.isAcceptableAbbreviation("9f'&?My");
      double[] doubleArray0 = tokenizerME0.getTokenProbabilities();
      assertArrayEquals(new double[] {}, doubleArray0, 0.01);
  }

  @Test(timeout = 4000)
  public void testUseAlphaNumericOptimizationReturningFalse()  throws Throwable  {
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = (-1250.61711);
      doubleArray0[1] = 0.0;
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn("9f'&?My", "9f'&?My", "9f'&?My", "9f'&?My", "").when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(0, 0, 0, 1, 1).when(maxentModel0).getIndex(anyString());
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory();
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      tokenizerME0.tokenizePos("[a-zA-Z]+");
      LinkedList<TokenSample> linkedList0 = new LinkedList<TokenSample>();
      CollectionObjectStream<TokenSample> collectionObjectStream0 = new CollectionObjectStream<TokenSample>(linkedList0);
      TrainingParameters trainingParameters0 = new TrainingParameters();
      Span[] spanArray0 = tokenizerME0.tokenizePos("[a-zA-Z]+");
      assertEquals(1, spanArray0.length);
      
      boolean boolean0 = tokenizerME0.isAcceptableAbbreviation("[a-zA-Z]+");
      assertFalse(boolean0);
      
      boolean boolean1 = tokenizerME0.useAlphaNumericOptimization();
      assertTrue(boolean1 == boolean0);
  }

  @Test(timeout = 4000)
  public void testGetTokenProbabilitiesAndTokenizePos()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null, (Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(false).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn("R").when(tokenizerModel0).getLanguage();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      assertFalse(tokenizerME0.useAlphaNumericOptimization());
      
      Span[] spanArray0 = tokenizerME0.tokenizePos("R");
      assertEquals(1, spanArray0.length);
      
      double[] doubleArray0 = tokenizerME0.getTokenProbabilities();
      assertArrayEquals(new double[] {1.0}, doubleArray0, 0.01);
  }

  @Test(timeout = 4000)
  public void testTokenizePosThrowsArrayIndexOutOfBoundsException()  throws Throwable  {
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = 1437.1368414506217;
      doubleArray0[1] = 1437.1368414506217;
      doubleArray0[2] = 0.0;
      String string0 = "";
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn(doubleArray0).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn("").when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn((-5)).when(maxentModel0).getIndex(anyString());
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      String[] stringArray0 = new String[1];
      stringArray0[0] = "";
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      Pattern pattern0 = Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory();
      pattern0.asPredicate();
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      // Undeclared exception!
      try { 
        tokenizerME0.tokenizePos("[a-zA-Z]+");
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index -5 out of bounds for length 3
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETaking2ArgumentsAndTokenizePos()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null, (Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(true).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn("6cI").when(tokenizerModel0).getLanguage();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      Span[] spanArray0 = tokenizerME0.tokenizePos("6cI");
      assertEquals(1, spanArray0.length);
  }

  @Test(timeout = 4000)
  public void testTokenizePos()  throws Throwable  {
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = (-1250.61711);
      doubleArray0[1] = 0.0;
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      String[] stringArray0 = new String[4];
      stringArray0[0] = "pos";
      stringArray0[1] = "9f'&?My";
      stringArray0[2] = "\"";
      stringArray0[3] = "9f'&?My";
      String[] stringArray1 = new String[6];
      stringArray1[0] = "9f'&?My";
      stringArray1[1] = "\"";
      stringArray1[2] = "\"";
      stringArray1[3] = "\"";
      stringArray0[3] = "\"";
      stringArray1[5] = "\"";
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      Pattern pattern0 = Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      doReturn(pattern0).when(tokenizerFactory0).getAlphaNumericPattern();
      doReturn(tokenContextGenerator0).when(tokenizerFactory0).getContextGenerator();
      doReturn(true).when(tokenizerFactory0).isUseAlphaNumericOptimization();
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      tokenizerME0.tokenizePos("\"");
      assertTrue(tokenizerME0.useAlphaNumericOptimization());
      
      Span[] spanArray0 = tokenizerME0.tokenizePos("pos");
      assertEquals(1, spanArray0.length);
  }

  @Test(timeout = 4000)
  public void testTokenizePosThrowsNullPointerExceptionAndTokenizePos0()  throws Throwable  {
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = 1437.1368414506217;
      doubleArray0[1] = 1725.5287197822618;
      doubleArray0[2] = 0.0;
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((double[]) null).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn((String) null).when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(0).when(maxentModel0).getIndex(anyString());
      String[] stringArray0 = new String[1];
      stringArray0[0] = "";
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      doReturn((String[]) null).when(tokenContextGenerator0).getContext(anyString() , anyInt());
      Pattern pattern0 = Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      doReturn(pattern0).when(tokenizerFactory0).getAlphaNumericPattern();
      doReturn(tokenContextGenerator0).when(tokenizerFactory0).getContextGenerator();
      doReturn(true).when(tokenizerFactory0).isUseAlphaNumericOptimization();
      pattern0.asPredicate();
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      // Undeclared exception!
      try { 
        tokenizerME0.tokenizePos("[a-zA-Z]+");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot load from double array because \"probs\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETakingTokenizerModelAndTokenizePos0()  throws Throwable  {
      double[] doubleArray0 = new double[3];
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn("9f'&?My", "T", "T", "9f'&?My", "T").when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(0, 0, 0, 0, 0).when(maxentModel0).getIndex(anyString());
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory();
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      Span[] spanArray0 = tokenizerME0.tokenizePos("9f'&?My");
      assertEquals(5, spanArray0.length);
  }

  @Test(timeout = 4000)
  public void testUseAlphaNumericOptimization()  throws Throwable  {
      double[] doubleArray0 = new double[6];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = (-942.252);
      doubleArray0[2] = 0.0;
      doubleArray0[3] = 3636.0;
      doubleArray0[5] = (-942.252);
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      String[] stringArray0 = new String[8];
      stringArray0[0] = "HlZ8V";
      stringArray0[1] = "";
      stringArray0[2] = "";
      stringArray0[3] = "";
      stringArray0[4] = "";
      stringArray0[5] = "";
      stringArray0[6] = "";
      stringArray0[7] = "";
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null, (Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(true).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn("2L+8J1cyT").when(tokenizerModel0).getLanguage();
      TrainingParameters trainingParameters0 = new TrainingParameters();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      boolean boolean0 = tokenizerME0.useAlphaNumericOptimization();
      assertTrue(boolean0);
  }

  @Test(timeout = 4000)
  public void testGetTokenProbabilitiesReturningNonEmptyArray()  throws Throwable  {
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = (-1250.61711);
      doubleArray0[1] = 0.0;
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      Pattern pattern0 = Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null, (Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(false).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn((String) null).when(tokenizerModel0).getLanguage();
      pattern0.asPredicate();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      boolean boolean0 = tokenizerME0.isAcceptableAbbreviation("9f'&?My");
      assertFalse(boolean0);
      
      tokenizerME0.tokenizePos("T");
      double[] doubleArray1 = tokenizerME0.getTokenProbabilities();
      assertArrayEquals(new double[] {1.0}, doubleArray1, 0.01);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETaking2ArgumentsAndGetTokenProbabilities()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null, (Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(false).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn("R").when(tokenizerModel0).getLanguage();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      double[] doubleArray0 = tokenizerME0.getTokenProbabilities();
      assertArrayEquals(new double[] {}, doubleArray0, 0.01);
  }

  @Test(timeout = 4000)
  public void testGetTokenProbabilitiesReturningEmptyArray()  throws Throwable  {
      double[] doubleArray0 = new double[6];
      doubleArray0[1] = (-942.252);
      doubleArray0[2] = 0.0;
      doubleArray0[3] = 3636.0;
      doubleArray0[5] = (-942.252);
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      String[] stringArray0 = new String[8];
      stringArray0[0] = "HlZ8V";
      stringArray0[1] = "";
      stringArray0[2] = "";
      stringArray0[3] = "";
      stringArray0[4] = "";
      stringArray0[5] = "";
      stringArray0[6] = "";
      stringArray0[7] = "";
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null, (Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(true).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn("2L+8J1cyT").when(tokenizerModel0).getLanguage();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      tokenizerME0.isAcceptableAbbreviation("");
      Span[] spanArray0 = tokenizerME0.tokenizePos("");
      tokenizerME0.getTokenProbabilities();
      Span[] spanArray1 = tokenizerME0.tokenizePos("");
      assertNotSame(spanArray1, spanArray0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETakingTokenizerModelAndTokenizePos1()  throws Throwable  {
      double[] doubleArray0 = new double[4];
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn("9f's?My", "9f's?My", "9f's?My", "9f's?My", "9f's?My").when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(0, 0, 0, 0, 0).when(maxentModel0).getIndex(anyString());
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory();
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      Span[] spanArray0 = tokenizerME0.tokenizePos("9f's?My");
      assertEquals(1, spanArray0.length);
  }

  @Test(timeout = 4000)
  public void testTokenizePosThrowsNullPointerExceptionAndTokenizePosReturningNonEmptyArray()  throws Throwable  {
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = 1437.1368414506217;
      doubleArray0[1] = 1725.5287197822618;
      doubleArray0[2] = 0.0;
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((Object) doubleArray0, (Object) null).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn("", (String) null).when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(1, 0).when(maxentModel0).getIndex(anyString());
      String[] stringArray0 = new String[1];
      stringArray0[0] = "";
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      doReturn((Object) stringArray0, (Object) null).when(tokenContextGenerator0).getContext(anyString() , anyInt());
      Pattern pattern0 = Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      doReturn(pattern0).when(tokenizerFactory0).getAlphaNumericPattern();
      doReturn(tokenContextGenerator0).when(tokenizerFactory0).getContextGenerator();
      doReturn(true).when(tokenizerFactory0).isUseAlphaNumericOptimization();
      pattern0.asPredicate();
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      // Undeclared exception!
      try { 
        tokenizerME0.tokenizePos("[a-zA-Z]+");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot load from double array because \"probs\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testTokenizePosReturningEmptyArray()  throws Throwable  {
      double[] doubleArray0 = new double[6];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = (-942.252);
      doubleArray0[2] = 0.0;
      doubleArray0[3] = 3636.0;
      doubleArray0[4] = 1.0E-4;
      doubleArray0[5] = 0.0;
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      String[] stringArray0 = new String[8];
      stringArray0[0] = "HlZ8V";
      stringArray0[1] = "";
      stringArray0[2] = "";
      stringArray0[3] = "";
      stringArray0[4] = "";
      stringArray0[5] = "";
      stringArray0[6] = "";
      stringArray0[7] = "";
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null, (Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(false).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn((String) null).when(tokenizerModel0).getLanguage();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      tokenizerME0.isAcceptableAbbreviation("");
      Span[] spanArray0 = tokenizerME0.tokenizePos("");
      assertEquals(0, spanArray0.length);
  }

  @Test(timeout = 4000)
  public void testIsAcceptableAbbreviation()  throws Throwable  {
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = (-1250.61711);
      doubleArray0[1] = 0.0;
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      Pattern pattern0 = Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      Reader reader0 = Reader.nullReader();
      Dictionary dictionary0 = Dictionary.parseOneEntryPerLine(reader0);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null, dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(true).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn("9f'&?My").when(tokenizerModel0).getLanguage();
      pattern0.asPredicate();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      tokenizerME0.isAcceptableAbbreviation("9f'&?My");
      tokenizerME0.tokenizePos("T");
      double[] doubleArray1 = tokenizerME0.getTokenProbabilities();
      assertArrayEquals(new double[] {1.0}, doubleArray1, 0.01);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETaking2ArgumentsAndIsAcceptableAbbreviation()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null, (Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(true).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn("R").when(tokenizerModel0).getLanguage();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      boolean boolean0 = tokenizerME0.isAcceptableAbbreviation("R");
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void testTokenizePosThrowsNullPointerExceptionAndCreatesTokenizerMETaking2Arguments0()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((double[]) null).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn((String) null).when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(0).when(maxentModel0).getIndex(anyString());
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null, (Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(true).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn("9-]3,-P1l-Mv9").when(tokenizerModel0).getLanguage();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      // Undeclared exception!
      try { 
        tokenizerME0.tokenizePos("9-]3,-P1l-Mv9");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot load from double array because \"probs\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testTokenizePosThrowsNullPointerExceptionAndTokenizePos1()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((double[]) null).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn((String) null).when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(0).when(maxentModel0).getIndex(anyString());
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      doReturn((String[]) null).when(tokenContextGenerator0).getContext(anyString() , anyInt());
      Pattern pattern0 = Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      doReturn(pattern0).when(tokenizerFactory0).getAlphaNumericPattern();
      doReturn(tokenContextGenerator0).when(tokenizerFactory0).getContextGenerator();
      doReturn(true).when(tokenizerFactory0).isUseAlphaNumericOptimization();
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      // Undeclared exception!
      try { 
        tokenizerME0.tokenizePos("[a-zA-Z]+");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot load from double array because \"probs\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testTokenizePosThrowsNullPointerExceptionAndCreatesTokenizerMETaking2Arguments1()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((double[]) null).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn((String) null).when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(0).when(maxentModel0).getIndex(anyString());
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null, (Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(false).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn("nG").when(tokenizerModel0).getLanguage();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      // Undeclared exception!
      try { 
        tokenizerME0.tokenizePos("nG");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot load from double array because \"probs\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETakingTokenizerModel()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      doReturn((Pattern) null).when(tokenizerFactory0).getAlphaNumericPattern();
      doReturn((TokenContextGenerator) null).when(tokenizerFactory0).getContextGenerator();
      doReturn(false).when(tokenizerFactory0).isUseAlphaNumericOptimization();
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn((MaxentModel) null).when(tokenizerModel0).getMaxentModel();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      assertFalse(tokenizerME0.useAlphaNumericOptimization());
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerMETakingTokenizerModelThrowsNullPointerException0()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((TokenizerFactory) null).when(tokenizerModel0).getFactory();
      TokenizerME tokenizerME0 = null;
      try {
        tokenizerME0 = new TokenizerME(tokenizerModel0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.tokenize.TokenizerFactory.getAlphaNumericPattern()\" because \"factory\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerMETaking2ArgumentsThrowsNullPointerException()  throws Throwable  {
      TokenizerME tokenizerME0 = null;
      try {
        tokenizerME0 = new TokenizerME((TokenizerModel) null, (Factory) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.tokenize.TokenizerModel.getLanguage()\" because \"model\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETaking2Arguments()  throws Throwable  {
      Factory factory0 = new Factory();
      String string0 = "";
      Locale.IsoCountryCode locale_IsoCountryCode0 = Locale.IsoCountryCode.PART1_ALPHA3;
      Set<String> set0 = Locale.getISOCountries(locale_IsoCountryCode0);
      factory0.createTokenContextGenerator("", set0);
      TokenizerME tokenizerME0 = null;
      try {
        tokenizerME0 = new TokenizerME((TokenizerModel) null, factory0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.tokenize.TokenizerModel.getLanguage()\" because \"model\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerMETakingTokenizerModelThrowsNullPointerException1()  throws Throwable  {
      TokenizerME tokenizerME0 = null;
      try {
        tokenizerME0 = new TokenizerME((TokenizerModel) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.tokenize.TokenizerModel.getFactory()\" because \"model\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainThrowsIOException()  throws Throwable  {
      LinkedHashSet<TokenSample> linkedHashSet0 = new LinkedHashSet<TokenSample>();
      CollectionObjectStream<TokenSample> collectionObjectStream0 = new CollectionObjectStream<TokenSample>(linkedHashSet0);
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "";
      stringArray0[1] = "";
      stringArray0[2] = "samples must not be null!";
      stringArray0[3] = "T";
      stringArray0[4] = "";
      TrainingParameters trainingParameters0 = TrainingParameters.setParams(stringArray0);
      try { 
        TokenizerME.train(collectionObjectStream0, tokenizerFactory0, trainingParameters0);
        fail("Expecting exception: IOException");
      
      } catch(IOException e) {
         //
         // Insufficient training data to create model.
         //
         verifyException("opennlp.tools.ml.model.AbstractDataIndexer", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainThrowsNullPointerException()  throws Throwable  {
      TrainingParameters trainingParameters0 = new TrainingParameters();
      // Undeclared exception!
      try { 
        TokenizerME.train((ObjectStream<TokenSample>) null, (TokenizerFactory) null, trainingParameters0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.tokenize.TokenizerFactory.isUseAlphaNumericOptimization()\" because \"factory\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }
}
