/*
 * This file was automatically generated by UTestGen and EvoSuite
 * Sun Jul 13 21:14:49 GMT 2025
 */

package opennlp.tools.tokenize;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.shaded.org.mockito.Mockito.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.IOException;
import java.io.Reader;
import java.util.LinkedHashSet;
import java.util.regex.Pattern;
import opennlp.tools.dictionary.Dictionary;
import opennlp.tools.ml.model.MaxentModel;
import opennlp.tools.tokenize.TokenContextGenerator;
import opennlp.tools.tokenize.TokenSample;
import opennlp.tools.tokenize.TokenizerFactory;
import opennlp.tools.tokenize.TokenizerME;
import opennlp.tools.tokenize.TokenizerModel;
import opennlp.tools.tokenize.lang.Factory;
import opennlp.tools.util.CollectionObjectStream;
import opennlp.tools.util.ObjectStream;
import opennlp.tools.util.Span;
import opennlp.tools.util.StringList;
import opennlp.tools.util.TrainingParameters;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.System;
import org.evosuite.runtime.ViolatedAssumptionAnswer;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, separateClassLoader = true) 
public class TokenizerME_4_ESTest extends TokenizerME_4_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETakingTokenizerModelAndTokenizePos0()  throws Throwable  {
      double[] doubleArray0 = new double[8];
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn("Svg?}Q7&?B", "T", "T", "Svg?}Q7&?B", "T").when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(0, 0, 0, 0, 0).when(maxentModel0).getIndex(anyString());
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory();
      Dictionary dictionary0 = new Dictionary();
      StringList stringList0 = new StringList("Svg?}Q7&?B");
      dictionary0.put(stringList0);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      Span[] spanArray0 = tokenizerME0.tokenizePos("Svg?}Q7&?B");
      assertEquals(7, spanArray0.length);
  }

  @Test(timeout = 4000)
  public void testIsAcceptableAbbreviationReturningTrue()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      Dictionary dictionary0 = new Dictionary(true);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0, dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(true).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn("p1=bok").when(tokenizerModel0).getLanguage();
      Factory factory0 = new Factory();
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "p1=bok");
      StringList stringList0 = new StringList("p1=bok");
      dictionary0.put(stringList0);
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      tokenizerME0.isAcceptableAbbreviation("p1=bok");
      double[] doubleArray0 = tokenizerME0.getTokenProbabilities();
      assertEquals(0, doubleArray0.length);
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerMETakingStringThrowsIOException()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      Dictionary dictionary0 = new Dictionary(false);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0, dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(false).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn(":r [xNkr]*T`").when(tokenizerModel0).getLanguage();
      Factory factory0 = new Factory();
      String string0 = "m9^`];2K04W";
      Pattern.compile(":r [xNkr]*T`");
      Factory factory1 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      TokenizerME tokenizerME1 = null;
      try {
        tokenizerME1 = new TokenizerME("^r+jp}VM.%c+u{ u.Yq");
        fail("Expecting exception: IOException");
      
      } catch(Throwable e) {
         //
         // Invalid model.
         //
         verifyException("opennlp.tools.util.DownloadUtil", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerMETaking2ArgumentsThrowsNullPointerException0()  throws Throwable  {
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = 1.0;
      doubleArray0[1] = 1.0;
      doubleArray0[1] = 0.0;
      doubleArray0[3] = 139.23415894052536;
      doubleArray0[4] = 2145.5062732;
      String string0 = "useTokenEnd is a mandatory property!";
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((Object) doubleArray0, (Object) doubleArray0).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn("tGd-T[iAOFa{?L", "tGd-T[iAOFa{?L").when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(4, 4).when(maxentModel0).getIndex(anyString());
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(tokenContextGenerator0).getContext(anyString() , anyInt());
      Pattern pattern0 = Pattern.compile("[a7M-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      doReturn(pattern0).when(tokenizerFactory0).getAlphaNumericPattern();
      doReturn(tokenContextGenerator0).when(tokenizerFactory0).getContextGenerator();
      doReturn(true).when(tokenizerFactory0).isUseAlphaNumericOptimization();
      Dictionary dictionary0 = new Dictionary(false);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      pattern0.asPredicate();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      tokenizerME0.tokenizePos("8@L");
      tokenizerME0.tokenizePos("MAXENT_QN");
      Factory factory0 = new Factory();
      TokenizerME tokenizerME1 = null;
      try {
        tokenizerME1 = new TokenizerME((TokenizerModel) null, factory0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.tokenize.TokenizerModel.getLanguage()\" because \"model\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETaking2ArgumentsAndTokenizePos0()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      Dictionary dictionary0 = new Dictionary(true);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0, dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(true).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn("r [uhKrYT`").when(tokenizerModel0).getLanguage();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      assertTrue(tokenizerME0.useAlphaNumericOptimization());
      
      Span[] spanArray0 = tokenizerME0.tokenizePos("jVy");
      assertEquals(1, spanArray0.length);
  }

  @Test(timeout = 4000)
  public void testTokenizePosThrowsNullPointerExceptionAndTokenizePos0()  throws Throwable  {
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = 4056.28773226;
      doubleArray0[2] = 0.05;
      doubleArray0[3] = (-58.9);
      String string0 = "";
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((double[]) null).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn((String) null).when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(0).when(maxentModel0).getIndex(anyString());
      String[] stringArray0 = new String[6];
      stringArray0[0] = "T";
      stringArray0[1] = "";
      stringArray0[2] = "";
      stringArray0[3] = "";
      stringArray0[4] = "";
      stringArray0[5] = "";
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      doReturn((String[]) null).when(tokenContextGenerator0).getContext(anyString() , anyInt());
      Pattern pattern0 = Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      doReturn(pattern0).when(tokenizerFactory0).getAlphaNumericPattern();
      doReturn(tokenContextGenerator0).when(tokenizerFactory0).getContextGenerator();
      doReturn(true).when(tokenizerFactory0).isUseAlphaNumericOptimization();
      Dictionary dictionary0 = new Dictionary(false);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      pattern0.asPredicate();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      tokenizerME0.keepNewLines = false;
      // Undeclared exception!
      try { 
        tokenizerME0.tokenizePos("[a-zA-Z]+");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot load from double array because \"probs\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETakingTokenizerModelAndTokenizePos1()  throws Throwable  {
      double[] doubleArray0 = new double[2];
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn("Svg?}Q7&?B", "T", "T", "Svg?}Q7&?B", "T").when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(0, 0, 0, 0, 0).when(maxentModel0).getIndex(anyString());
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory();
      Dictionary dictionary0 = new Dictionary();
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      Span[] spanArray0 = tokenizerME0.tokenizePos("Svg?}Q7&?B");
      assertEquals(8, spanArray0.length);
  }

  @Test(timeout = 4000)
  public void testUseAlphaNumericOptimizationReturningFalse()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      Dictionary dictionary0 = new Dictionary(false);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0, dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(false).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn(":r [xNkr]*T`").when(tokenizerModel0).getLanguage();
      dictionary0.spliterator();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      boolean boolean0 = tokenizerME0.useAlphaNumericOptimization();
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETaking2Arguments()  throws Throwable  {
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = 4779.859126080777;
      doubleArray0[2] = 45.043439;
      doubleArray0[3] = 0.0;
      doubleArray0[4] = 1538.4531338;
      doubleArray0[5] = (-1399.9744);
      doubleArray0[6] = 1.2;
      doubleArray0[7] = 0.0;
      doubleArray0[8] = 0.0;
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      String[] stringArray0 = new String[4];
      stringArray0[0] = ":r [xNkr]*T`";
      stringArray0[1] = ":r [xNkr]*T`";
      stringArray0[2] = ":r [xNkr]*T`";
      stringArray0[3] = ":r [xNkr]*T`";
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      Dictionary dictionary0 = new Dictionary(false);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0, (Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(false).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn((String) null).when(tokenizerModel0).getLanguage();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      assertFalse(tokenizerME0.useAlphaNumericOptimization());
  }

  @Test(timeout = 4000)
  public void testIsAcceptableAbbreviationAndCreatesTokenizerMETaking2Arguments()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      Dictionary dictionary0 = new Dictionary(false);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0, dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(false).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn(":r [xNkr]*T`").when(tokenizerModel0).getLanguage();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      assertFalse(tokenizerME0.useAlphaNumericOptimization());
      
      boolean boolean0 = tokenizerME0.isAcceptableAbbreviation(":r [xNkr]*T`");
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void testGetTokenProbabilitiesAndCreatesTokenizerMETaking2Arguments()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      Dictionary dictionary0 = new Dictionary();
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0, dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(false).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn("r [xNkr*T`").when(tokenizerModel0).getLanguage();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      tokenizerME0.tokenizePos("r");
      double[] doubleArray0 = tokenizerME0.getTokenProbabilities();
      assertArrayEquals(new double[] {1.0}, doubleArray0, 0.01);
  }

  @Test(timeout = 4000)
  public void testGetTokenProbabilitiesAndGetTokenProbabilities()  throws Throwable  {
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = 4056.28773226;
      doubleArray0[2] = 0.05;
      doubleArray0[3] = (-58.9);
      double[] doubleArray1 = new double[4];
      doubleArray1[0] = 1396.0;
      doubleArray1[1] = 4056.28773226;
      doubleArray1[2] = (-979.0);
      doubleArray1[3] = (-58.9);
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray1, (Object) doubleArray1, (Object) doubleArray0).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn("", "A", "", "", "/opennlp/tools/postag/pos-default-features.xml").when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(0, 0, 0, 0, 1).when(maxentModel0).getIndex(anyString());
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null, (Object) null, (Object) null).when(tokenContextGenerator0).getContext(anyString() , anyInt());
      Pattern pattern0 = Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      doReturn(pattern0).when(tokenizerFactory0).getAlphaNumericPattern();
      doReturn(tokenContextGenerator0).when(tokenizerFactory0).getContextGenerator();
      doReturn(true).when(tokenizerFactory0).isUseAlphaNumericOptimization();
      Dictionary dictionary0 = new Dictionary(false);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      pattern0.asPredicate();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      tokenizerME0.tokenizePos("A");
      System.setCurrentTimeMillis(0L);
      Span[] spanArray0 = tokenizerME0.tokenizePos("[a-zA-Z]+");
      assertEquals(1, spanArray0.length);
      
      tokenizerME0.isAcceptableAbbreviation("A");
      assertTrue(tokenizerME0.useAlphaNumericOptimization());
      
      tokenizerME0.tokenizePos("A");
      double[] doubleArray2 = tokenizerME0.getTokenProbabilities();
      assertArrayEquals(new double[] {1.0}, doubleArray2, 0.01);
      assertTrue(tokenizerME0.useAlphaNumericOptimization());
  }

  @Test(timeout = 4000)
  public void testIsAcceptableAbbreviationAndIsAcceptableAbbreviation()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      doReturn((Pattern) null).when(tokenizerFactory0).getAlphaNumericPattern();
      doReturn((TokenContextGenerator) null).when(tokenizerFactory0).getContextGenerator();
      doReturn(false).when(tokenizerFactory0).isUseAlphaNumericOptimization();
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((Dictionary) null).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn((MaxentModel) null).when(tokenizerModel0).getMaxentModel();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      assertFalse(tokenizerME0.useAlphaNumericOptimization());
      
      double[] doubleArray0 = tokenizerME0.getTokenProbabilities();
      assertEquals(0, doubleArray0.length);
      
      boolean boolean0 = tokenizerME0.isAcceptableAbbreviation("[a-zA-Z]+");
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void testTokenizePosReturningEmptyArray()  throws Throwable  {
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = 4056.28773226;
      doubleArray0[2] = 0.05;
      doubleArray0[3] = (-58.9);
      double[] doubleArray1 = new double[4];
      doubleArray1[0] = 1396.0;
      doubleArray1[1] = 4056.28773226;
      doubleArray1[2] = (-979.0);
      doubleArray1[3] = (-58.9);
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      Pattern pattern0 = Pattern.compile("8");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      doReturn(pattern0).when(tokenizerFactory0).getAlphaNumericPattern();
      doReturn(tokenContextGenerator0).when(tokenizerFactory0).getContextGenerator();
      doReturn(true).when(tokenizerFactory0).isUseAlphaNumericOptimization();
      Dictionary dictionary0 = new Dictionary(false);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      pattern0.asPredicate();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      tokenizerME0.keepNewLines = true;
      tokenizerME0.tokenizePos("");
      System.setCurrentTimeMillis(1L);
  }

  @Test(timeout = 4000)
  public void testUseAlphaNumericOptimization()  throws Throwable  {
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = 4056.28773226;
      doubleArray0[2] = 0.05;
      doubleArray0[3] = (-58.9);
      double[] doubleArray1 = new double[4];
      doubleArray1[0] = 1396.0;
      doubleArray1[1] = 4056.28773226;
      doubleArray1[2] = (-979.0);
      doubleArray1[3] = (-58.9);
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray1, (Object) doubleArray1, (Object) doubleArray0).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn("", "A", "", "", "/opennlp/tools/postag/pos-default-features.xml").when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(0, 0, 0, 0, 1).when(maxentModel0).getIndex(anyString());
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null, (Object) null, (Object) null).when(tokenContextGenerator0).getContext(anyString() , anyInt());
      Pattern pattern0 = Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      doReturn(pattern0).when(tokenizerFactory0).getAlphaNumericPattern();
      doReturn(tokenContextGenerator0).when(tokenizerFactory0).getContextGenerator();
      doReturn(true).when(tokenizerFactory0).isUseAlphaNumericOptimization();
      Dictionary dictionary0 = new Dictionary(false);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      pattern0.asPredicate();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      tokenizerME0.keepNewLines = false;
      Span[] spanArray0 = tokenizerME0.tokenizePos("[a-zA-Z]+");
      assertEquals(1, spanArray0.length);
      
      System.setCurrentTimeMillis(1L);
      boolean boolean0 = tokenizerME0.useAlphaNumericOptimization();
      assertTrue(boolean0);
  }

  @Test(timeout = 4000)
  public void testTokenizePos0()  throws Throwable  {
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = 1.0;
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      String[] stringArray0 = new String[3];
      stringArray0[0] = null;
      stringArray0[1] = null;
      stringArray0[2] = null;
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      Pattern pattern0 = Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      doReturn(pattern0).when(tokenizerFactory0).getAlphaNumericPattern();
      doReturn(tokenContextGenerator0).when(tokenizerFactory0).getContextGenerator();
      doReturn(true).when(tokenizerFactory0).isUseAlphaNumericOptimization();
      Dictionary dictionary0 = new Dictionary(false);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      pattern0.asPredicate();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      Span[] spanArray0 = tokenizerME0.tokenizePos("F");
      assertEquals(1, spanArray0.length);
  }

  @Test(timeout = 4000)
  public void testTokenizePosThrowsNullPointerExceptionAndTokenizePosReturningNonEmptyArray()  throws Throwable  {
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = 0.0;
      doubleArray0[1] = 4056.28773226;
      doubleArray0[2] = 0.05;
      doubleArray0[3] = (-58.9);
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((Object) doubleArray0, (Object) null).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn("", (String) null).when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(0, 0).when(maxentModel0).getIndex(anyString());
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(tokenContextGenerator0).getContext(anyString() , anyInt());
      Pattern pattern0 = Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      doReturn(pattern0).when(tokenizerFactory0).getAlphaNumericPattern();
      doReturn(tokenContextGenerator0).when(tokenizerFactory0).getContextGenerator();
      doReturn(true).when(tokenizerFactory0).isUseAlphaNumericOptimization();
      Dictionary dictionary0 = new Dictionary(false);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      pattern0.asPredicate();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      tokenizerME0.keepNewLines = false;
      // Undeclared exception!
      try { 
        tokenizerME0.tokenizePos("[a-zA-Z]+");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot load from double array because \"probs\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testTokenizePos1()  throws Throwable  {
      double[] doubleArray0 = new double[8];
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn("Svg?}Q7&?B", "T", "T", "Svg?}Q7&?B", "T").when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(0, 0, 0, 0, 0).when(maxentModel0).getIndex(anyString());
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory();
      tokenizerFactory0.isUseAlphaNumericOptimization();
      Dictionary dictionary0 = new Dictionary();
      StringList stringList0 = new StringList("Svg?}Q7&?B");
      dictionary0.put(stringList0);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      Span[] spanArray0 = tokenizerME0.tokenizePos("Svg?}Q7&?B");
      assertEquals(7, spanArray0.length);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETakingTokenizerModelAndTokenizePos2()  throws Throwable  {
      double[] doubleArray0 = new double[2];
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn("Svg?}Q7&?B", "Svg?}Q7&?B", "Svg?}Q7&?B", "Svg?}Q7&?B", "Svg?}Q7&?B").when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(0, 0, 0, 0, 0).when(maxentModel0).getIndex(anyString());
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory();
      Dictionary dictionary0 = new Dictionary();
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      Span[] spanArray0 = tokenizerME0.tokenizePos("Svg?}Q7&?B");
      assertEquals(1, spanArray0.length);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETaking2ArgumentsAndTokenizePos1()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      Dictionary dictionary0 = new Dictionary(false);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0, dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(false).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn("r [xNkr]*T`").when(tokenizerModel0).getLanguage();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      Span[] spanArray0 = tokenizerME0.tokenizePos(")");
      assertEquals(1, spanArray0.length);
  }

  @Test(timeout = 4000)
  public void testTokenizePosThrowsNullPointerExceptionAndCreatesTokenizerMETaking2Arguments0()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((double[]) null).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn((String) null).when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(0).when(maxentModel0).getIndex(anyString());
      Dictionary dictionary0 = new Dictionary();
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0, dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(true).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn("G,#wW]wA>F}I$p~g/96").when(tokenizerModel0).getLanguage();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      // Undeclared exception!
      try { 
        tokenizerME0.tokenizePos("G,#wW]wA>F}I$p~g/96");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot load from double array because \"probs\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testTokenizePosThrowsNullPointerExceptionAndTokenizePos1()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((double[]) null).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn((String) null).when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(0).when(maxentModel0).getIndex(anyString());
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      doReturn((String[]) null).when(tokenContextGenerator0).getContext(anyString() , anyInt());
      Pattern pattern0 = Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      doReturn(pattern0).when(tokenizerFactory0).getAlphaNumericPattern();
      doReturn(tokenContextGenerator0).when(tokenizerFactory0).getContextGenerator();
      doReturn(true).when(tokenizerFactory0).isUseAlphaNumericOptimization();
      Dictionary dictionary0 = new Dictionary(false);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(tokenizerFactory0).when(tokenizerModel0).getFactory();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      pattern0.asPredicate();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0);
      // Undeclared exception!
      try { 
        tokenizerME0.tokenizePos("[a-zA-Z]+");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot load from double array because \"probs\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testTokenizePosThrowsNullPointerExceptionAndCreatesTokenizerMETaking2Arguments1()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      doReturn((double[]) null).when(maxentModel0).eval(any(java.lang.String[].class));
      doReturn((String) null).when(maxentModel0).getBestOutcome(any(double[].class));
      doReturn(0).when(maxentModel0).getIndex(anyString());
      Dictionary dictionary0 = new Dictionary(false);
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn(dictionary0, dictionary0).when(tokenizerModel0).getAbbreviations();
      doReturn(maxentModel0).when(tokenizerModel0).getMaxentModel();
      doReturn(false).when(tokenizerModel0).useAlphaNumericOptimization();
      doReturn("r [xNkr]*T`").when(tokenizerModel0).getLanguage();
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = new TokenizerME(tokenizerModel0, factory0);
      // Undeclared exception!
      try { 
        tokenizerME0.tokenizePos("r [xNkr]*T`");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot load from double array because \"probs\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerMETakingTokenizerModelThrowsNullPointerException0()  throws Throwable  {
      MaxentModel maxentModel0 = mock(MaxentModel.class, new ViolatedAssumptionAnswer());
      TokenContextGenerator tokenContextGenerator0 = mock(TokenContextGenerator.class, new ViolatedAssumptionAnswer());
      Pattern.compile("[a-zA-Z]+");
      TokenizerFactory tokenizerFactory0 = mock(TokenizerFactory.class, new ViolatedAssumptionAnswer());
      TokenizerModel tokenizerModel0 = mock(TokenizerModel.class, new ViolatedAssumptionAnswer());
      doReturn((TokenizerFactory) null).when(tokenizerModel0).getFactory();
      TokenizerME tokenizerME0 = null;
      try {
        tokenizerME0 = new TokenizerME(tokenizerModel0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.tokenize.TokenizerFactory.getAlphaNumericPattern()\" because \"factory\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerMETaking2ArgumentsThrowsNullPointerException1()  throws Throwable  {
      Factory factory0 = new Factory();
      TokenizerME tokenizerME0 = null;
      try {
        tokenizerME0 = new TokenizerME((TokenizerModel) null, factory0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.tokenize.TokenizerModel.getLanguage()\" because \"model\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerMETaking2ArgumentsAndFailsToCreateTokenizerMETaking2ArgumentsThrowsNullPointerException()  throws Throwable  {
      TokenizerME tokenizerME0 = null;
      try {
        tokenizerME0 = new TokenizerME((TokenizerModel) null, (Factory) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.tokenize.TokenizerModel.getLanguage()\" because \"model\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainThrowsNullPointerException0()  throws Throwable  {
      Reader reader0 = Reader.nullReader();
      Dictionary dictionary0 = Dictionary.parseOneEntryPerLine(reader0);
      Factory factory0 = new Factory();
      Pattern pattern0 = factory0.getAlphanumeric("=MzcHo+jaL?!0");
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory(";MtoL).", dictionary0, true, pattern0);
      TrainingParameters trainingParameters0 = TrainingParameters.defaultParams();
      // Undeclared exception!
      try { 
        TokenizerME.train((ObjectStream<TokenSample>) null, tokenizerFactory0, trainingParameters0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.util.ObjectStream.read()\" because \"this.samples\" is null
         //
         verifyException("opennlp.tools.util.AbstractEventStream", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerMETakingTokenizerModelThrowsNullPointerException1()  throws Throwable  {
      TokenizerME tokenizerME0 = null;
      try {
        tokenizerME0 = new TokenizerME((TokenizerModel) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.tokenize.TokenizerModel.getFactory()\" because \"model\" is null
         //
         verifyException("opennlp.tools.tokenize.TokenizerME", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainThrowsNullPointerExceptionAndTrain()  throws Throwable  {
      LinkedHashSet<TokenSample> linkedHashSet0 = new LinkedHashSet<TokenSample>();
      CollectionObjectStream<TokenSample> collectionObjectStream0 = new CollectionObjectStream<TokenSample>(linkedHashSet0);
      String string0 = "";
      Dictionary dictionary0 = new Dictionary(false);
      Pattern pattern0 = Pattern.compile("", 44);
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory("", dictionary0, true, pattern0);
      TrainingParameters trainingParameters0 = null;
      // Undeclared exception!
      try { 
        TokenizerME.train(collectionObjectStream0, tokenizerFactory0, (TrainingParameters) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.util.TrainingParameters.getStringParameter(String, String)\" because \"trainParams\" is null
         //
         verifyException("opennlp.tools.ml.TrainerFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainThrowsNullPointerException1()  throws Throwable  {
      TokenizerFactory tokenizerFactory0 = new TokenizerFactory();
      TrainingParameters trainingParameters0 = new TrainingParameters();
      // Undeclared exception!
      try { 
        TokenizerME.train((ObjectStream<TokenSample>) null, tokenizerFactory0, trainingParameters0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"opennlp.tools.util.ObjectStream.read()\" because \"this.samples\" is null
         //
         verifyException("opennlp.tools.util.AbstractEventStream", e);
      }
  }
}
