/*
 * This file was automatically generated by UTestGen and EvoSuite
 * Wed Apr 16 22:51:35 GMT 2025
 */

package edu.stanford.nlp.parser.lexparser;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.shaded.org.mockito.Mockito.*;
import static org.evosuite.runtime.EvoAssertions.*;
import edu.stanford.nlp.ie.ClassifierCombiner;
import edu.stanford.nlp.ie.NERClassifierCombiner;
import edu.stanford.nlp.ie.PresetSequenceClassifier;
import edu.stanford.nlp.io.ExtensionFileFilter;
import edu.stanford.nlp.io.NumberRangeFileFilter;
import edu.stanford.nlp.io.RegExFileFilter;
import edu.stanford.nlp.ling.BasicDocument;
import edu.stanford.nlp.ling.CategoryWordTag;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.ling.HasWord;
import edu.stanford.nlp.ling.IndexedWord;
import edu.stanford.nlp.ling.LabeledWord;
import edu.stanford.nlp.ling.TaggedWord;
import edu.stanford.nlp.ling.Word;
import edu.stanford.nlp.parser.common.ParserQuery;
import edu.stanford.nlp.parser.lexparser.BinaryGrammar;
import edu.stanford.nlp.parser.lexparser.DependencyGrammar;
import edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor;
import edu.stanford.nlp.parser.lexparser.GrammarCompactor;
import edu.stanford.nlp.parser.lexparser.HebrewTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.LexicalizedParser;
import edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery;
import edu.stanford.nlp.parser.lexparser.Lexicon;
import edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar;
import edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.Options;
import edu.stanford.nlp.parser.lexparser.OutsideRuleFilter;
import edu.stanford.nlp.parser.lexparser.SpanishUnknownWordModelTrainer;
import edu.stanford.nlp.parser.lexparser.TestOptions;
import edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer;
import edu.stanford.nlp.parser.lexparser.TreebankLangParserParams;
import edu.stanford.nlp.parser.lexparser.UnaryGrammar;
import edu.stanford.nlp.parser.lexparser.UnknownWordModel;
import edu.stanford.nlp.parser.metrics.Eval;
import edu.stanford.nlp.parser.metrics.ParserQueryEval;
import edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions;
import edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser;
import edu.stanford.nlp.process.AmericanizeFunction;
import edu.stanford.nlp.process.CoreLabelTokenFactory;
import edu.stanford.nlp.sequences.SeqClassifierFlags;
import edu.stanford.nlp.trees.CompositeTreeTransformer;
import edu.stanford.nlp.trees.CompositeTreebank;
import edu.stanford.nlp.trees.DiskTreebank;
import edu.stanford.nlp.trees.MemoryTreebank;
import edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer;
import edu.stanford.nlp.trees.PennTreeReaderFactory;
import edu.stanford.nlp.trees.PennTreebankLanguagePack;
import edu.stanford.nlp.trees.TransformingTreebank;
import edu.stanford.nlp.trees.Tree;
import edu.stanford.nlp.trees.TreeGraphNode;
import edu.stanford.nlp.trees.TreePrint;
import edu.stanford.nlp.trees.Treebank;
import edu.stanford.nlp.trees.TreebankLanguagePack;
import edu.stanford.nlp.util.HashIndex;
import edu.stanford.nlp.util.Triple;
import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;
import java.io.File;
import java.io.FileFilter;
import java.io.ObjectInputStream;
import java.io.ObjectOutputStream;
import java.util.ArrayList;
import java.util.Comparator;
import java.util.LinkedList;
import java.util.List;
import java.util.Locale;
import java.util.PriorityQueue;
import java.util.Properties;
import java.util.Set;
import java.util.Stack;
import java.util.Vector;
import java.util.function.Function;
import java.util.regex.Pattern;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.ViolatedAssumptionAnswer;
import org.evosuite.runtime.mock.java.io.MockFileInputStream;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, separateClassLoader = true) 
public class LexicalizedParser_5_ESTest extends LexicalizedParser_5_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void testLoadModelTakingObjectInputStreamAndSaveParserToSerializedAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      MockFileInputStream mockFileInputStream0 = new MockFileInputStream("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      ObjectInputStream objectInputStream0 = new ObjectInputStream(mockFileInputStream0);
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.loadModel(objectInputStream0);
      assertNotSame(lexicalizedParser1, lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking3ArgumentsAndDefaultCoreNLPFlags()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      extensionFileFilter0.getDescription();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("EDU.STANFORD.NLP.PARSER.SHIFTREDUCE.BASICFEATUREFACTORY Files (*.edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory)", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      TreeAnnotatorAndBinarizer treeAnnotatorAndBinarizer0 = LexicalizedParser.buildTrainBinarizer(shiftReduceOptions0);
      Options options0 = new Options();
      LexicalizedParser.buildTrainTransformer(options0, treeAnnotatorAndBinarizer0);
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", shiftReduceOptions0);
      assertNotSame(lexicalizedParser1, lexicalizedParser0);
      
      String[] stringArray0 = lexicalizedParser0.defaultCoreNLPFlags();
      LexicalizedParser lexicalizedParser2 = LexicalizedParser.loadModel("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (Options) shiftReduceOptions0, stringArray0);
      assertNotSame(lexicalizedParser2, lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray0()  throws Throwable  {
      ByteArrayOutputStream byteArrayOutputStream0 = new ByteArrayOutputStream();
      byteArrayOutputStream0.flush();
      ObjectOutputStream objectOutputStream0 = new ObjectOutputStream(byteArrayOutputStream0);
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-train";
      stringArray0[1] = "SL;p+R";
      stringArray0[2] = "-savetotextfile";
      stringArray0[3] = "zuv$";
      stringArray0[4] = ".gz";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray0()  throws Throwable  {
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-train";
      stringArray0[1] = "SL;p+R";
      stringArray0[2] = "-savetotextfile";
      stringArray0[3] = "zuv$";
      stringArray0[4] = "SL;p+R";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray1()  throws Throwable  {
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-tLPP";
      stringArray0[1] = "edu.stanford.nlp.parser.lexparser.BaseUnknownWordModel";
      stringArray0[2] = "-tLPP";
      stringArray0[3] = "-tLPP";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.lang.NoSuchMethodException: edu.stanford.nlp.parser.lexparser.BaseUnknownWordModel.<init>()
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromSerializedFileWithNull()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      String[] stringArray0 = new String[0];
      ClassifierCombiner<CoreLabel> classifierCombiner0 = new ClassifierCombiner<CoreLabel>(stringArray0);
      shiftReduceOptions0.wordFunction = (Function<String, String>) classifierCombiner0;
      TreeAnnotatorAndBinarizer treeAnnotatorAndBinarizer0 = LexicalizedParser.buildTrainBinarizer(shiftReduceOptions0);
      LexicalizedParser.buildTrainTransformer((Options) shiftReduceOptions0, treeAnnotatorAndBinarizer0);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.getParserFromSerializedFile((String) null);
      assertNull(lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingObjectInputStreamWithNonNull0()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      ByteArrayOutputStream byteArrayOutputStream0 = new ByteArrayOutputStream();
      ObjectOutputStream objectOutputStream0 = new ObjectOutputStream(byteArrayOutputStream0);
      objectOutputStream0.close();
      byte[] byteArray0 = byteArrayOutputStream0.toByteArray();
      ByteArrayInputStream byteArrayInputStream0 = new ByteArrayInputStream(byteArray0);
      ObjectInputStream objectInputStream0 = new ObjectInputStream(byteArrayInputStream0);
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel(objectInputStream0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.io.EOFException
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1AndGetParserFromSerializedFile()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      shiftReduceOptions0.freeDependencies = true;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser.getParserFromSerializedFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      String[] stringArray0 = new String[0];
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.loadModel("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", stringArray0);
      assertNotSame(lexicalizedParser1, lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankAndGetAnnotatedBinaryTreebankFromTreebankWithNull0()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      NegraPennTreebankParserParams negraPennTreebankParserParams0 = new NegraPennTreebankParserParams();
      DiskTreebank diskTreebank0 = negraPennTreebankParserParams0.diskTreebank();
      Triple<Treebank, Treebank, Treebank> triple0 = LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(diskTreebank0, (Treebank) null, diskTreebank0, shiftReduceOptions0);
      assertNotNull(triple0);
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray2()  throws Throwable  {
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-train2";
      stringArray0[1] = "[^6}L0{*?Fmy[!Tqcb";
      stringArray0[2] = "-train2";
      stringArray0[3] = "-train2";
      stringArray0[4] = "-train2";
      stringArray0[5] = "-train2";
      stringArray0[6] = "-train2";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -train2
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testBuildTrainTransformerTakingOptionsAndGetAnnotatedBinaryTreebankFromTreebank()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-sentences";
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      Options options0 = new Options(italianTreebankParserParams0);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ShiftReduceParser shiftReduceParser0 = new ShiftReduceParser(shiftReduceOptions0);
      TreebankLanguagePack treebankLanguagePack0 = shiftReduceParser0.treebankLanguagePack();
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams(treebankLanguagePack0);
      MemoryTreebank memoryTreebank0 = hebrewTreebankParserParams0.memoryTreebank();
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, (Treebank) null, shiftReduceOptions0);
      LexicalizedParser.buildTrainBinarizer(shiftReduceOptions0);
      CompositeTreeTransformer compositeTreeTransformer0 = LexicalizedParser.buildTrainTransformer((Options) shiftReduceOptions0);
      assertNotNull(compositeTreeTransformer0);
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankAndGetAnnotatedBinaryTreebankFromTreebankWithNull1()  throws Throwable  {
      DiskTreebank diskTreebank0 = new DiskTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      Triple<Treebank, Treebank, Treebank> triple0 = LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(diskTreebank0, diskTreebank0, (Treebank) null, shiftReduceOptions0);
      assertNotNull(triple0);
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray1()  throws Throwable  {
      Stack<List<TaggedWord>> stack0 = new Stack<List<TaggedWord>>();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, true);
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-train2";
      stringArray0[1] = "inspan";
      stringArray0[2] = "w=cD&]r.cD}~3qfvZ";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Constructor argument not valid list of number ranges: w=cD&]r.cD}~3qfvZ
         //
         verifyException("edu.stanford.nlp.io.NumberRangesFileFilter", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray3()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-train2";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingObjectInputStreamWithNonNull1()  throws Throwable  {
      byte[] byteArray0 = new byte[25];
      byteArray0[0] = (byte) 172;
      byteArray0[1] = (byte) 237;
      byteArray0[2] = (byte) 0;
      byteArray0[3] = (byte) 5;
      byteArray0[4] = (byte) 115;
      byteArray0[5] = (byte) 114;
      byteArray0[6] = (byte) 0;
      byteArray0[7] = (byte) 4;
      byteArray0[8] = (byte) 84;
      byteArray0[9] = (byte) 101;
      byteArray0[10] = (byte) 115;
      byteArray0[11] = (byte) 116;
      byteArray0[12] = (byte) 0;
      byteArray0[13] = (byte) 0;
      byteArray0[14] = (byte) 0;
      byteArray0[15] = (byte) 0;
      byteArray0[16] = (byte) 0;
      byteArray0[17] = (byte) 0;
      byteArray0[18] = (byte) 0;
      byteArray0[19] = (byte) 1;
      byteArray0[20] = (byte) 2;
      byteArray0[21] = (byte) 0;
      byteArray0[22] = (byte) 0;
      byteArray0[23] = (byte) 120;
      byteArray0[24] = (byte) 112;
      ByteArrayInputStream byteArrayInputStream0 = new ByteArrayInputStream(byteArray0);
      ObjectInputStream objectInputStream0 = new ObjectInputStream(byteArrayInputStream0);
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel(objectInputStream0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.lang.ClassNotFoundException: Class 'Test.class' should be in target project, but could not be found!
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1WithNonNullAndNonEmptyArray()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      TreeAnnotatorAndBinarizer treeAnnotatorAndBinarizer0 = LexicalizedParser.buildTrainBinarizer(shiftReduceOptions0);
      LexicalizedParser.buildTrainTransformer((Options) shiftReduceOptions0, treeAnnotatorAndBinarizer0);
      String[] stringArray0 = new String[2];
      stringArray0[0] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel((Options) shiftReduceOptions0, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingNoArgumentsAndLoadModelTakingNoArguments()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel();
      assertNull(lexicalizedParser0);
      
      Locale locale0 = Locale.PRC;
      Set<String> set0 = locale0.getUnicodeLocaleKeys();
      TestOptions testOptions0 = new TestOptions();
      Properties properties0 = testOptions0.evals;
      // Undeclared exception!
      try { 
        NERClassifierCombiner.createNERClassifierCombiner("(?:\u661F\u671F|\u5468|\u793C\u62DC).+", set0, properties0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // org.evosuite.runtime.mock.java.lang.MockThrowable: Couldn't load classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz
         //
         verifyException("edu.stanford.nlp.ie.NERClassifierCombiner", e);
      }
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFile0()  throws Throwable  {
      Lexicon lexicon0 = mock(Lexicon.class, new ViolatedAssumptionAnswer());
      doReturn((UnknownWordModel) null).when(lexicon0).getUnknownWordModel();
      BinaryGrammar binaryGrammar0 = mock(BinaryGrammar.class, new ViolatedAssumptionAnswer());
      UnaryGrammar unaryGrammar0 = mock(UnaryGrammar.class, new ViolatedAssumptionAnswer());
      HashIndex<String> hashIndex0 = new HashIndex<String>();
      hashIndex0.add("S");
      HashIndex<String> hashIndex1 = new HashIndex<String>();
      hashIndex1.add("word");
      HashIndex<String> hashIndex2 = new HashIndex<String>();
      hashIndex2.add("NN");
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = new LexicalizedParser(lexicon0, binaryGrammar0, unaryGrammar0, (DependencyGrammar) null, hashIndex0, hashIndex1, hashIndex2, options0);
      lexicalizedParser0.saveParserToTextFile("temp_text_grammar.txt");
      File file0 = new File("temp_text_grammar.txt");
      file0.exists();
      boolean boolean0 = file0.delete();
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFileAndTrainFromTreebankTaking11And10()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.dg = null;
      lexicalizedParser0.saveParserToTextFile("done [read ");
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFile1()  throws Throwable  {
      Lexicon lexicon0 = mock(Lexicon.class, new ViolatedAssumptionAnswer());
      doReturn((UnknownWordModel) null).when(lexicon0).getUnknownWordModel();
      BinaryGrammar binaryGrammar0 = mock(BinaryGrammar.class, new ViolatedAssumptionAnswer());
      UnaryGrammar unaryGrammar0 = mock(UnaryGrammar.class, new ViolatedAssumptionAnswer());
      DependencyGrammar dependencyGrammar0 = mock(DependencyGrammar.class, new ViolatedAssumptionAnswer());
      HashIndex<String> hashIndex0 = new HashIndex<String>();
      hashIndex0.add("S");
      HashIndex<String> hashIndex1 = new HashIndex<String>();
      hashIndex1.add("hello");
      HashIndex<String> hashIndex2 = new HashIndex<String>();
      hashIndex2.add("NN");
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = new LexicalizedParser(lexicon0, binaryGrammar0, unaryGrammar0, dependencyGrammar0, hashIndex0, hashIndex1, hashIndex2, options0);
      lexicalizedParser0.saveParserToTextFile("output_model.txt.gz");
      File file0 = new File("output_model.txt.gz");
      file0.exists();
      File file1 = new File("output_model.txt.gz");
      boolean boolean0 = file1.delete();
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileThrowsNullPointerException()  throws Throwable  {
      String string0 = "-escaper";
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Lexicon lexicon0 = englishTreebankParserParams0.lex(shiftReduceOptions0, lexicalizedParser0.stateIndex, lexicalizedParser0.tagIndex);
      englishTreebankParserParams0.setInputEncoding("7");
      lexicalizedParser0.lex = lexicon0;
      // Undeclared exception!
      try { 
        lexicalizedParser0.saveParserToTextFile("-escaper");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingObjectInputStream()  throws Throwable  {
      ByteArrayOutputStream byteArrayOutputStream0 = new ByteArrayOutputStream();
      ObjectOutputStream objectOutputStream0 = new ObjectOutputStream(byteArrayOutputStream0);
      objectOutputStream0.writeObject("This is not a parser");
      objectOutputStream0.close();
      byte[] byteArray0 = byteArrayOutputStream0.toByteArray();
      ByteArrayInputStream byteArrayInputStream0 = new ByteArrayInputStream(byteArray0);
      ObjectInputStream objectInputStream0 = new ObjectInputStream(byteArrayInputStream0);
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel(objectInputStream0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // Wanted LexicalizedParser, got class java.lang.String
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingObjectInputStreamWithNonNull2()  throws Throwable  {
      ByteArrayOutputStream byteArrayOutputStream0 = new ByteArrayOutputStream();
      ObjectOutputStream objectOutputStream0 = new ObjectOutputStream(byteArrayOutputStream0);
      objectOutputStream0.writeObject(".gz");
      byte[] byteArray0 = byteArrayOutputStream0.toByteArray();
      ByteArrayInputStream byteArrayInputStream0 = new ByteArrayInputStream(byteArray0);
      ObjectInputStream objectInputStream0 = new ObjectInputStream(byteArrayInputStream0);
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel(objectInputStream0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // Wanted LexicalizedParser, got class java.lang.String
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankWithNegative()  throws Throwable  {
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      Stack<List<TaggedWord>> stack0 = new Stack<List<TaggedWord>>();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      options0.doDep = false;
      ExactGrammarCompactor exactGrammarCompactor1 = new ExactGrammarCompactor(options0, false, true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, (-1308.73087053515), exactGrammarCompactor1, options0, memoryTreebank0, stack0);
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking2ArgumentsAndGetExtraEvals()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.doDep = false;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      List<Eval> list0 = lexicalizedParser0.getExtraEvals();
      assertEquals(0, list0.size());
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray2()  throws Throwable  {
      Options options0 = new Options();
      options0.useUnigramWordSmoothing = false;
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      Stack<List<TaggedWord>> stack0 = new Stack<List<TaggedWord>>();
      String[] stringArray0 = new String[6];
      stringArray0[0] = "-tagseparator";
      stringArray0[1] = "STATE_INDEX";
      stringArray0[2] = "5rMyw]E@Mj";
      stringArray0[3] = "O";
      stringArray0[4] = " tag=\"";
      stringArray0[5] = "-esaper";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray4()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-tagSeparator";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankAndGetAnnotatedBinaryTreebankFromTreebankWithNull2()  throws Throwable  {
      Treebank treebank0 = null;
      Options options0 = new Options();
      // Undeclared exception!
      try { 
        LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank((Treebank) null, (Treebank) null, (Treebank) null, options0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.trees.Treebank.transform(edu.stanford.nlp.trees.TreeTransformer)\" because \"trainTreebank\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray3()  throws Throwable  {
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      Stack<List<TaggedWord>> stack0 = new Stack<List<TaggedWord>>();
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "-treebank");
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-treebank";
      stringArray0[1] = "-treebank";
      stringArray0[2] = "-treebank";
      stringArray0[3] = "-treebank";
      stringArray0[4] = "@xeJ*.";
      stringArray0[5] = "-treebank";
      stringArray0[6] = "-treebank";
      stringArray0[7] = "-treebank";
      stringArray0[8] = "-treebank";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -test
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray5()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-treebank";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankWithNonEmptyListAndNull()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-traintreebank";
      NPTmpRetainingTreeNormalizer.NPTmpRetainingTreeReaderFactory nPTmpRetainingTreeNormalizer_NPTmpRetainingTreeReaderFactory0 = new NPTmpRetainingTreeNormalizer.NPTmpRetainingTreeReaderFactory();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(nPTmpRetainingTreeNormalizer_NPTmpRetainingTreeReaderFactory0);
      LinkedList<TaggedWord> linkedList0 = new LinkedList<TaggedWord>();
      List<List<TaggedWord>> list0 = List.of(linkedList0, linkedList0, linkedList0, linkedList0, linkedList0);
      // Undeclared exception!
      LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, 0.0, (GrammarCompactor) null, options0, memoryTreebank0, list0);
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray6()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-parseInside";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray7()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-model";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseMultipleTaking2ArgumentsAndParseMultipleTaking2ArgumentsAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      assertFalse(lexicalizedParser0.requiresTags());
      
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      assertFalse(lexicalizedParser0.requiresTags());
      
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      Properties properties0 = new Properties();
      PresetSequenceClassifier<CoreLabel> presetSequenceClassifier0 = new PresetSequenceClassifier<CoreLabel>(properties0);
      LinkedList<CoreLabel> linkedList0 = new LinkedList<CoreLabel>();
      IndexedWord indexedWord0 = new IndexedWord();
      BasicDocument<Object> basicDocument0 = BasicDocument.init();
      LinkedList<LabeledWord> linkedList1 = new LinkedList<LabeledWord>();
      BasicDocument<Object> basicDocument1 = basicDocument0.init((List<? extends Word>) linkedList1);
      List<BasicDocument<Object>> list0 = List.of(basicDocument1, basicDocument1, basicDocument1, basicDocument1);
      lexicalizedParser0.parseMultiple(list0, 3);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      CompositeTreebank compositeTreebank0 = new CompositeTreebank(memoryTreebank0, memoryTreebank0);
      ShiftReduceOptions shiftReduceOptions1 = new ShiftReduceOptions();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions1, true, false);
      exactGrammarCompactor0.newStateIndex = lexicalizedParser0.wordIndex;
      LexicalizedParser.trainFromTreebank((Treebank) compositeTreebank0, (GrammarCompactor) exactGrammarCompactor0, (Options) shiftReduceOptions1);
      // Undeclared exception!
      try { 
        LexicalizedParser.getParserFromFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (Options) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromFileWithNull()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      Properties properties0 = new Properties();
      PresetSequenceClassifier<CoreLabel> presetSequenceClassifier0 = new PresetSequenceClassifier<CoreLabel>(properties0);
      LinkedList<CoreLabel> linkedList0 = new LinkedList<CoreLabel>();
      IndexedWord indexedWord0 = new IndexedWord();
      BasicDocument<Object> basicDocument0 = BasicDocument.init();
      LinkedList<LabeledWord> linkedList1 = new LinkedList<LabeledWord>();
      List<BasicDocument<Object>> list0 = List.of(basicDocument0, basicDocument0, basicDocument0, basicDocument0);
      lexicalizedParser0.parseMultiple(list0, 3);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      CompositeTreebank compositeTreebank0 = new CompositeTreebank(memoryTreebank0, memoryTreebank0);
      ShiftReduceOptions shiftReduceOptions1 = new ShiftReduceOptions();
      // Undeclared exception!
      try { 
        LexicalizedParser.getParserFromFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (Options) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileReturningLexicalizedParserWhereRequiresTagsIsFalse()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, options0);
      lexicalizedParser0.saveParserToTextFile("f`YyQJTL}|");
      Properties properties0 = new Properties();
      LexicalizedParser.getParserFromTextFile("f`YyQJTL}|", options0);
      String[] stringArray0 = new String[1];
      stringArray0[0] = "f`YyQJTL}|";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFileAndMainWithNonEmptyArray()  throws Throwable  {
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("-markovorder", false);
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("$g`_)GJqpHEYrV(", (FileFilter) extensionFileFilter0, options0);
      lexicalizedParser0.saveParserToSerialized("?oT+G{d=`C;nUMd';q");
      lexicalizedParser0.saveParserToTextFile("Removed from vertical splitters: ");
      Properties properties0 = new Properties();
      PresetSequenceClassifier<CoreLabel> presetSequenceClassifier0 = new PresetSequenceClassifier<CoreLabel>(properties0);
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-markovorder";
      stringArray0[1] = "-markovorder";
      stringArray0[2] = "?oT+G{d=`C;nUMd';q";
      stringArray0[3] = "-markovorder";
      stringArray0[4] = "?oT+G{d=`C;nUMd';q";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Unknown option: -markovorder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.Options", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromFileThrowsNullPointerException()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      Properties properties0 = new Properties();
      PresetSequenceClassifier<CoreLabel> presetSequenceClassifier0 = new PresetSequenceClassifier<CoreLabel>(properties0);
      LinkedList<CoreLabel> linkedList0 = new LinkedList<CoreLabel>();
      IndexedWord indexedWord0 = new IndexedWord();
      BasicDocument<Object> basicDocument0 = BasicDocument.init();
      LinkedList<LabeledWord> linkedList1 = new LinkedList<LabeledWord>();
      BasicDocument<Object> basicDocument1 = basicDocument0.init((List<? extends Word>) linkedList1);
      List<BasicDocument<Object>> list0 = List.of(basicDocument1, basicDocument1, basicDocument1, basicDocument1);
      lexicalizedParser0.parseMultiple(list0, 1518);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      CompositeTreebank compositeTreebank0 = new CompositeTreebank(memoryTreebank0, memoryTreebank0);
      ShiftReduceOptions shiftReduceOptions1 = new ShiftReduceOptions();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions1, true, false);
      LexicalizedParser.trainFromTreebank((Treebank) compositeTreebank0, (GrammarCompactor) exactGrammarCompactor0, (Options) shiftReduceOptions1);
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (edu.stanford.nlp.parser.lexparser.Options) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.Options.readData(java.io.BufferedReader)\" because \"op\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseMultipleTaking2ArgumentsWithNonEmptyList()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      extensionFileFilter0.getDescription();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      Properties properties0 = new Properties();
      PresetSequenceClassifier<CoreLabel> presetSequenceClassifier0 = new PresetSequenceClassifier<CoreLabel>(properties0);
      LinkedList<CoreLabel> linkedList0 = new LinkedList<CoreLabel>();
      IndexedWord indexedWord0 = new IndexedWord();
      BasicDocument<Object> basicDocument0 = BasicDocument.init();
      LinkedList<LabeledWord> linkedList1 = new LinkedList<LabeledWord>();
      BasicDocument<Object> basicDocument1 = basicDocument0.init((List<? extends Word>) linkedList1);
      List<BasicDocument<Object>> list0 = List.of(basicDocument1, basicDocument1, basicDocument1, basicDocument1);
      lexicalizedParser0.parseMultiple(list0, 3);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      CompositeTreebank compositeTreebank0 = new CompositeTreebank(memoryTreebank0, memoryTreebank0);
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", shiftReduceOptions0);
      assertFalse(lexicalizedParser1.requiresTags());
  }

  @Test(timeout = 4000)
  public void testMainAndSaveParserToTextFile()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      Properties properties0 = new Properties();
      PresetSequenceClassifier<CoreLabel> presetSequenceClassifier0 = new PresetSequenceClassifier<CoreLabel>(properties0);
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-tune";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray8()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-tune";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // MemoryTreebank.processFile IOException in file edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory
         //
         verifyException("edu.stanford.nlp.trees.MemoryTreebank", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray9()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-tune";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray4()  throws Throwable  {
      Stack<List<TaggedWord>> stack0 = new Stack<List<TaggedWord>>();
      String[] stringArray0 = new String[7];
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "d|kH}I$]Y6g&K,P9");
      stringArray0[0] = "-savetotextfile";
      stringArray0[1] = "R";
      stringArray0[2] = "useTypeySequences";
      stringArray0[4] = "Exception: in printToFile ";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray5()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-savetotextfile";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankWithEmptyListAndNull()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      LinkedList<BasicDocument<Object>> linkedList0 = new LinkedList<BasicDocument<Object>>();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      extensionFileFilter0.getDescription();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(100);
      ArrayList<List<TaggedWord>> arrayList1 = new ArrayList<List<TaggedWord>>();
      // Undeclared exception!
      LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, 0.0, (GrammarCompactor) null, shiftReduceOptions0, memoryTreebank0, arrayList1);
  }

  @Test(timeout = 4000)
  public void testDefaultCoreNLPFlagsReturningNonEmptyArray()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("f`YyQJTL}|");
      Properties properties0 = new Properties();
      LexicalizedParser.loadModel();
      String[] stringArray0 = new String[0];
      LexicalizedParser.loadModel("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", stringArray0);
      String[] stringArray1 = lexicalizedParser0.defaultCoreNLPFlags();
      assertNotSame(stringArray1, stringArray0);
  }

  @Test(timeout = 4000)
  public void testGetParserFromSerializedFileReturningLexicalizedParserWhereRequiresTagsIsFalse()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.useUnigramWordSmoothing = true;
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      LinkedList<BasicDocument<Object>> linkedList0 = new LinkedList<BasicDocument<Object>>();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      extensionFileFilter0.getDescription();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("EDU.STANFORD.NLP.PARSER.SHIFTREDUCE.BASICFEATUREFACTORY Files (*.edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory)", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      lexicalizedParser0.getExtraEvals();
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromSerializedFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      assertNotSame(lexicalizedParser1, lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFileAndTrainFromTreebankTaking11And11()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory.gz");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory.gz");
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testGetTreePrintAndParseStringsAndTrainFromTreebankTaking11And1()  throws Throwable  {
      Stack<String> stack0 = new Stack<String>();
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      DiskTreebank diskTreebank0 = italianTreebankParserParams0.diskTreebank();
      Options options0 = new Options(italianTreebankParserParams0);
      options0.distance = true;
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      lexicalizedParser0.parseStrings(stack0);
      TreePrint treePrint0 = lexicalizedParser0.getTreePrint();
      assertNotNull(treePrint0);
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray6()  throws Throwable  {
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      String string0 = "-markFem";
      String string1 = "-tokenizeroptions";
      String string2 = "Wanted LexicalizedParser, got ";
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "Wanted LexicalizedParser, got ");
      String[] stringArray0 = new String[9];
      String string3 = "-";
      stringArray0[0] = "-";
      stringArray0[1] = "Wanted LexicalizedParser, got ";
      stringArray0[2] = "-markFem";
      stringArray0[3] = "-markFem";
      stringArray0[4] = "-markFem";
      stringArray0[5] = "-markFem";
      stringArray0[6] = "-tokenizeroptions";
      stringArray0[7] = "Wanted LexicalizedParser, got ";
      stringArray0[8] = "-tokenizeroptions";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray10()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-";
      stringArray0[1] = "Cfy0*=m_&C'C)c[%Ze";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testDefaultCoreNLPFlagsAndParseMultipleTaking2Arguments()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, false);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      MemoryTreebank memoryTreebank0 = hebrewTreebankParserParams0.memoryTreebank();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, options0);
      lexicalizedParser0.saveParserToTextFile("-train");
      IndexedWord indexedWord0 = new IndexedWord("-train", (-2752), 100);
      Properties properties0 = new Properties();
      SeqClassifierFlags seqClassifierFlags0 = new SeqClassifierFlags(properties0);
      List<String> list0 = seqClassifierFlags0.comboProps;
      List<String> list1 = seqClassifierFlags0.comboProps;
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.loadModel("-train", list1);
      lexicalizedParser0.parseStrings(seqClassifierFlags0.gazettes);
      lexicalizedParser1.saveParserToTextFile("NLP_PARSER");
      lexicalizedParser1.defaultCoreNLPFlags();
      List<Tree> list2 = lexicalizedParser1.parseMultiple((List<? extends List<? extends HasWord>>) vector0, 719);
      assertTrue(list2.isEmpty());
  }

  @Test(timeout = 4000)
  public void testDefaultCoreNLPFlagsAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      String[] stringArray0 = lexicalizedParser0.defaultCoreNLPFlags();
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankWithNullAndGetParserFromTreebank()  throws Throwable  {
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      Stack<List<TaggedWord>> stack0 = new Stack<List<TaggedWord>>();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(100);
      Stack<List<TaggedWord>> stack1 = new Stack<List<TaggedWord>>();
      MemoryTreebank memoryTreebank1 = new MemoryTreebank(100);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.getParserFromTreebank(memoryTreebank0, (Treebank) null, 139.196506232, exactGrammarCompactor0, options0, (Treebank) null, stack1);
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray7()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, false);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(1124);
      String[] stringArray0 = new String[6];
      stringArray0[0] = "-saveTrainTrees";
      stringArray0[2] = "-saveTrainTrees";
      stringArray0[4] = "-saveTrainTrees";
      stringArray0[5] = "-saveTrainTrees";
      LexicalizedParser.main(stringArray0);
      assertEquals(6, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray8()  throws Throwable  {
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      Stack<List<TaggedWord>> stack0 = new Stack<List<TaggedWord>>();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(100);
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-saveTrainTrees";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray11()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-savetraintrees";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray9()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-test";
      stringArray0[1] = "-tLPP";
      stringArray0[2] = "<P8uqlvMUP`OkAv";
      stringArray0[3] = "-tLPP";
      stringArray0[4] = "-tLPP";
      stringArray0[5] = "-tLPP";
      stringArray0[6] = "-tLPP";
      stringArray0[7] = "freight";
      stringArray0[8] = "-tLPP";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -test
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray12()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-test";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking2ArgumentsWithNonNull()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, true);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      Stack<List<TaggedWord>> stack0 = new Stack<List<TaggedWord>>();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-encoding";
      stringArray0[1] = "-encoding";
      stringArray0[2] = "-encoding";
      stringArray0[3] = "-encoding";
      LexicalizedParser.main(stringArray0);
      Vector<List<TaggedWord>> vector1 = new Vector<List<TaggedWord>>();
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray10()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      Vector<List<TaggedWord>> vector1 = new Stack<List<TaggedWord>>();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-encoding";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray13()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-encoding";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testParse()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      OutsideRuleFilter.reverse(arrayList0);
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) arrayList0, 100);
      Properties properties0 = new Properties();
      LinkedList<CoreLabel> linkedList0 = new LinkedList<CoreLabel>();
      IndexedWord indexedWord0 = new IndexedWord();
      CoreLabel coreLabel0 = new CoreLabel(indexedWord0);
      TreeGraphNode treeGraphNode0 = new TreeGraphNode(coreLabel0);
      TransformingTreebank transformingTreebank0 = new TransformingTreebank();
      properties0.put(transformingTreebank0, lexicalizedParser0);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      List<List<TaggedWord>> list0 = OutsideRuleFilter.reverse(vector0);
      treeGraphNode0.yield(list0);
      lexicalizedParser0.parseTree(linkedList0);
      Tree tree0 = lexicalizedParser0.parse((List<? extends HasWord>) linkedList0);
      assertEquals(Double.NaN, tree0.score(), 0.01);
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray14()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-tokenizerMethod";
      stringArray0[1] = "-tokenizerMethod";
      stringArray0[2] = "-tokenizerMethod";
      stringArray0[3] = "-tokenizerMethod";
      stringArray0[4] = "-tokenizerMethod";
      stringArray0[5] = "-tokenizerMethod";
      stringArray0[6] = "-tokenizerMethod";
      stringArray0[7] = "-tokenizerMethod";
      stringArray0[8] = "-tokenizerMethod";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 9 out of bounds for length 9
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray11()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(100);
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-savetoserializedfile";
      LexicalizedParser.main(stringArray0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray12()  throws Throwable  {
      Stack<String> stack0 = new Stack<String>();
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      DiskTreebank diskTreebank0 = new DiskTreebank();
      Options options0 = new Options(italianTreebankParserParams0);
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-escaper";
      stringArray0[1] = "VF?ew";
      stringArray0[2] = "-tokenizerfactory";
      stringArray0[3] = "-tokenizerfactory";
      stringArray0[4] = "teleshop";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray15()  throws Throwable  {
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-tokenizerfactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray13()  throws Throwable  {
      Stack<String> stack0 = new Stack<String>();
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      DiskTreebank diskTreebank0 = new DiskTreebank();
      Options options0 = new Options(italianTreebankParserParams0);
      String[] stringArray0 = new String[8];
      stringArray0[0] = "-saveToSerializedFile";
      stringArray0[1] = "-saveToSerializedFile";
      stringArray0[2] = "ytMP1z;WGs~yRi6";
      stringArray0[3] = "o";
      stringArray0[4] = "uT8{@t^m";
      stringArray0[5] = "teleshop";
      stringArray0[6] = "newline";
      stringArray0[7] = "-tokenizerfactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray14()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-savetoserializedfile";
      stringArray0[1] = "/<x3u$VD3fe}a";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray15()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      options0.newTestOptions();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, false);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      Vector<List<TaggedWord>> vector1 = new Vector<List<TaggedWord>>();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "-saveToSerializedFile";
      stringArray0[1] = "'p}lm";
      stringArray0[2] = "Tags are: ";
      stringArray0[3] = "Y);WPir+";
      stringArray0[4] = "__ << /^MW/";
      stringArray0[5] = "WARNING: No document date specified";
      stringArray0[6] = "'p}lm";
      stringArray0[7] = "-savetraintrees";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray16()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, false);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      Vector<List<TaggedWord>> vector1 = new Vector<List<TaggedWord>>();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-escaper";
      stringArray0[1] = "-escaper";
      stringArray0[2] = "-escaper";
      stringArray0[3] = "{v+U";
      stringArray0[4] = "-tokenizerMethod";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 5 out of bounds for length 5
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray16()  throws Throwable  {
      String[] stringArray0 = new String[8];
      stringArray0[0] = "-tokenizerMethod";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testBuildTrainBinarizerThrowsRuntimeException()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("-tLPP", false);
      extensionFileFilter0.getDescription();
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("H~I", (FileFilter) extensionFileFilter0, options0);
      lexicalizedParser0.saveParserToTextFile(" score=\"");
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-tLPP";
      stringArray0[1] = "Y]}rVH?kca";
      stringArray0[2] = "H~I";
      stringArray0[3] = "H~I";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.lang.ClassNotFoundException: Class 'Y]}rVH?kca.class' should be in target project, but could not be found!
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray17()  throws Throwable  {
      String[] stringArray0 = new String[8];
      stringArray0[0] = "-tLPP";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray17()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-tLPP";
      LexicalizedParser.main(stringArray0);
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testGetTLPParamsReturningTreebankLangParserParamsWhereSupportsBasicDependenciesIsFalse()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, false);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      MemoryTreebank memoryTreebank0 = hebrewTreebankParserParams0.memoryTreebank();
      Vector<List<TaggedWord>> vector1 = new Vector<List<TaggedWord>>();
      Options options1 = new Options(options0.tlpParams);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      TreebankLangParserParams treebankLangParserParams0 = lexicalizedParser0.getTLPParams();
      assertFalse(treebankLangParserParams0.generateOriginalDependencies());
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray18()  throws Throwable  {
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-train";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ReturningNullAndLoadModelTaking1And1AndMain()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      String[] stringArray0 = new String[0];
      LexicalizedParser.main(stringArray0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel("Compiling grammar...", stringArray0);
      // Undeclared exception!
      try { 
        LexicalizedParser.copyLexicalizedParser((LexicalizedParser) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"lex\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray18()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-traintreebank";
      stringArray0[1] = "1|<]A_3jhn$E3kp";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankAndGetParserFromTreebankReturningLexicalizedParserWhereRequiresTagsIsFalse()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      Vector<List<TaggedWord>> vector1 = new Vector<List<TaggedWord>>();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, 100, exactGrammarCompactor0, options0, (Treebank) null, vector0);
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray19()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-escaper";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFileWithEmptyString()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      OutsideRuleFilter.reverse(arrayList0);
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      ExtensionFileFilter extensionFileFilter1 = new ExtensionFileFilter("done.", false);
      ExtensionFileFilter extensionFileFilter2 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      extensionFileFilter2.getDescription();
      String string0 = "-tlpp";
      int int0 = 254;
      Pattern pattern0 = Pattern.compile(" simpleBinarizedLabels=", 254);
      RegExFileFilter regExFileFilter0 = new RegExFileFilter(pattern0);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("-tlpp", (FileFilter) regExFileFilter0, (Options) shiftReduceOptions0);
      String string1 = "";
      // Undeclared exception!
      try { 
        lexicalizedParser0.saveParserToTextFile("");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.io.FileNotFoundException
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray19()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      Options options1 = spanishUnknownWordModelTrainer0.op;
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-traintreebank";
      stringArray0[1] = "1|<]A_3jhn$E3kp";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray20()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-traintreebank";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -train
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray21()  throws Throwable  {
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-testtreebank";
      stringArray0[1] = "I>;";
      stringArray0[2] = "-sentences";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 3 out of bounds for length 3
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray22()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, false);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      hebrewTreebankParserParams0.memoryTreebank();
      exactGrammarCompactor0.outputType = (Object) "";
      Vector<List<TaggedWord>> vector1 = new Vector<List<TaggedWord>>();
      Options options1 = new Options(hebrewTreebankParserParams0);
      String[] stringArray0 = new String[6];
      stringArray0[0] = "R0";
      stringArray0[1] = "";
      stringArray0[2] = "";
      stringArray0[3] = "usage: java edu.stanford.nlp.parser.lexparser.LexicalizedParser -train trainFilesPath [fileRange] -saveToSerializedFile serializedParserFilename";
      stringArray0[4] = "";
      stringArray0[5] = "R0";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseMultipleTaking2ArgumentsAndMainWithNonEmptyArray()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      OutsideRuleFilter.reverse(arrayList0);
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      extensionFileFilter0.getDescription();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("EDU.STANFORD.NLP.PARSER.SHIFTREDUCE.BASICFEATUREFACTORY Files (*.edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory)", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      lexicalizedParser0.saveParserToTextFile("EDU.STANFORD.NLP.PARSER.SHIFTREDUCE.BASICFEATUREFACTORY Files (*.edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory)");
      List<Tree> list0 = lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) arrayList0, 100);
      assertEquals(0, list0.size());
      
      Properties properties0 = new Properties();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("C");
      FileSystemHandling.appendLineToFile(evoSuiteFile0, "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      String[] stringArray0 = new String[3];
      stringArray0[0] = "EDU.STANFORD.NLP.PARSER.SHIFTREDUCE.BASICFEATUREFACTORY Files (*.edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory)";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "EDU.STANFORD.NLP.PARSER.SHIFTREDUCE.BASICFEATUREFACTORY Files (*.edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory)";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray20()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, false);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-loadFromSerializedFile";
      stringArray0[1] = "-";
      stringArray0[2] = "5.gz";
      stringArray0[3] = "?qD}UirA";
      stringArray0[4] = "Removed from vertical splitters: ";
      String string0 = "*!?i5f0n@";
      stringArray0[5] = "*!?i5f0n@";
      stringArray0[6] = "-a)k-vOrde";
      stringArray0[7] = "LG7R";
      stringArray0[8] = "Couldn't instantiate escaper ";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray21()  throws Throwable  {
      Stack<String> stack0 = new Stack<String>();
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      italianTreebankParserParams0.diskTreebank();
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      Vector<List<TaggedWord>> vector1 = new Vector<List<TaggedWord>>();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-model";
      stringArray0[1] = "]D~+=3Ui0<a6uK|d^";
      stringArray0[2] = "No test treebank path specified.  Using train path: \"";
      stringArray0[3] = "-tokenizermethod";
      stringArray0[4] = "Rd4,.;~U4hGJ,#eaXe";
      stringArray0[5] = "-train";
      stringArray0[6] = "Couldn't instantiate TokenizerFactory ";
      stringArray0[7] = "-tokenized";
      stringArray0[8] = "M!r|tbTt9X]6i7nz)";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray23()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-loadfromserializedfile";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray24()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-loadfromserializedfile";
      stringArray0[1] = "-loadfromserializedfile";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray22()  throws Throwable  {
      Stack<String> stack0 = new Stack<String>();
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-sentences";
      stringArray0[1] = "-sentences";
      stringArray0[2] = "-sentences";
      stringArray0[3] = "-sentences";
      stringArray0[4] = "I>;";
      stringArray0[5] = "-sentences";
      stringArray0[6] = "-sentences";
      stringArray0[7] = "-sentences";
      stringArray0[8] = "-sentences";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray23()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-sentences";
      stringArray0[1] = "-sentences";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testTreebankLanguagePackReturningTreebankLanguagePackWhereSupportsGrammaticalStructuresIsFalse()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, false);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      MemoryTreebank memoryTreebank0 = hebrewTreebankParserParams0.memoryTreebank();
      exactGrammarCompactor0.outputType = (Object) "";
      Vector<List<TaggedWord>> vector1 = new Vector<List<TaggedWord>>();
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      Options options1 = new Options(hebrewTreebankParserParams0);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (GrammarCompactor) exactGrammarCompactor0, options1);
      lexicalizedParser0.saveParserToTextFile("-train");
      lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) vector0, 100);
      TreebankLanguagePack treebankLanguagePack0 = lexicalizedParser0.treebankLanguagePack();
      TreebankLanguagePack treebankLanguagePack1 = lexicalizedParser0.treebankLanguagePack();
      assertSame(treebankLanguagePack1, treebankLanguagePack0);
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking3ArgumentsReturningNull()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      Options options0 = new Options();
      String[] stringArray0 = new String[0];
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.loadModel("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", options0, stringArray0);
      assertNull(lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testGetTreePrintAndSaveParserToTextFile()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      extensionFileFilter0.getDescription();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("EDU.STANFORD.NLP.PARSER.SHIFTREDUCE.BASICFEATUREFACTORY Files (*.edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory)", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      lexicalizedParser0.saveParserToTextFile("EDU.STANFORD.NLP.PARSER.SHIFTREDUCE.BASICFEATUREFACTORY Files (*.edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory)");
      // Undeclared exception!
      try { 
        lexicalizedParser0.getTreePrint();
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseTreeAndParseTree()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      OutsideRuleFilter.reverse(arrayList0);
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      extensionFileFilter0.getDescription();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("EDU.STANFORD.NLP.PARSER.SHIFTREDUCE.BASICFEATUREFACTORY Files (*.edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory)", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      lexicalizedParser0.saveParserToTextFile("EDU.STANFORD.NLP.PARSER.SHIFTREDUCE.BASICFEATUREFACTORY Files (*.edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory)");
      lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) arrayList0, 100);
      Properties properties0 = new Properties();
      PresetSequenceClassifier<CoreLabel> presetSequenceClassifier0 = new PresetSequenceClassifier<CoreLabel>(properties0);
      LinkedList<CoreLabel> linkedList0 = new LinkedList<CoreLabel>();
      IndexedWord indexedWord0 = new IndexedWord();
      CoreLabel coreLabel0 = new CoreLabel(indexedWord0);
      TreeGraphNode treeGraphNode0 = new TreeGraphNode(coreLabel0);
      CoreLabel coreLabel1 = treeGraphNode0.label();
      TransformingTreebank transformingTreebank0 = new TransformingTreebank();
      properties0.put(transformingTreebank0, lexicalizedParser0);
      List<CoreLabel> list0 = presetSequenceClassifier0.classifyWithGlobalInformation(linkedList0, coreLabel1, coreLabel1);
      Tree tree0 = lexicalizedParser0.parseTree(list0);
      assertNull(tree0);
  }

  @Test(timeout = 4000)
  public void testParseTree()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      Stack<CoreLabel> stack0 = new Stack<CoreLabel>();
      Tree tree0 = lexicalizedParser0.parseTree(stack0);
      assertNull(tree0);
  }

  @Test(timeout = 4000)
  public void testBuildTrainTransformerTaking2ArgumentsThrowsIllegalArgumentException()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("C");
      FileSystemHandling.appendLineToFile(evoSuiteFile0, "-testtreebank");
      FileSystemHandling.appendLineToFile(evoSuiteFile0, "-loadFromTextFile");
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-loadFromTextFile";
      stringArray0[1] = "-testtreebank";
      stringArray0[2] = "-testtreebank";
      stringArray0[3] = "-testtreebank";
      stringArray0[4] = "i)#H^NQrK=Jtr{%";
      stringArray0[5] = "-testtreebank";
      stringArray0[6] = "-loadFromTextFile";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -test
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray24()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-loadfromtextfile";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testParseMultipleTakingListReturningListWhereIsEmptyIsFalse()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "-tokenized");
      Stack<List<TaggedWord>> stack0 = new Stack<List<TaggedWord>>();
      Stack<TaggedWord> stack1 = new Stack<TaggedWord>();
      stack0.add((List<TaggedWord>) stack1);
      HebrewTreebankParserParams hebrewTreebankParserParams1 = new HebrewTreebankParserParams();
      Options options1 = new Options(hebrewTreebankParserParams1);
      RegExFileFilter regExFileFilter0 = new RegExFileFilter("-test");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("-testtreebank", (FileFilter) regExFileFilter0, options0);
      lexicalizedParser0.saveParserToTextFile("-testtreebank");
      lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) stack0);
      List<Eval> list0 = lexicalizedParser0.getExtraEvals();
      assertEquals(0, list0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesLexicalizedParser()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("C");
      FileSystemHandling.appendLineToFile(evoSuiteFile0, "-splitPNPAgr");
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-splitPNPAgr";
      boolean boolean0 = FileSystemHandling.appendLineToFile(evoSuiteFile0, "z&}b.JVe!<pkh)E$9ND");
      stringArray0[1] = "-splitPNPAgr";
      stringArray0[2] = "-splitPNPAgr";
      stringArray0[3] = "-splitPNPAgr";
      LexicalizedParser.main(stringArray0);
      Comparator<Object> comparator0 = (Comparator<Object>) mock(Comparator.class, new ViolatedAssumptionAnswer());
      PriorityQueue<String> priorityQueue0 = new PriorityQueue<String>(34, comparator0);
      HashIndex<String> hashIndex0 = new HashIndex<String>(priorityQueue0);
      BinaryGrammar binaryGrammar0 = new BinaryGrammar(hashIndex0);
      UnaryGrammar unaryGrammar0 = new UnaryGrammar(hashIndex0);
      MLEDependencyGrammar mLEDependencyGrammar0 = new MLEDependencyGrammar(options0.tlpParams, true, false, true, false, options0, hashIndex0, hashIndex0);
      LexicalizedParser lexicalizedParser0 = new LexicalizedParser((Lexicon) null, binaryGrammar0, unaryGrammar0, mLEDependencyGrammar0, hashIndex0, hashIndex0, hashIndex0, options0);
      boolean boolean1 = lexicalizedParser0.requiresTags();
      assertFalse(boolean1 == boolean0);
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray25()  throws Throwable  {
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-train";
      stringArray0[1] = "SL;p+R";
      stringArray0[2] = "-savetotextfile";
      stringArray0[4] = ".gz";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testSaveParserToSerializedAndTrainFromTreebankTaking11And1AndMainWithNonEmptyArray()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      String[] stringArray0 = new String[6];
      stringArray0[0] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray25()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-loadfromtextfile";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.parserQuery()\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray26()  throws Throwable  {
      Options options0 = new Options();
      options0.doDep = true;
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      Stack<List<TaggedWord>> stack0 = new Stack<List<TaggedWord>>();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-loadfromtextfile";
      stringArray0[1] = "V(,w^i";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.parserQuery()\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      // Undeclared exception!
      try { 
        lexicalizedParser0.getTreePrint();
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray26()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-traintreebank";
      stringArray0[1] = "1|<]A_3jhn$E3kp";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndGetExtraEvals()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      OutsideRuleFilter.reverse(arrayList0);
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      extensionFileFilter0.getDescription();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("EDU.STANFORD.NLP.PARSER.SHIFTREDUCE.BASICFEATUREFACTORY Files (*.edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory)", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      lexicalizedParser0.getExtraEvals();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray27()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      Vector<List<TaggedWord>> vector1 = new Vector<List<TaggedWord>>();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-train";
      stringArray0[1] = "edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray28()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-markovorder";
      LexicalizedParser.main(stringArray0);
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray29()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      OutsideRuleFilter.reverse(arrayList0);
      shiftReduceOptions0.newTestOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("C");
      FileSystemHandling.appendLineToFile(evoSuiteFile0, "-testtreebank");
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-tokenizeroptions";
      stringArray0[1] = "Cr";
      stringArray0[2] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[3] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray27()  throws Throwable  {
      String[] stringArray0 = new String[18];
      stringArray0[0] = "-tokenizeroptions";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLexicalizedParserQueryAndGetParserQueryEvalsAndLexicalizedParserQuery()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter(" cTags=", true);
      vector0.add((List<TaggedWord>) null);
      Options options1 = new Options(options0.tlpParams);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("J29Kq;q{!mml:5U", (FileFilter) extensionFileFilter0, options1);
      lexicalizedParser0.parse("J29Kq;q{!mml:5U");
      lexicalizedParser0.lexicalizedParserQuery();
      lexicalizedParser0.getParserQueryEvals();
      // Undeclared exception!
      try { 
        lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) vector0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingObjectInputStreamWithNull()  throws Throwable  {
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel((ObjectInputStream) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"java.io.ObjectInputStream.readObject()\" because \"ois\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking3ArgumentsWithNonEmptyArray()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      OutsideRuleFilter.reverse(arrayList0);
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      extensionFileFilter0.getDescription();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("EDU.STANFORD.NLP.PARSER.SHIFTREDUCE.BASICFEATUREFACTORY Files (*.edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory)", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      lexicalizedParser0.getExtraEvals();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[3] = "EDU.STANFORD.NLP.PARSER.SHIFTREDUCE.BASICFEATUREFACTORY Files (*.edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory)";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (Options) shiftReduceOptions0, stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Unknown option: edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory
         //
         verifyException("edu.stanford.nlp.parser.lexparser.Options", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromFile()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", shiftReduceOptions0);
      assertNotSame(lexicalizedParser1, lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testGetParserFromSerializedFileAndSaveParserToSerializedAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromSerializedFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      assertFalse(lexicalizedParser1.requiresTags());
  }

  @Test(timeout = 4000)
  public void testCopyLexicalizedParserThrowsIllegalArgumentException()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      OutsideRuleFilter.reverse(arrayList0);
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("C");
      FileSystemHandling.appendLineToFile(evoSuiteFile0, "-testtreebank");
      String[] stringArray0 = new String[6];
      stringArray0[0] = "-testtreebank";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "A,K15E|NZV(g_3F";
      stringArray0[3] = "-testtreebank";
      stringArray0[3] = "-testtreebank";
      stringArray0[5] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Constructor argument not valid list of number ranges: A,K15E|NZV(g_3F
         //
         verifyException("edu.stanford.nlp.io.NumberRangesFileFilter", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray28()  throws Throwable  {
      String[] stringArray0 = new String[6];
      stringArray0[0] = "-testtreebank";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingNoArgumentsThrowsNullPointerException()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-tokenized";
      stringArray0[1] = "Cr";
      stringArray0[2] = "-tokenized";
      stringArray0[3] = "-tokenized";
      stringArray0[4] = "Cr";
      stringArray0[5] = "Cr";
      stringArray0[6] = "Cr";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray30()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-tokenized";
      LexicalizedParser.main(stringArray0);
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testParseMultipleTaking2Arguments()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      List<Tree> list0 = lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) arrayList0, 100);
      assertEquals(0, list0.size());
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFileAndSaveParserToSerializedAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      String string0 = LexicalizedParser.DEFAULT_PARSER_LOC;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      lexicalizedParser0.saveParserToTextFile("edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz");
      // Undeclared exception!
      try { 
        lexicalizedParser0.getTreePrint();
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFileWithNull()  throws Throwable  {
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      DiskTreebank diskTreebank0 = italianTreebankParserParams0.diskTreebank();
      Options options0 = new Options(italianTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      lexicalizedParser0.getLexicon();
      LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, options0);
      // Undeclared exception!
      try { 
        lexicalizedParser0.saveParserToTextFile((String) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFileAndTrainFromTreebankTaking11And12()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray29()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-sentences";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankAndGetParserFromTreebankWithZeroAndGetParserFromTreebankWithNonEmptyList()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, false);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      hebrewTreebankParserParams0.inputEncoding = "";
      Vector<List<TaggedWord>> vector1 = new Vector<List<TaggedWord>>();
      vector1.setSize(100);
      // Undeclared exception!
      try { 
        LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, 0.0, exactGrammarCompactor0, options0, memoryTreebank0, vector1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"java.util.List.iterator()\" because \"sentence\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.BaseLexicon", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankWithNonEmptyListAndNonNull()  throws Throwable  {
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      vector0.setSize(100);
      // Undeclared exception!
      try { 
        LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, 0.0, exactGrammarCompactor0, options0, memoryTreebank0, vector0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"java.util.List.iterator()\" because \"sentence\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.BaseLexicon", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankAndMainWithNonEmptyArray()  throws Throwable  {
      String[] stringArray0 = new String[1];
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, ">6O%Q");
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      MemoryTreebank memoryTreebank0 = englishTreebankParserParams0.memoryTreebank();
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      AmericanizeFunction americanizeFunction0 = new AmericanizeFunction();
      shiftReduceOptions0.wordFunction = (Function<String, String>) americanizeFunction0;
      Options options0 = spanishUnknownWordModelTrainer0.op;
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, memoryTreebank0, shiftReduceOptions0);
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankWithNonNull0()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      PennTreebankLanguagePack pennTreebankLanguagePack0 = new PennTreebankLanguagePack();
      Function<String, String> function0 = pennTreebankLanguagePack0.getBasicCategoryFunction();
      shiftReduceOptions0.wordFunction = function0;
      // Undeclared exception!
      try { 
        LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank((Treebank) null, (Treebank) null, (Treebank) null, shiftReduceOptions0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.trees.Treebank.transform(edu.stanford.nlp.trees.TreeTransformer)\" because \"trainTreebank\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testRequiresTags()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      assertFalse(lexicalizedParser0.requiresTags());
      
      boolean boolean0 = lexicalizedParser0.requiresTags();
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void testGetTLPParamsAndRequiresTags()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options(englishTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, true);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      Vector<List<TaggedWord>> vector1 = new Vector<List<TaggedWord>>();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("` >>9;t", true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("!", (FileFilter) extensionFileFilter0, options0);
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      lexicalizedParser1.parseMultiple((List<? extends List<? extends HasWord>>) vector1);
      lexicalizedParser1.requiresTags();
      TreebankLangParserParams treebankLangParserParams0 = lexicalizedParser0.getTLPParams();
      assertEquals("UTF-8", treebankLangParserParams0.getInputEncoding());
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1AndSaveParserToSerializedWithNonEmptyString()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("Ud_s<");
      FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      OutsideRuleFilter.reverse(arrayList0);
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("BEGIN", false);
      extensionFileFilter0.getDescription();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("BEGIN", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      // Undeclared exception!
      try { 
        lexicalizedParser0.saveParserToSerialized("Ud_s<");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.io.IOException: Simulated IOException
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetLexiconThrowsNoClassDefFoundError()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.TestOptions testOptions0 = new edu.stanford.nlp.parser.lexparser.TestOptions();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      DiskTreebank diskTreebank0 = englishTreebankParserParams0.diskTreebank();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, true, false);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (GrammarCompactor) exactGrammarCompactor0, (Options) shiftReduceOptions0);
      Stack<String> stack0 = new Stack<String>();
      stack0.add("");
      // Undeclared exception!
      try { 
        lexicalizedParser0.parseStrings(stack0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseStringsWithNonEmptyList()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      List<String> list0 = List.of("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      // Undeclared exception!
      try { 
        lexicalizedParser0.parseStrings(list0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseMultipleTakingListAndParseMultipleTakingListWithNonEmptyListAndTrainFromTreebankTaking11And1WithNonNull()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter(" cTags=", true);
      vector0.add((List<TaggedWord>) null);
      Options options1 = new Options(options0.tlpParams);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("J29Kq;q{!mml:5U", (FileFilter) extensionFileFilter0, options1);
      // Undeclared exception!
      try { 
        lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) vector0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testParseMultipleTakingListAndGetExtraEvals()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      Stack<BasicDocument<CategoryWordTag>> stack0 = new Stack<BasicDocument<CategoryWordTag>>();
      lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) stack0);
      List<Eval> list0 = lexicalizedParser0.getExtraEvals();
      assertEquals(0, list0.size());
  }

  @Test(timeout = 4000)
  public void testSetOptionFlags()  throws Throwable  {
      Stack<String> stack0 = new Stack<String>();
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      DiskTreebank diskTreebank0 = italianTreebankParserParams0.diskTreebank();
      Options options0 = new Options(italianTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      lexicalizedParser0.parseStrings(stack0);
      lexicalizedParser0.getLexicon();
      // Undeclared exception!
      try { 
        lexicalizedParser0.setOptionFlags((String[]) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read the array length because \"flags\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.Options", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileThrowsIllegalArgumentException()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      String[] stringArray0 = new String[1];
      stringArray0[0] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Unknown option: edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory
         //
         verifyException("edu.stanford.nlp.parser.lexparser.Options", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserQueryEvals()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      List<ParserQueryEval> list0 = lexicalizedParser0.getParserQueryEvals();
      assertTrue(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testGetParserQueryEvalsAndGetParserQueryEvals()  throws Throwable  {
      byte[] byteArray0 = new byte[8];
      byteArray0[0] = (byte)87;
      byteArray0[1] = (byte)53;
      byteArray0[2] = (byte)82;
      byteArray0[3] = (byte) (-4);
      byteArray0[4] = (byte)73;
      byteArray0[5] = (byte)35;
      byteArray0[6] = (byte) (-123);
      byteArray0[7] = (byte)45;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("Error loading segmenter, exiting...");
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("-train", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      List<ParserQueryEval> list0 = lexicalizedParser0.getParserQueryEvals();
      assertTrue(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray30()  throws Throwable  {
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-num";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankWithNullAndParseStrings()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser.buildTrainTransformer((Options) shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.TestOptions testOptions0 = new edu.stanford.nlp.parser.lexparser.TestOptions();
      ShiftReduceOptions shiftReduceOptions1 = new ShiftReduceOptions();
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      shiftReduceOptions1.distance = true;
      DiskTreebank diskTreebank0 = englishTreebankParserParams0.diskTreebank();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, false);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (GrammarCompactor) exactGrammarCompactor0, (Options) shiftReduceOptions1);
      Stack<String> stack0 = new Stack<String>();
      lexicalizedParser0.parseStrings(stack0);
      // Undeclared exception!
      LexicalizedParser.getParserFromTreebank(diskTreebank0, diskTreebank0, 0.0, exactGrammarCompactor0, shiftReduceOptions1, diskTreebank0, (List<List<TaggedWord>>) null);
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankAndLoadModelTaking1And1WithNonEmptyString()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      MemoryTreebank memoryTreebank0 = englishTreebankParserParams0.memoryTreebank();
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      Options options0 = spanishUnknownWordModelTrainer0.op;
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, memoryTreebank0, shiftReduceOptions0);
      String[] stringArray0 = new String[7];
      stringArray0[0] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[3] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[4] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[5] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[6] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", false);
      LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      NegraPennTreebankParserParams negraPennTreebankParserParams0 = new NegraPennTreebankParserParams();
      DiskTreebank diskTreebank0 = negraPennTreebankParserParams0.diskTreebank();
      Triple<Treebank, Treebank, Treebank> triple0 = LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(diskTreebank0, (Treebank) null, diskTreebank0, shiftReduceOptions0);
      assertNotNull(triple0);
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebank()  throws Throwable  {
      DiskTreebank diskTreebank0 = new DiskTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      Triple<Treebank, Treebank, Treebank> triple0 = LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(diskTreebank0, diskTreebank0, diskTreebank0, shiftReduceOptions0);
      assertNotNull(triple0);
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankWithNonNull1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      // Undeclared exception!
      try { 
        LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank((Treebank) null, (Treebank) null, (Treebank) null, shiftReduceOptions0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.trees.Treebank.transform(edu.stanford.nlp.trees.TreeTransformer)\" because \"trainTreebank\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetLexiconAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      Lexicon lexicon0 = lexicalizedParser0.getLexicon();
      assertEquals(0, lexicon0.numRules());
  }

  @Test(timeout = 4000)
  public void testGetLexiconAndParseStrings()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser.buildTrainTransformer((Options) shiftReduceOptions0);
      TestOptions testOptions0 = new TestOptions();
      ShiftReduceOptions shiftReduceOptions1 = new ShiftReduceOptions();
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      shiftReduceOptions1.distance = true;
      DiskTreebank diskTreebank0 = englishTreebankParserParams0.diskTreebank();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, false);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (GrammarCompactor) exactGrammarCompactor0, (Options) shiftReduceOptions1);
      Stack<String> stack0 = new Stack<String>();
      lexicalizedParser0.parseStrings(stack0);
      Lexicon lexicon0 = lexicalizedParser0.getLexicon();
      assertEquals(0, lexicon0.numRules());
  }

  @Test(timeout = 4000)
  public void testParseStrings()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      Vector<String> vector0 = new Vector<String>();
      Tree tree0 = lexicalizedParser0.parseStrings(vector0);
      assertEquals(Double.NaN, tree0.score(), 0.01);
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ReturningNull()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ShiftReduceParser shiftReduceParser0 = new ShiftReduceParser(shiftReduceOptions0);
      // Undeclared exception!
      try { 
        shiftReduceParser0.getOp();
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
      }
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1WithNull()  throws Throwable  {
      String[] stringArray0 = new String[4];
      stringArray0[0] = "C";
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("C", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("cp: could not list files in source: ");
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      Options options0 = new Options();
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("*U$5{", options0, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testGetTLPParams()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      TreebankLangParserParams treebankLangParserParams0 = lexicalizedParser0.getTLPParams();
      assertEquals("UTF-8", treebankLangParserParams0.getOutputEncoding());
  }

  @Test(timeout = 4000)
  public void testTreebankLanguagePack()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      TreebankLanguagePack treebankLanguagePack0 = lexicalizedParser0.treebankLanguagePack();
      assertTrue(treebankLanguagePack0.supportsGrammaticalStructures());
  }

  @Test(timeout = 4000)
  public void testTreebankLanguagePackAndBuildTrainTransformerTakingOptionsAndTreebankLanguagePack()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser.buildTrainTransformer((Options) shiftReduceOptions0);
      RegExFileFilter regExFileFilter0 = new RegExFileFilter("C");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("C", (FileFilter) regExFileFilter0, (Options) shiftReduceOptions0);
      TreebankLanguagePack treebankLanguagePack0 = lexicalizedParser0.treebankLanguagePack();
      assertFalse(treebankLanguagePack0.generateOriginalDependencies());
  }

  @Test(timeout = 4000)
  public void testParserQuery()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      ParserQuery parserQuery0 = lexicalizedParser0.parserQuery();
      assertEquals(Double.NEGATIVE_INFINITY, parserQuery0.getPCFGScore(), 0.01);
  }

  @Test(timeout = 4000)
  public void testParserQueryAndGetExtraEvals()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      OutsideRuleFilter.reverse(arrayList0);
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("Ud_s<", false);
      extensionFileFilter0.getDescription();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/Users/amirdeljouyi/se/llm-powered-unit-test-generation-for-nlp-libraries/benchmark");
      FileSystemHandling.setPermissions(evoSuiteFile0, false, true, false);
      extensionFileFilter0.getDescription();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("Ud_s<", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.parserQuery();
      lexicalizedParser0.saveParserToSerialized("(7P%feQ=zs[E6L|Oe8X");
      ShiftReduceOptions shiftReduceOptions1 = new ShiftReduceOptions();
      List<Eval> list0 = lexicalizedParser0.getExtraEvals();
      assertTrue(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankWithEmptyListAndNonNull()  throws Throwable  {
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      Stack<List<TaggedWord>> stack0 = new Stack<List<TaggedWord>>();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(100);
      // Undeclared exception!
      LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, 0.0, exactGrammarCompactor0, options0, memoryTreebank0, stack0);
  }

  @Test(timeout = 4000)
  public void testBuildTrainTransformerTaking2Arguments()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.TestOptions testOptions0 = new edu.stanford.nlp.parser.lexparser.TestOptions();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser.buildTrainTransformer((Options) shiftReduceOptions0);
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("BEGINBEGIN");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("b[x.]dE`tGmE7p:WE", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      TreeAnnotatorAndBinarizer treeAnnotatorAndBinarizer0 = LexicalizedParser.buildTrainBinarizer(shiftReduceOptions0);
      LexicalizedParser.buildTrainTransformer((Options) shiftReduceOptions0, treeAnnotatorAndBinarizer0);
      // Undeclared exception!
      try { 
        lexicalizedParser0.saveParserToSerialized((String) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankWithNull()  throws Throwable  {
      String string0 = null;
      String string1 = "OJCV1!";
      String[] stringArray0 = new String[6];
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      MemoryTreebank memoryTreebank0 = englishTreebankParserParams0.memoryTreebank();
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      Options options0 = spanishUnknownWordModelTrainer0.op;
      // Undeclared exception!
      try { 
        LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, memoryTreebank0, (Options) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"tlpParams\" because \"op\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainAndMainWithEmptyArray()  throws Throwable  {
      Options options0 = new Options();
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      OutsideRuleFilter.reverse(arrayList0);
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("Ud_s<", false);
      String[] stringArray0 = new String[0];
      LexicalizedParser.main(stringArray0);
      boolean boolean0 = FileSystemHandling.shouldAllThrowIOExceptions();
      assertTrue(boolean0);
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithEmptyArray()  throws Throwable  {
      String[] stringArray0 = new String[0];
      LexicalizedParser.main(stringArray0);
      assertEquals(0, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testGetExtraEvalsAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      List<Eval> list0 = lexicalizedParser0.getExtraEvals();
      assertEquals(0, list0.size());
  }

  @Test(timeout = 4000)
  public void testGetExtraEvals()  throws Throwable  {
      Options options0 = new Options();
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      OutsideRuleFilter.reverse(arrayList0);
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("Ud_s<", false);
      extensionFileFilter0.getDescription();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("Ud_s<", (FileFilter) extensionFileFilter0, options0);
      lexicalizedParser0.saveParserToSerialized("(7P%feQ=zs[E6L|Oe8X");
      NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new NPTmpRetainingTreeNormalizer(90, true, 100, true, true);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(nPTmpRetainingTreeNormalizer0);
      Stack<BasicDocument<Object>> stack0 = new Stack<BasicDocument<Object>>();
      Stack<Tree> stack1 = new Stack<Tree>();
      lexicalizedParser0.getExtraEvals();
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      Options options1 = spanishUnknownWordModelTrainer0.op;
      LexicalizedParser lexicalizedParser1 = (LexicalizedParser)edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromFile("BEGIN", (edu.stanford.nlp.parser.lexparser.Options) null);
      assertNull(lexicalizedParser1);
  }

  @Test(timeout = 4000)
  public void testLexicalizedParserQueryAndTrainFromTreebankTaking11And1WithNull()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      LexicalizedParserQuery lexicalizedParserQuery0 = lexicalizedParser0.lexicalizedParserQuery();
      assertFalse(lexicalizedParserQuery0.parseSkipped());
  }

  @Test(timeout = 4000)
  public void testGetOpAndGetParserFromFile()  throws Throwable  {
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "CRForder");
      NumberRangeFileFilter numberRangeFileFilter0 = new NumberRangeFileFilter(5, 1355, true);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "BEGINBEGIN";
      stringArray0[1] = "CRForder";
      stringArray0[2] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[3] = "Mm-] 0YXpt";
      stringArray0[4] = "o|GkI[hlt3W";
      stringArray0[5] = "o|GkI[hlt3W";
      stringArray0[6] = "o|GkI[hlt3W";
      shiftReduceOptions0.setOptionsOrWarn(stringArray0);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("o|GkI[hlt3W", (FileFilter) numberRangeFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.getOp();
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking2ArgumentsReturningLexicalizedParserWhereRequiresTagsIsFalse()  throws Throwable  {
      String[] stringArray0 = new String[1];
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      hebrewTreebankParserParams0.collinizerEvalb();
      DiskTreebank diskTreebank0 = hebrewTreebankParserParams0.diskTreebank();
      LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (Options) shiftReduceOptions0);
      String[] stringArray1 = new String[4];
      stringArray1[0] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray1[1] = "k;";
      stringArray1[2] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray1[3] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("k;", stringArray1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking2ArgumentsAndTrainFromTreebankTaking2ArgumentsWithNull()  throws Throwable  {
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      OutsideRuleFilter.reverse(arrayList0);
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      Options options0 = spanishUnknownWordModelTrainer0.op;
      // Undeclared exception!
      try { 
        LexicalizedParser.trainFromTreebank((Treebank) null, (Options) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1AndTrainFromTreebankTaking11And1WithNonNull()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, true, false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (GrammarCompactor) exactGrammarCompactor0, (Options) shiftReduceOptions0);
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testSaveParserToSerializedAndTrainFromTreebankTaking11And1()  throws Throwable  {
      Options options0 = new Options();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "T-shirt";
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      OutsideRuleFilter.reverse(arrayList0);
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("T-shirt", true);
      extensionFileFilter0.getDescription();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("@4#g:~WVB-x");
      FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("T-shirt", (FileFilter) extensionFileFilter0, options0);
      lexicalizedParser0.saveParserToSerialized("<4~n");
      NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new NPTmpRetainingTreeNormalizer(100, false, 320, false, true);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(nPTmpRetainingTreeNormalizer0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, true);
      LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("@4#g:~WVB-x", stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ReturningNullAndLoadModelTaking1And1()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "T-shirt";
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      OutsideRuleFilter.reverse(arrayList0);
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("T-shirt", true);
      Vector<String> vector0 = new Vector<String>();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.loadModel("p\"=W", (List<String>) vector0);
      assertNull(lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankWithPositive()  throws Throwable  {
      FileSystemHandling.shouldAllThrowIOExceptions();
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory();
      DiskTreebank diskTreebank0 = new DiskTreebank(72, pennTreeReaderFactory0);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, true, true);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      // Undeclared exception!
      LexicalizedParser.getParserFromTreebank(diskTreebank0, diskTreebank0, 72, exactGrammarCompactor0, shiftReduceOptions0, diskTreebank0, vector0);
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1ReturningLexicalizedParserWhereRequiresTagsIsFalse()  throws Throwable  {
      Options options0 = new Options();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "T-shirt";
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      OutsideRuleFilter.reverse(arrayList0);
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("T-shirt", true);
      LexicalizedParser.trainFromTreebank("T-shirt", (FileFilter) extensionFileFilter0, options0);
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel("@4#g:~WVB-x", stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray31()  throws Throwable  {
      Options options0 = new Options();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("Z6%&d");
      FileSystemHandling.appendLineToFile(evoSuiteFile0, "BEGIN");
      String[] stringArray0 = new String[5];
      stringArray0[0] = "Z6%&d";
      stringArray0[1] = "p\"=W";
      stringArray0[2] = "Z6%&d";
      stringArray0[3] = "BEGIN";
      stringArray0[4] = "Z6%&d";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromSerializedFileAndGetParserFromSerializedFile()  throws Throwable  {
      String string0 = null;
      LexicalizedParser.getParserFromSerializedFile((String) null);
      // Undeclared exception!
      try { 
        LexicalizedParser.copyLexicalizedParser((LexicalizedParser) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"lex\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileAndBuildTrainTransformerTakingOptions()  throws Throwable  {
      Options options0 = new Options();
      LexicalizedParser.loadModel();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser.getParserFromTextFile("!j @`tWl!1", options0);
      HashIndex<CoreLabel> hashIndex0 = new HashIndex<CoreLabel>(100);
      CompositeTreeTransformer compositeTreeTransformer0 = LexicalizedParser.buildTrainTransformer((Options) shiftReduceOptions0);
      assertNotNull(compositeTreeTransformer0);
  }

  @Test(timeout = 4000)
  public void testCopyLexicalizedParserThrowsNullPointerException()  throws Throwable  {
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser((edu.stanford.nlp.parser.lexparser.LexicalizedParser) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"lex\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingNoArgumentsAndCopyLexicalizedParserWithNull()  throws Throwable  {
      LexicalizedParser.loadModel();
      // Undeclared exception!
      try { 
        LexicalizedParser.copyLexicalizedParser((LexicalizedParser) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"lex\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileWithNonEmptyStringAndNonNull()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      // Undeclared exception!
      try { 
        LexicalizedParser.getParserFromTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", shiftReduceOptions0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory: expecting BEGIN block; got \uFFFD\uFFFD\u0000\u0005sr\u00003edu.stanford.nlp.parser.lexparser.LexicalizedParser\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0002\u0002\u0000\tL\u0000\u0002bgt\u00001Ledu/stanford/nlp/parser/lexparser/BinaryGrammar;L\u0000\u0002dgt\u00005Ledu/stanford/nlp/parser/lexparser/DependencyGrammar;L\u0000\u0003lext\u0000+Ledu/stanford/nlp/parser/lexparser/Lexicon;L\u0000\u0002opt\u0000+Ledu/stanford/nlp/parser/lexparser/Options;L\u0000\brerankert\u0000,Ledu/stanford/nlp/parser/lexparser/Reranker;L\u0000
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1WithNonEmptyStringAndNonEmptyArray()  throws Throwable  {
      String string0 = "com";
      String[] stringArray0 = new String[7];
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("com", stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // com: expecting BEGIN block; got end of file.
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileAndSaveParserToTextFileAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", shiftReduceOptions0);
      assertFalse(lexicalizedParser1.requiresTags());
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray32()  throws Throwable  {
      String[] stringArray0 = new String[3];
      stringArray0[0] = "Z6%&d";
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("Z6%&d");
      FileSystemHandling.appendLineToFile(evoSuiteFile0, "p\"=W");
      stringArray0[1] = "p\"=W";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Z6%&d: expecting BEGIN block; got p\"=W
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1WithNull()  throws Throwable  {
      Options options0 = new Options();
      CompositeTreeTransformer compositeTreeTransformer0 = LexicalizedParser.buildTrainTransformer(options0);
      assertNotNull(compositeTreeTransformer0);
      
      LexicalizedParser.loadModel();
      Properties properties0 = options0.testOptions.evals;
      SeqClassifierFlags seqClassifierFlags0 = new SeqClassifierFlags(properties0, true);
      List<String> list0 = seqClassifierFlags0.comboProps;
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel((String) null, list0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Attempt to open file with null name
         //
         verifyException("edu.stanford.nlp.io.IOUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1AndLoadModelTaking1And1WithNonEmptyStringAndLoadModelTaking1And1WithEmptyList()  throws Throwable  {
      Stack<String> stack0 = new Stack<String>();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.loadModel("bF:v^{", (List<String>) stack0);
      assertNull(lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testParseThrowsNullPointerException()  throws Throwable  {
      String string0 = "P3=:&NW_$\"";
      String[] stringArray0 = new String[6];
      stringArray0[0] = "P3=:&NW_$\"";
      String string1 = "i('OJ^x%\\c*)[k";
      stringArray0[1] = "i('OJ^x%c*)[k";
      String string2 = ": ";
      stringArray0[2] = ": ";
      stringArray0[3] = "P3=:&NW_$\"";
      HashIndex<CoreLabel> hashIndex0 = new HashIndex<CoreLabel>();
      hashIndex0.unmodifiableView();
      hashIndex0.objectsList();
      String string3 = "Yg./a*7I0";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("Yg./a*7I0", (List<String>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"java.util.List.size()\" because \"extraFlags\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1AndTrainFromTreebankTaking11And1WithNull()  throws Throwable  {
      String[] stringArray0 = new String[6];
      stringArray0[0] = "P3=:&NW_$\"";
      stringArray0[1] = "i('OJ^x%c*)[k";
      stringArray0[2] = ": ";
      ArrayList<BasicDocument<Object>> arrayList0 = new ArrayList<BasicDocument<Object>>();
      OutsideRuleFilter.reverse(arrayList0);
      int int0 = (-798);
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("&_,N8J4r", false);
      // Undeclared exception!
      try { 
        LexicalizedParser.trainFromTreebank("SPY|6W*)#", (FileFilter) extensionFileFilter0, (Options) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray31()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      Options options0 = new Options(hebrewTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, false);
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      Vector<List<TaggedWord>> vector1 = new Vector<List<TaggedWord>>();
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-escaper";
      stringArray0[1] = "{v+U";
      stringArray0[2] = "BEGINBEGIN UNARY_GRAMMAR";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainAndMainWithNonEmptyArray()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-tLPP";
      LexicalizedParser.main(stringArray0);
      String[] stringArray1 = new String[20];
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray33()  throws Throwable  {
      String[] stringArray0 = new String[4];
      stringArray0[0] = "C";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1AndLoadModelTaking1And1WithNonNullAndLoadModelTaking1And1WithNonEmptyArray()  throws Throwable  {
      Options options0 = new Options();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "b&,";
      stringArray0[1] = "*;vbS";
      stringArray0[2] = "";
      stringArray0[3] = "";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel(options0, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileReturningNull()  throws Throwable  {
      LexicalizedParser.getParserFromTextFile("cAzQz41T7'#V,j5|Xqu", (Options) null);
      TestOptions testOptions0 = new TestOptions();
      Properties properties0 = testOptions0.evals;
      PresetSequenceClassifier<CoreLabel> presetSequenceClassifier0 = new PresetSequenceClassifier<CoreLabel>(properties0);
      LinkedList<CoreLabel> linkedList0 = new LinkedList<CoreLabel>();
      CoreLabelTokenFactory coreLabelTokenFactory0 = new CoreLabelTokenFactory(false);
      Object object0 = new Object();
      Object object1 = new Object();
      properties0.put(object0, object1);
      // Undeclared exception!
      try { 
        coreLabelTokenFactory0.makeToken((String[]) null, (String[]) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read the array length because \"keys\" is null
         //
         verifyException("edu.stanford.nlp.ling.CoreLabel", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking3ArgumentsAndLoadModelTaking3ArgumentsWithNull()  throws Throwable  {
      String[] stringArray0 = new String[6];
      stringArray0[0] = "P3=:&NW_$\"";
      stringArray0[1] = "i('OJ^x%c*)[k";
      stringArray0[2] = ": ";
      stringArray0[3] = "P3=:&NW_$\"";
      stringArray0[4] = "P3=:&NW_$\"";
      stringArray0[5] = "P3=:&NW_$\"";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("P3=:&NW_$\"", (Options) null, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testBuildTrainBinarizerAndBuildTrainBinarizerWithNull()  throws Throwable  {
      Options options0 = null;
      // Undeclared exception!
      try { 
        LexicalizedParser.buildTrainBinarizer((Options) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testBuildTrainBinarizerAndBuildTrainBinarizerWithNonNull()  throws Throwable  {
      Options options0 = new Options();
      TreeAnnotatorAndBinarizer treeAnnotatorAndBinarizer0 = LexicalizedParser.buildTrainBinarizer(options0);
      assertNotNull(treeAnnotatorAndBinarizer0);
  }

  @Test(timeout = 4000)
  public void testBuildTrainTransformerTakingOptionsAndBuildTrainTransformerTakingOptions()  throws Throwable  {
      Options options0 = new Options();
      LexicalizedParser.buildTrainTransformer(options0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel();
      options0.freeDependencies = false;
      options0.directional = true;
      String string0 = "2[X _AHk+i^$bVi";
      String[] stringArray0 = new String[7];
      stringArray0[0] = "2[X _AHk+i^$bVi";
      stringArray0[1] = "2[X _AHk+i^$bVi";
      stringArray0[2] = "2[X _AHk+i^$bVi";
      stringArray0[3] = "";
      stringArray0[4] = "2[X _AHk+i^$bVi";
      stringArray0[5] = "prep_to";
      stringArray0[6] = "2[X _AHk+i^$bVi";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("2[X _AHk+i^$bVi", stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray32()  throws Throwable  {
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-parseinside";
      stringArray0[2] = "-sentences";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsStringIndexOutOfBoundsException()  throws Throwable  {
      String[] stringArray0 = new String[4];
      stringArray0[0] = "";
      stringArray0[1] = "gY";
      stringArray0[2] = ";x6mx-QU6jw";
      stringArray0[3] = "3'ycK@Ye/+eGg4|;0";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: StringIndexOutOfBoundsException");
      
      } catch(StringIndexOutOfBoundsException e) {
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException()  throws Throwable  {
      String[] stringArray0 = new String[1];
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ThrowsNullPointerException()  throws Throwable  {
      String[] stringArray0 = new String[1];
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel("y@Gy(x|b6", stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testDefaultCoreNLPFlagsThrowsNullPointerException()  throws Throwable  {
      String[] stringArray0 = new String[7];
      stringArray0[0] = "BEGIN ";
      stringArray0[1] = "BEGIN ";
      stringArray0[2] = "BEGIN ";
      stringArray0[3] = "BEGIN ";
      stringArray0[4] = "BEGIN ";
      stringArray0[5] = "BEGIN ";
      stringArray0[6] = "BEGIN ";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel("BEGIN ", stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }
}
