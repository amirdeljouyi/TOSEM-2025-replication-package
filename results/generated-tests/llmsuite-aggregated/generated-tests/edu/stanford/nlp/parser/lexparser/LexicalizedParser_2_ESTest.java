/*
 * This file was automatically generated by UTestGen and EvoSuite
 * Wed Apr 16 05:39:47 GMT 2025
 */

package edu.stanford.nlp.parser.lexparser;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.shaded.org.mockito.Mockito.*;
import static org.evosuite.runtime.EvoAssertions.*;
import edu.stanford.nlp.io.ExtensionFileFilter;
import edu.stanford.nlp.io.NumberRangeFileFilter;
import edu.stanford.nlp.io.NumberRangesFileFilter;
import edu.stanford.nlp.io.RegExFileFilter;
import edu.stanford.nlp.ling.BasicDocument;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.ling.HasWord;
import edu.stanford.nlp.ling.TaggedWord;
import edu.stanford.nlp.ling.WordLemmaTag;
import edu.stanford.nlp.parser.common.ParserQuery;
import edu.stanford.nlp.parser.lexparser.BinaryGrammar;
import edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.DependencyGrammar;
import edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor;
import edu.stanford.nlp.parser.lexparser.GrammarCompactor;
import edu.stanford.nlp.parser.lexparser.HebrewTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.HungarianTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.LexicalizedParser;
import edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery;
import edu.stanford.nlp.parser.lexparser.Lexicon;
import edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.Options;
import edu.stanford.nlp.parser.lexparser.OutsideRuleFilter;
import edu.stanford.nlp.parser.lexparser.SpanishTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.SpanishUnknownWordModelTrainer;
import edu.stanford.nlp.parser.lexparser.TrainOptions;
import edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer;
import edu.stanford.nlp.parser.lexparser.TreebankLangParserParams;
import edu.stanford.nlp.parser.lexparser.UnaryGrammar;
import edu.stanford.nlp.parser.lexparser.UnknownWordModel;
import edu.stanford.nlp.parser.metrics.Eval;
import edu.stanford.nlp.parser.metrics.ParserQueryEval;
import edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions;
import edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser;
import edu.stanford.nlp.parser.shiftreduce.ShiftReduceTrainOptions;
import edu.stanford.nlp.process.AmericanizeFunction;
import edu.stanford.nlp.process.CoreLabelTokenFactory;
import edu.stanford.nlp.sequences.SeqClassifierFlags;
import edu.stanford.nlp.sequences.TrueCasingForNISTDocumentReaderAndWriter;
import edu.stanford.nlp.trees.BobChrisTreeNormalizer;
import edu.stanford.nlp.trees.CompositeTreeTransformer;
import edu.stanford.nlp.trees.DiskTreebank;
import edu.stanford.nlp.trees.FilteringTreebank;
import edu.stanford.nlp.trees.LeftHeadFinder;
import edu.stanford.nlp.trees.MemoryTreebank;
import edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer;
import edu.stanford.nlp.trees.PennTreebankLanguagePack;
import edu.stanford.nlp.trees.TransformingTreebank;
import edu.stanford.nlp.trees.Tree;
import edu.stanford.nlp.trees.TreeGraphNode;
import edu.stanford.nlp.trees.TreeReaderFactory;
import edu.stanford.nlp.trees.Treebank;
import edu.stanford.nlp.trees.TreebankLanguagePack;
import edu.stanford.nlp.trees.WordStemmer;
import edu.stanford.nlp.util.HashIndex;
import edu.stanford.nlp.util.Pair;
import edu.stanford.nlp.util.Triple;
import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;
import java.io.EOFException;
import java.io.File;
import java.io.FileFilter;
import java.io.FileNotFoundException;
import java.io.InputStream;
import java.io.ObjectInputStream;
import java.io.ObjectOutputStream;
import java.util.ArrayList;
import java.util.Comparator;
import java.util.LinkedList;
import java.util.List;
import java.util.Locale;
import java.util.Properties;
import java.util.Stack;
import java.util.Vector;
import java.util.function.Consumer;
import java.util.function.Function;
import java.util.function.Predicate;
import java.util.regex.Pattern;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.Random;
import org.evosuite.runtime.System;
import org.evosuite.runtime.ViolatedAssumptionAnswer;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.mock.java.io.MockFileInputStream;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.EvoSuiteURL;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.evosuite.runtime.testdata.NetworkHandling;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, separateClassLoader = true) 
public class LexicalizedParser_2_ESTest extends LexicalizedParser_2_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void testLoadModelTakingObjectInputStreamWithNonNull0()  throws Throwable  {
      ByteArrayOutputStream byteArrayOutputStream0 = new ByteArrayOutputStream();
      ObjectOutputStream objectOutputStream0 = new ObjectOutputStream(byteArrayOutputStream0);
      objectOutputStream0.writeBoolean(false);
      objectOutputStream0.writeObject("This is not a parser");
      objectOutputStream0.close();
      byte[] byteArray0 = byteArrayOutputStream0.toByteArray();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      ByteArrayInputStream byteArrayInputStream0 = new ByteArrayInputStream(byteArray0);
      ObjectInputStream objectInputStream0 = new ObjectInputStream(byteArrayInputStream0);
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel(objectInputStream0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.io.OptionalDataException
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-tune";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // MemoryTreebank.processFile IOException in file edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory
         //
         verifyException("edu.stanford.nlp.trees.MemoryTreebank", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray0()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-tune";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // MemoryTreebank.processFile IOException in file edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory
         //
         verifyException("edu.stanford.nlp.trees.MemoryTreebank", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebank()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ShiftReduceTrainOptions shiftReduceTrainOptions0 = (ShiftReduceTrainOptions)shiftReduceOptions0.trainOptions;
      shiftReduceTrainOptions0.trainTreeFile = "*UNK*";
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      assertFalse(lexicalizedParser0.requiresTags());
      
      Vector<List<TaggedWord>> vector0 = new Vector<List<TaggedWord>>();
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, 1.0E-40, (GrammarCompactor) null, shiftReduceOptions0, (Treebank) null, vector0);
      assertNotSame(lexicalizedParser1, lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankWithNullAndGetParserFromTreebank()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(100);
      shiftReduceOptions0.doDep = false;
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, true);
      ArrayList<List<edu.stanford.nlp.ling.TaggedWord>> arrayList0 = new ArrayList<List<edu.stanford.nlp.ling.TaggedWord>>();
      LexicalizedParser.getParserFromTreebank(memoryTreebank0, (Treebank) null, 100, exactGrammarCompactor0, shiftReduceOptions0, (Treebank) null, arrayList0);
      Stack<Tree> stack0 = new Stack<Tree>();
      assertTrue(stack0.empty());
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1AndGetParserFromFile()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      DiskTreebank diskTreebank0 = italianTreebankParserParams0.diskTreebank();
      Options options0 = new Options(italianTreebankParserParams0);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, options0);
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser.getParserFromFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", options0);
      String[] stringArray0 = new String[0];
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", stringArray0);
      assertFalse(lexicalizedParser1.requiresTags());
  }

  @Test(timeout = 4000)
  public void testGetParserFromSerializedFileReturningLexicalizedParserWhereRequiresTagsIsFalse()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      shiftReduceOptions0.baseParserWeight = (-1.0);
      String[] stringArray0 = new String[1];
      edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams italianTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams();
      italianTreebankParserParams0.memoryTreebank();
  }

  @Test(timeout = 4000)
  public void testGetTreePrintThrowsNullPointerException()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      NetworkHandling.createRemoteTextFile((EvoSuiteURL) null, "~ew");
      BobChrisTreeNormalizer.EmptyFilter bobChrisTreeNormalizer_EmptyFilter0 = new BobChrisTreeNormalizer.EmptyFilter();
      Predicate<Tree> predicate0 = bobChrisTreeNormalizer_EmptyFilter0.negate();
      FilteringTreebank filteringTreebank0 = new FilteringTreebank((Treebank) null, predicate0);
      AmericanizeFunction americanizeFunction0 = new AmericanizeFunction();
      shiftReduceOptions0.wordFunction = (Function<String, String>) americanizeFunction0;
      // Undeclared exception!
      try { 
        LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank((Treebank) null, (Treebank) null, (Treebank) null, shiftReduceOptions0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.trees.Treebank.transform(edu.stanford.nlp.trees.TreeTransformer)\" because \"trainTreebank\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testBuildTrainBinarizerAndBuildTrainTransformerTaking2Arguments()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      PennTreebankLanguagePack pennTreebankLanguagePack0 = new PennTreebankLanguagePack();
      Function<String, String> function0 = pennTreebankLanguagePack0.getBasicCategoryFunction();
      shiftReduceOptions0.wordFunction = function0;
      TreeAnnotatorAndBinarizer treeAnnotatorAndBinarizer0 = LexicalizedParser.buildTrainBinarizer(shiftReduceOptions0);
      CompositeTreeTransformer compositeTreeTransformer0 = LexicalizedParser.buildTrainTransformer((Options) shiftReduceOptions0, treeAnnotatorAndBinarizer0);
      assertNotNull(compositeTreeTransformer0);
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking2Arguments0()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank("edu.stanford.nlp.parser.lexparser.EnglishUnknownWordModel");
      Stack<WordLemmaTag> stack0 = new Stack<WordLemmaTag>();
      Options options0 = new Options();
      TrainOptions trainOptions0 = new TrainOptions();
      trainOptions0.trainTreeFile = "-TAG";
      options0.trainOptions = trainOptions0;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, options0);
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFileAndTrainFromTreebankTaking2ArgumentsAndMainWithNonEmptyArray0()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-savetoserializedfile";
      stringArray0[1] = "-savetoserializedfile";
      stringArray0[2] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFileAndTrainFromTreebankTaking2ArgumentsAndMainWithNonEmptyArray1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-savetoserializedfile";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetTLPParamsAndGetParserFromFile()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(100);
      TreebankLanguagePack treebankLanguagePack0 = shiftReduceOptions0.langpack();
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams(treebankLanguagePack0);
      Options options0 = new Options(hebrewTreebankParserParams0);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, options0);
      lexicalizedParser0.saveParserToTextFile("Mark PRD.\n");
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromFile("Mark PRD.\n", options0);
      TreebankLangParserParams treebankLangParserParams0 = lexicalizedParser1.getTLPParams();
      assertFalse(treebankLangParserParams0.supportsBasicDependencies());
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray1()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-train2";
      stringArray0[1] = "kEe";
      stringArray0[2] = "-train2";
      stringArray0[3] = "-train2";
      stringArray0[4] = "-train2";
      stringArray0[5] = "-train2";
      stringArray0[6] = "-train2";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -train2
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray2()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-train2";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[...]\" is null
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testTreebankLanguagePackReturningTreebankLanguagePackWhereSupportsGrammaticalStructuresIsFalse()  throws Throwable  {
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-sentences";
      edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams italianTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = italianTreebankParserParams0.diskTreebank();
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options(italianTreebankParserParams0);
      // Undeclared exception!
      try { 
        diskTreebank0.printFileNames();
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
      }
  }

  @Test(timeout = 4000)
  public void testGetTreePrintReturningNonNull()  throws Throwable  {
      Vector<WordLemmaTag> vector0 = new Stack<WordLemmaTag>();
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      Lexicon lexicon0 = null;
      try {  
      lexicon0 = spanishUnknownWordModelTrainer0.lex;
      } catch(IllegalArgumentException e) {}
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray3()  throws Throwable  {
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-tune";
      stringArray0[1] = "newline";
      stringArray0[2] = "-tune";
      stringArray0[3] = "-tune";
      stringArray0[4] = "HWH@OfF";
      stringArray0[5] = "-tune";
      stringArray0[6] = "-tune";
      stringArray0[7] = "-tune";
      stringArray0[8] = "-tune";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -tune
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingObjectInputStreamWithNonNull1()  throws Throwable  {
      byte[] byteArray0 = new byte[25];
      byteArray0[0] = (byte) 172;
      byteArray0[1] = (byte) 237;
      byteArray0[2] = (byte) 0;
      byteArray0[3] = (byte) 5;
      byteArray0[4] = (byte) 115;
      byteArray0[5] = (byte) 114;
      byteArray0[6] = (byte) 0;
      byteArray0[7] = (byte) 4;
      byteArray0[8] = (byte) 84;
      byteArray0[9] = (byte) 101;
      byteArray0[10] = (byte) 115;
      byteArray0[11] = (byte) 116;
      byteArray0[12] = (byte) 0;
      byteArray0[13] = (byte) 0;
      byteArray0[14] = (byte) 0;
      byteArray0[15] = (byte) 0;
      byteArray0[16] = (byte) 0;
      byteArray0[17] = (byte) 0;
      byteArray0[18] = (byte) 0;
      byteArray0[19] = (byte) 1;
      byteArray0[20] = (byte) 2;
      byteArray0[21] = (byte) 0;
      byteArray0[22] = (byte) 0;
      byteArray0[23] = (byte) 120;
      byteArray0[24] = (byte) 112;
      ByteArrayInputStream byteArrayInputStream0 = new ByteArrayInputStream(byteArray0);
      ObjectInputStream objectInputStream0 = new ObjectInputStream(byteArrayInputStream0);
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel(objectInputStream0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.lang.ClassNotFoundException: Class 'Test.class' should be in target project, but could not be found!
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1AndLoadModelTaking1And1WithNonNullAndLoadModelTaking1And1WithEmptyArray()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      String[] stringArray0 = new String[0];
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.loadModel((Options) shiftReduceOptions0, stringArray0);
      assertNull(lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testCreatesLexicalizedParserAndSaveParserToTextFile()  throws Throwable  {
      Lexicon lexicon0 = mock(Lexicon.class, new ViolatedAssumptionAnswer());
      doReturn((UnknownWordModel) null).when(lexicon0).getUnknownWordModel();
      BinaryGrammar binaryGrammar0 = mock(BinaryGrammar.class, new ViolatedAssumptionAnswer());
      UnaryGrammar unaryGrammar0 = mock(UnaryGrammar.class, new ViolatedAssumptionAnswer());
      HashIndex<String> hashIndex0 = new HashIndex<String>();
      boolean boolean0 = hashIndex0.add("S");
      HashIndex<String> hashIndex1 = new HashIndex<String>();
      hashIndex1.add("word");
      HashIndex<String> hashIndex2 = new HashIndex<String>();
      hashIndex2.add("NN");
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = new LexicalizedParser(lexicon0, binaryGrammar0, unaryGrammar0, (DependencyGrammar) null, hashIndex0, hashIndex1, hashIndex2, options0);
      lexicalizedParser0.saveParserToTextFile("temp_text_grammar.txt");
      File file0 = new File("temp_text_grammar.txt");
      file0.exists();
      boolean boolean1 = file0.delete();
      assertFalse(boolean1 == boolean0);
  }

  @Test(timeout = 4000)
  public void testGetParserFromFile0()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      DiskTreebank diskTreebank0 = new DiskTreebank(100);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (Options) shiftReduceOptions0);
      lexicalizedParser0.dg = null;
      lexicalizedParser0.saveParserToTextFile("~:DcN&");
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromFile("M50SM4aDVKE Uo", shiftReduceOptions0);
      assertNull(lexicalizedParser1);
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingObjectInputStream()  throws Throwable  {
      ByteArrayOutputStream byteArrayOutputStream0 = new ByteArrayOutputStream();
      ObjectOutputStream objectOutputStream0 = new ObjectOutputStream(byteArrayOutputStream0);
      objectOutputStream0.writeObject("This is not a parser");
      objectOutputStream0.close();
      byte[] byteArray0 = byteArrayOutputStream0.toByteArray();
      ByteArrayInputStream byteArrayInputStream0 = new ByteArrayInputStream(byteArray0);
      ObjectInputStream objectInputStream0 = new ObjectInputStream(byteArrayInputStream0);
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel(objectInputStream0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // Wanted LexicalizedParser, got class java.lang.String
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray4()  throws Throwable  {
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-escaper";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseMultipleTaking2ArgumentsWithNonEmptyList()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ArrayList<List<edu.stanford.nlp.ling.TaggedWord>> arrayList0 = new ArrayList<List<edu.stanford.nlp.ling.TaggedWord>>();
      LinkedList<edu.stanford.nlp.ling.TaggedWord> linkedList0 = new LinkedList<edu.stanford.nlp.ling.TaggedWord>();
      arrayList0.add((List<edu.stanford.nlp.ling.TaggedWord>) linkedList0);
      Options.LexOptions options_LexOptions0 = new Options.LexOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter((String) null);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      List<Tree> list0 = lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) arrayList0, 0);
      assertFalse(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingObjectInputStreamAndSaveParserToSerializedAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.featureFactoryClass = "BEGINBEGIN STATE_INDEX";
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("BEGINBEGIN STATE_INDEX", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("BEGINBEGIN STATE_INDEX");
      String[] stringArray0 = new String[1];
      MockFile mockFile0 = new MockFile("BEGINBEGIN STATE_INDEX");
      MockFileInputStream mockFileInputStream0 = new MockFileInputStream(mockFile0);
      ObjectInputStream objectInputStream0 = new ObjectInputStream(mockFileInputStream0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel(objectInputStream0);
      stringArray0[0] = "BEGINBEGIN STATE_INDEX";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseMultipleTakingListReturningListWhereIsEmptyIsFalse()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      ArrayList<List<edu.stanford.nlp.ling.TaggedWord>> arrayList0 = new ArrayList<List<edu.stanford.nlp.ling.TaggedWord>>();
      LinkedList<edu.stanford.nlp.ling.TaggedWord> linkedList0 = new LinkedList<edu.stanford.nlp.ling.TaggedWord>();
      arrayList0.add((List<edu.stanford.nlp.ling.TaggedWord>) linkedList0);
      Options.LexOptions options_LexOptions0 = new Options.LexOptions();
      lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) arrayList0);
      String[] stringArray0 = new String[6];
      stringArray0[0] = null;
      stringArray0[1] = null;
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "");
      stringArray0[2] = null;
      stringArray0[3] = null;
      stringArray0[4] = null;
      stringArray0[5] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseMultipleTakingListWithNonEmptyList()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(100);
      byte[] byteArray0 = new byte[2];
      byteArray0[1] = (byte)120;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, true);
      ArrayList<List<edu.stanford.nlp.ling.TaggedWord>> arrayList0 = new ArrayList<List<edu.stanford.nlp.ling.TaggedWord>>();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.getParserFromTreebank(memoryTreebank0, (Treebank) null, 100, exactGrammarCompactor0, shiftReduceOptions0, (Treebank) null, arrayList0);
      LinkedList<edu.stanford.nlp.ling.TaggedWord> linkedList0 = new LinkedList<edu.stanford.nlp.ling.TaggedWord>();
      arrayList0.add((List<edu.stanford.nlp.ling.TaggedWord>) linkedList0);
      lexicalizedParser0.lexicalizedParserQuery();
      lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) arrayList0);
      List<ParserQueryEval> list0 = lexicalizedParser0.getParserQueryEvals();
      assertEquals(0, list0.size());
  }

  @Test(timeout = 4000)
  public void testParseMultipleTakingListWithEmptyList()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      ArrayList<List<edu.stanford.nlp.ling.TaggedWord>> arrayList0 = new ArrayList<List<edu.stanford.nlp.ling.TaggedWord>>();
      Options.LexOptions options_LexOptions0 = new Options.LexOptions();
      lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) arrayList0);
      shiftReduceOptions0.lexOptions = options_LexOptions0;
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", options0);
      assertFalse(lexicalizedParser1.requiresTags());
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFileAndTrainFromTreebankTaking11And1WithNonNull()  throws Throwable  {
      RegExFileFilter regExFileFilter0 = new RegExFileFilter("-savetraintrees.z");
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("-~}P", (FileFilter) regExFileFilter0, (Options) shiftReduceOptions0);
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      lexicalizedParser1.saveParserToTextFile("AO\"");
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-~}P";
      stringArray0[1] = "AO\"";
      stringArray0[2] = "";
      stringArray0[2] = "*Cy[";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Unknown option: -~}P
         //
         verifyException("edu.stanford.nlp.parser.lexparser.Options", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseMultipleTakingListReturningListWhereIsEmptyIsTrue()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      ArrayList<List<edu.stanford.nlp.ling.TaggedWord>> arrayList0 = new ArrayList<List<edu.stanford.nlp.ling.TaggedWord>>();
      String[] stringArray0 = new String[1];
      edu.stanford.nlp.parser.lexparser.Options.LexOptions options_LexOptions0 = new edu.stanford.nlp.parser.lexparser.Options.LexOptions();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) arrayList0);
      FileSystemHandling.appendLineToFile(evoSuiteFile0, (String) null);
      shiftReduceOptions0.lexOptions = (Options.LexOptions) options_LexOptions0;
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1WithNonNullAndNonNull()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      Stack<List<edu.stanford.nlp.ling.TaggedWord>> stack0 = new Stack<List<edu.stanford.nlp.ling.TaggedWord>>();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, true, true);
  }

  @Test(timeout = 4000)
  public void test()  throws Throwable  {
      Stack<CoreLabel> stack0 = new Stack<CoreLabel>();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LinkedList<List<edu.stanford.nlp.ling.TaggedWord>> linkedList0 = new LinkedList<List<edu.stanford.nlp.ling.TaggedWord>>();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, true);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankWithNegative()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions1 = new ShiftReduceOptions();
      Locale.getISOCountries();
      LinkedList<List<edu.stanford.nlp.ling.TaggedWord>> linkedList0 = new LinkedList<List<edu.stanford.nlp.ling.TaggedWord>>();
      CoreLabelTokenFactory coreLabelTokenFactory0 = new CoreLabelTokenFactory(true);
      CoreLabel coreLabel0 = coreLabelTokenFactory0.makeToken(">I5;5edq._7pG%]lF3", 100, 100);
      TreeGraphNode treeGraphNode0 = new TreeGraphNode(coreLabel0, memoryTreebank0);
      ArrayList<edu.stanford.nlp.ling.TaggedWord> arrayList0 = treeGraphNode0.yieldHasWord();
      linkedList0.add((List<edu.stanford.nlp.ling.TaggedWord>) arrayList0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor((Options) null, true, true);
      // Undeclared exception!
      try { 
        LexicalizedParser.getParserFromTreebank(memoryTreebank0, (Treebank) null, (-2216.140974589), exactGrammarCompactor0, shiftReduceOptions0, (Treebank) null, linkedList0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // class edu.stanford.nlp.ling.CoreLabel cannot be cast to class edu.stanford.nlp.ling.TaggedWord (edu.stanford.nlp.ling.CoreLabel and edu.stanford.nlp.ling.TaggedWord are in unnamed module of loader org.evosuite.instrumentation.InstrumentingClassLoader @4c23dcea)
         //
         verifyException("edu.stanford.nlp.parser.lexparser.BaseLexicon", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromFileReturningLexicalizedParserWhereRequiresTagsIsFalse()  throws Throwable  {
      Stack<CoreLabel> stack0 = new Stack<CoreLabel>();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      WordStemmer wordStemmer0 = new WordStemmer();
      memoryTreebank0.apply(wordStemmer0);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      String[] stringArray0 = new String[1];
      lexicalizedParser0.lexicalizedParserQuery();
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1AndMain()  throws Throwable  {
      RegExFileFilter regExFileFilter0 = new RegExFileFilter("-savetraintrees.gz");
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("-~}P", (FileFilter) regExFileFilter0, (Options) shiftReduceOptions0);
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      lexicalizedParser1.saveParserToTextFile("-sentences");
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-~}P";
      stringArray0[1] = "-sentences";
      stringArray0[2] = "\u00B6";
      stringArray0[2] = "*Cy[";
      LexicalizedParser.main(stringArray0);
      Properties properties0 = shiftReduceOptions0.testOptions.evals;
      SeqClassifierFlags seqClassifierFlags0 = new SeqClassifierFlags(properties0, false);
      List<String> list0 = seqClassifierFlags0.gazettes;
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel("-sentences", list0);
  }

  @Test(timeout = 4000)
  public void testParseMultipleTaking2ArgumentsReturningListWhereIsEmptyIsFalse()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ArrayList<List<edu.stanford.nlp.ling.TaggedWord>> arrayList0 = new ArrayList<List<edu.stanford.nlp.ling.TaggedWord>>();
      LinkedList<edu.stanford.nlp.ling.TaggedWord> linkedList0 = new LinkedList<edu.stanford.nlp.ling.TaggedWord>();
      arrayList0.add((List<edu.stanford.nlp.ling.TaggedWord>) linkedList0);
      arrayList0.add((List<edu.stanford.nlp.ling.TaggedWord>) linkedList0);
      edu.stanford.nlp.parser.lexparser.Options.LexOptions options_LexOptions0 = new edu.stanford.nlp.parser.lexparser.Options.LexOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter((String) null);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) arrayList0, 0);
      ParserQuery parserQuery0 = lexicalizedParser0.parserQuery();
      assertEquals(Double.NEGATIVE_INFINITY, parserQuery0.getBestScore(), 0.01);
  }

  @Test(timeout = 4000)
  public void testParseMultipleTaking2ArgumentsWithPositive()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      ArrayList<List<edu.stanford.nlp.ling.TaggedWord>> arrayList0 = new ArrayList<List<edu.stanford.nlp.ling.TaggedWord>>();
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.trainFromTreebank("|'0jC-R8B-q|a", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser1.parseMultiple((List<? extends List<? extends HasWord>>) arrayList0, 100);
      // Undeclared exception!
      try { 
        lexicalizedParser0.saveParserToTextFile((String) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testParseMultipleTaking2ArgumentsReturningListWhereIsEmptyIsTrue()  throws Throwable  {
      Stack<CoreLabel> stack0 = new Stack<CoreLabel>();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      String[] stringArray0 = ItalianTreebankParserParams.EMPTY_SISTERS;
      shiftReduceOptions0.featureFactoryClass = "WHADVP";
      LinkedList<List<edu.stanford.nlp.ling.TaggedWord>> linkedList0 = new LinkedList<List<edu.stanford.nlp.ling.TaggedWord>>();
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor((edu.stanford.nlp.parser.lexparser.Options) null, false, false);
  }

  @Test(timeout = 4000)
  public void testParseMultipleTaking2ArgumentsWithEmptyList()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ArrayList<List<edu.stanford.nlp.ling.TaggedWord>> arrayList0 = new ArrayList<List<edu.stanford.nlp.ling.TaggedWord>>();
      Options.LexOptions options_LexOptions0 = new Options.LexOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter((String) null, true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      List<Tree> list0 = lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) arrayList0, 0);
      assertTrue(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileReturningLexicalizedParserWhereRequiresTagsIsFalse()  throws Throwable  {
      Options options0 = new Options();
      RegExFileFilter regExFileFilter0 = new RegExFileFilter("-savetraintrees.gz");
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) regExFileFilter0, (Options) shiftReduceOptions0);
      LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank((TreeReaderFactory) null, "SUCCESS: wrote model to ");
      NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new NPTmpRetainingTreeNormalizer(100, false, 100, true);
      memoryTreebank0.transform(nPTmpRetainingTreeNormalizer0);
      shiftReduceOptions0.featureFactoryClass = "SUCCESS: wrote model to ";
  }

  @Test(timeout = 4000)
  public void testMain0()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("4xU'C");
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-tune";
      stringArray0[1] = "|XZ'p,fH#j'o]sNNa";
      stringArray0[2] = "\u00B6";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Constructor argument not valid list of number ranges: \u00B6
         //
         verifyException("edu.stanford.nlp.io.NumberRangesFileFilter", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray5()  throws Throwable  {
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-tune";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[...]\" is null
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndTrainFromTreebankTaking11And1WithNonEmptyString()  throws Throwable  {
      edu.stanford.nlp.io.RegExFileFilter regExFileFilter0 = new edu.stanford.nlp.io.RegExFileFilter("]3@?Wr");
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray6()  throws Throwable  {
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-sentences";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray7()  throws Throwable  {
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-sentences";
      stringArray0[1] = "-sentences";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndSaveParserToTextFile()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("-savetraintrees");
      Options options0 = new Options();
      ArrayList<List<edu.stanford.nlp.ling.TaggedWord>> arrayList0 = new ArrayList<List<edu.stanford.nlp.ling.TaggedWord>>();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-savetraintrees";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "-savetraintrees";
      stringArray0[3] = "";
      LexicalizedParser.main(stringArray0);
      assertEquals(4, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMain1()  throws Throwable  {
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-^Vmenc";
      stringArray0[1] = "-savetraintrees";
      stringArray0[2] = "-^Vmenc";
      stringArray0[3] = "-^Vmenc";
      LexicalizedParser.main(stringArray0);
      assertEquals(4, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain0()  throws Throwable  {
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-tagseparator";
      stringArray0[1] = "[2 lqZ";
      stringArray0[2] = "Eg@%gmJ,CsRfaA@.";
      stringArray0[3] = "N;oA@?L?FE[c/Fg^A";
      stringArray0[4] = " V_;H_";
      stringArray0[5] = "-tesdlttreebank";
      stringArray0[6] = "hil<1?lgnU'6r'Y}";
      stringArray0[7] = "l>ks";
      stringArray0[8] = "BEGINBEGIN WORD_INDEX";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMain2()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-tagSeparator";
      shiftReduceOptions0.directional = false;
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMain3()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-savetoserializedfile";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "-savetoserializedfile";
      LexicalizedParser.main(stringArray0);
      assertEquals(3, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray8()  throws Throwable  {
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-tokenizerfactory";
      stringArray0[1] = "-^Vmenc";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMain4()  throws Throwable  {
      NegraPennTreebankParserParams negraPennTreebankParserParams0 = new NegraPennTreebankParserParams();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-traintreebank";
      stringArray0[1] = "bRQ.j/xy";
      stringArray0[2] = "# distsim: Distributional similarity classes can be an added source of information";
      stringArray0[3] = ": expecting BEGIN block; got ";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Constructor argument not valid list of number ranges: # distsim: Distributional similarity classes can be an added source of information
         //
         verifyException("edu.stanford.nlp.io.NumberRangesFileFilter", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray9()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-traintreebank";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -train
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMain0()  throws Throwable  {
      Options options0 = new Options();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("-tokenizeroptions");
      String[] stringArray0 = new String[6];
      stringArray0[0] = "-tokenizeroptions";
      stringArray0[1] = "-tokenizeroptions";
      stringArray0[2] = "-tokenizeroptions";
      stringArray0[4] = "-tokenizeroptions";
      stringArray0[5] = "-tokenizeroptions";
      LexicalizedParser.main(stringArray0);
      assertEquals(6, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainWithNonEmptyArray10()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-tokenizerOptions";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentException0()  throws Throwable  {
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-train";
      String string0 = "S0LWT-";
      stringArray0[1] = "S0LWT-";
      stringArray0[2] = "-train";
      stringArray0[3] = "-train";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -train
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMain5()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-savetoserializedfile";
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainAndTrainFromTreebankTaking11And1()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      edu.stanford.nlp.io.ExtensionFileFilter extensionFileFilter0 = new edu.stanford.nlp.io.ExtensionFileFilter("-tesDlttreebank");
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("-tesDlttreebank", (FileFilter) extensionFileFilter0, options0);
      Stack<String> stack0 = new Stack<String>();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-tesDlttreebank";
      stringArray0[1] = "-savetoserializedfile";
      stringArray0[2] = "-tesDlttreebank";
      stringArray0[3] = "-tesDlttreebank";
      stringArray0[4] = "-tesDlttreebank";
      stringArray0[5] = "-tesDlttreebank";
      stringArray0[6] = "-tesDlttreebank";
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
      assertEquals(7, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMain6()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-encoding";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ReturningNull()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(shiftReduceOptions0, true, false);
      edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams negraPennTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams();
      negraPennTreebankParserParams0.diskTreebank();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromFile(".gz", shiftReduceOptions0);
      String[] stringArray0 = new String[0];
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel((edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0, stringArray0);
      assertNull(lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testRequiresTagsThrowsIllegalArgumentException()  throws Throwable  {
      Stack<edu.stanford.nlp.ling.CoreLabel> stack0 = new Stack<edu.stanford.nlp.ling.CoreLabel>();
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank();
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, options0);
      lexicalizedParser0.parseTree(stack0);
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-train";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -train
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentException1()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-train";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -train
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain1()  throws Throwable  {
      NumberRangeFileFilter numberRangeFileFilter0 = new NumberRangeFileFilter(951, (-1460577869), true);
      HungarianTreebankParserParams hungarianTreebankParserParams0 = new HungarianTreebankParserParams();
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      ArrayList<List<TaggedWord>> arrayList0 = new ArrayList<List<TaggedWord>>();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-model";
      stringArray0[2] = "-model";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException0()  throws Throwable  {
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-model";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException1()  throws Throwable  {
      String[] stringArray0 = new String[10];
      stringArray0[0] = "-savetotextfile";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException2()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams negraPennTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-testtreebank";
      stringArray0[1] = "Ya#?";
      stringArray0[2] = "-testAtreebank";
      stringArray0[3] = "1&w";
      stringArray0[4] = "Invalid class in file: ";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndSaveParserToSerialized()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      edu.stanford.nlp.io.ExtensionFileFilter extensionFileFilter0 = new edu.stanford.nlp.io.ExtensionFileFilter("-loadfromserializedfile", false);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("-loadfromserializedfile", (FileFilter) extensionFileFilter0, options0);
      options0.useUnigramWordSmoothing = false;
      lexicalizedParser0.saveParserToSerialized("Q8<-IT");
      Vector<String> vector0 = new Vector<String>();
      String[] stringArray0 = new String[6];
      stringArray0[0] = "-loadfromserializedfile";
      stringArray0[1] = "-loadfromserializedfile";
      stringArray0[2] = "-loadfromserializedfile";
      stringArray0[3] = "Couldn't instantiate: ";
      stringArray0[4] = "-loadfromserializedfile";
      stringArray0[5] = "-loadfromserializedfile";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException3()  throws Throwable  {
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-model";
      stringArray0[2] = "-model";
      stringArray0[3] = "-model";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndTrainFromTreebankTaking11And1()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      edu.stanford.nlp.io.ExtensionFileFilter extensionFileFilter0 = new edu.stanford.nlp.io.ExtensionFileFilter("-loadfromserializedfile", false);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("-loadfromserializedfile", (FileFilter) extensionFileFilter0, options0);
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-loadfromserializedfile";
      stringArray0[1] = "-loadfromserializedfile";
      stringArray0[2] = "-loadfromserializedfile";
      stringArray0[3] = "-loadfromserializedfile";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsArrayIndexOutOfBoundsException0()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      edu.stanford.nlp.parser.lexparser.Options options1 = new edu.stanford.nlp.parser.lexparser.Options(options0.tlpParams);
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-loadfromserializedfile";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testBuildTrainTransformerTaking2ArgumentsThrowsArrayIndexOutOfBoundsException()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams negraPennTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams();
      edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams negraPennTreebankParserParams1 = new edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams();
      negraPennTreebankParserParams1.diskTreebank();
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options(negraPennTreebankParserParams0);
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-savetotextfile";
      stringArray0[1] = "-loadFromTextFile";
      stringArray0[2] = "-loadFromTextFile";
      stringArray0[3] = "-loadFromTextFile";
      stringArray0[4] = "-loadFromTextFile";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 5 out of bounds for length 5
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsArrayIndexOutOfBoundsException1()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-loadfromtextfile";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankThrowsIllegalArgumentException()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams negraPennTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams();
      negraPennTreebankParserParams0.diskTreebank();
      negraPennTreebankParserParams0.collinizer();
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options(negraPennTreebankParserParams0);
      Consumer<Object> consumer0 = (Consumer<Object>) mock(Consumer.class, new ViolatedAssumptionAnswer());
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-tokenized";
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromSerializedFile("-tokenized");
      Random.setNextRandom(100);
      String string0 = " has an unexpected number of =s";
      NumberRangesFileFilter numberRangesFileFilter0 = null;
      try {
        numberRangesFileFilter0 = new NumberRangesFileFilter("-tokenized", false);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Constructor argument not valid list of number ranges: -tokenized
         //
         verifyException("edu.stanford.nlp.io.NumberRangesFileFilter", e);
      }
  }

  @Test(timeout = 4000)
  public void testMain7()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams italianTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-tokenized";
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentExceptionAndMain0()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      edu.stanford.nlp.parser.lexparser.Options options1 = new edu.stanford.nlp.parser.lexparser.Options(options0.tlpParams);
      ArrayList<List<TaggedWord>> arrayList0 = new ArrayList<List<TaggedWord>>();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-treebank";
      stringArray0[1] = "AX@v*";
      stringArray0[2] = "-tokenizerFactory";
      stringArray0[3] = "-loadfrmserilizedfile";
      stringArray0[4] = "-savetoserializedfile";
      stringArray0[5] = "-loadfrmserilizedfile";
      stringArray0[6] = "-treebank";
      stringArray0[7] = "-treebank";
      stringArray0[8] = "-loadfrmserilizedfile";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -test
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentException2()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-treebank";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -test
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsArrayIndexOutOfBoundsExceptionAndMain()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams negraPennTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = negraPennTreebankParserParams0.diskTreebank();
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options(negraPennTreebankParserParams0);
      Consumer<Object> consumer0 = (Consumer<Object>) mock(Consumer.class, new ViolatedAssumptionAnswer());
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      diskTreebank0.forEach(consumer0);
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(options0, false, false);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) diskTreebank0, (edu.stanford.nlp.parser.lexparser.GrammarCompactor) exactGrammarCompactor0, options0);
      edu.stanford.nlp.io.ExtensionFileFilter extensionFileFilter0 = new edu.stanford.nlp.io.ExtensionFileFilter("-parseinside", false);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("-parseinside", (FileFilter) extensionFileFilter0, options0);
      lexicalizedParser1.getExtraEvals();
      lexicalizedParser0.lexicalizedParserQuery();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-parseinside";
      stringArray0[1] = "-parseinside";
      stringArray0[2] = "-parseinside";
      stringArray0[3] = "-parseinside";
      stringArray0[4] = "-parseinside";
      stringArray0[5] = "-parseinside";
      stringArray0[6] = "-parseinside";
      stringArray0[7] = "-parseinside";
      stringArray0[8] = "-parseinside";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 9 out of bounds for length 9
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsRuntimeException()  throws Throwable  {
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-parseInside";
      stringArray0[1] = "-tlpp";
      stringArray0[2] = "-tlpp";
      stringArray0[3] = "-^Vmenc";
      stringArray0[4] = "-tlpp";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.lang.ClassNotFoundException: Class '-^Vmenc.class' should be in target project, but could not be found!
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMain1()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams negraPennTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams();
      negraPennTreebankParserParams0.diskTreebank();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-~}P";
      stringArray0[1] = "-~}P";
      stringArray0[2] = "-~}P";
      stringArray0[3] = "-~}P";
      stringArray0[4] = "-~}P";
      stringArray0[5] = "-tokenizermethod";
      stringArray0[6] = "-~}P";
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
      assertEquals(7, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsArrayIndexOutOfBoundsException2()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-tokenizermethod";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankThrowsIllegalArgumentException()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams negraPennTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = negraPennTreebankParserParams0.diskTreebank();
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options(negraPennTreebankParserParams0);
      Consumer<Object> consumer0 = (Consumer<Object>) mock(Consumer.class, new ViolatedAssumptionAnswer());
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      diskTreebank0.forEach(consumer0);
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(options0, false, false);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) diskTreebank0, (edu.stanford.nlp.parser.lexparser.GrammarCompactor) exactGrammarCompactor0, options0);
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-testtreebank";
      stringArray0[1] = "Training a parser from treebank dir: ";
      stringArray0[2] = "C=o72uW";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Constructor argument not valid list of number ranges: C=o72uW
         //
         verifyException("edu.stanford.nlp.io.NumberRangesFileFilter", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentException3()  throws Throwable  {
      String[] stringArray0 = new String[1];
      FileSystemHandling.shouldAllThrowIOExceptions();
      stringArray0[0] = "-testtreebank";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -test
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankThrowsNullPointerException()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = new edu.stanford.nlp.trees.DiskTreebank();
      LinkedList<List<TaggedWord>> linkedList0 = new LinkedList<List<TaggedWord>>();
      linkedList0.addLast((List<TaggedWord>) null);
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromTreebank(diskTreebank0, diskTreebank0, 100, (edu.stanford.nlp.parser.lexparser.GrammarCompactor) null, shiftReduceOptions0, diskTreebank0, linkedList0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"java.util.List.iterator()\" because \"sentence\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.BaseLexicon", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsRuntimeExceptionAndMain()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams negraPennTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = negraPennTreebankParserParams0.diskTreebank();
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options(negraPennTreebankParserParams0);
      Consumer<Object> consumer0 = (Consumer<Object>) mock(Consumer.class, new ViolatedAssumptionAnswer());
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      diskTreebank0.forEach(consumer0);
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(options0, false, false);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) diskTreebank0, (edu.stanford.nlp.parser.lexparser.GrammarCompactor) exactGrammarCompactor0, options0);
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-tlpp";
      stringArray0[1] = "-~}P";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.lang.ClassNotFoundException: Class '-~}P.class' should be in target project, but could not be found!
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndGetExtraEvalsAndTrainFromTreebankTaking11And1()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams negraPennTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = negraPennTreebankParserParams0.diskTreebank();
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options(negraPennTreebankParserParams0);
      Consumer<Object> consumer0 = (Consumer<Object>) mock(Consumer.class, new ViolatedAssumptionAnswer());
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      Consumer<Object> consumer1 = (Consumer<Object>) mock(Consumer.class, new ViolatedAssumptionAnswer());
      diskTreebank0.forEach(consumer1);
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(options0, true, false);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) diskTreebank0, (edu.stanford.nlp.parser.lexparser.GrammarCompactor) exactGrammarCompactor0, options0);
      lexicalizedParser0.getExtraEvals();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-tlpp";
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException4()  throws Throwable  {
      String[] stringArray0 = new String[27];
      stringArray0[0] = "-tlpp";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
      }
  }

  @Test(timeout = 4000)
  public void testMain8()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-tlpp";
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testGetTLPParamsAndGetTLPParamsAndTrainFromTreebankTaking11And1()  throws Throwable  {
      edu.stanford.nlp.io.ExtensionFileFilter extensionFileFilter0 = new edu.stanford.nlp.io.ExtensionFileFilter("Tags are: ");
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("Tags are: ", (FileFilter) extensionFileFilter0, options0);
      assertFalse(lexicalizedParser0.requiresTags());
      
      edu.stanford.nlp.parser.lexparser.Options.LexOptions options_LexOptions0 = new edu.stanford.nlp.parser.lexparser.Options.LexOptions();
      options0.lexOptions = options_LexOptions0;
      Vector<String> vector0 = new Vector<String>();
      edu.stanford.nlp.parser.lexparser.TreebankLangParserParams treebankLangParserParams0 = lexicalizedParser0.getTLPParams();
      assertEquals("UTF-8", treebankLangParserParams0.getOutputEncoding());
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentExceptionAndSaveParserToTextFile()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("40d+7%qz90pP4.gz", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      lexicalizedParser1.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-test";
      stringArray0[1] = "40d+7%qz90pP4.gz";
      stringArray0[2] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[3] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[4] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -test
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMain9()  throws Throwable  {
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-test";
      stringArray0[1] = "GES!Ql6&Xx{HvS";
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testDefaultCoreNLPFlagsReturningEmptyArray()  throws Throwable  {
      ChineseTreebankParserParams chineseTreebankParserParams0 = new ChineseTreebankParserParams();
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options(chineseTreebankParserParams0);
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(options0, true, true);
      edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams negraPennTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = negraPennTreebankParserParams0.diskTreebank();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) diskTreebank0, (edu.stanford.nlp.parser.lexparser.GrammarCompactor) exactGrammarCompactor0, options0);
      lexicalizedParser0.defaultCoreNLPFlags();
      LinkedList<List<TaggedWord>> linkedList0 = new LinkedList<List<TaggedWord>>();
      // Undeclared exception!
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromTreebank(diskTreebank0, diskTreebank0, 2432.27732746, exactGrammarCompactor0, options0, diskTreebank0, linkedList0);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankThrowsTooManyResourcesExceptionAndMain()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(shiftReduceOptions0, true, false);
      edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams negraPennTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = negraPennTreebankParserParams0.diskTreebank();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) diskTreebank0, (edu.stanford.nlp.parser.lexparser.GrammarCompactor) exactGrammarCompactor0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      String[] stringArray0 = lexicalizedParser0.defaultCoreNLPFlags();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
      LinkedList<List<TaggedWord>> linkedList0 = new LinkedList<List<TaggedWord>>();
      // Undeclared exception!
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromTreebank(diskTreebank0, diskTreebank0, 100, (edu.stanford.nlp.parser.lexparser.GrammarCompactor) null, shiftReduceOptions0, diskTreebank0, linkedList0);
  }

  @Test(timeout = 4000)
  public void testGetOpAndGetOp()  throws Throwable  {
      edu.stanford.nlp.io.ExtensionFileFilter extensionFileFilter0 = new edu.stanford.nlp.io.ExtensionFileFilter("!g-^{&Ai", true);
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("0cCQ]X4_g<kOr", (FileFilter) extensionFileFilter0, options0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      edu.stanford.nlp.parser.lexparser.Options options1 = lexicalizedParser1.getOp();
      assertFalse(options1.nodePrune);
  }

  @Test(timeout = 4000)
  public void testParseStringsThrowsNoClassDefFoundError()  throws Throwable  {
      edu.stanford.nlp.io.ExtensionFileFilter extensionFileFilter0 = new edu.stanford.nlp.io.ExtensionFileFilter("Tags are: ");
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("Tags are: ", (FileFilter) extensionFileFilter0, options0);
      Vector<String> vector0 = new Vector<String>();
      vector0.add("Tags are: ");
      // Undeclared exception!
      try { 
        lexicalizedParser0.parseStrings(vector0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFileAndMainThrowsNullPointerException()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("P!", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("LVt:}_.gz");
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      lexicalizedParser0.saveParserToTextFile("LVt:}_.gz");
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options(shiftReduceOptions0.tlpParams);
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor((edu.stanford.nlp.parser.lexparser.Options) null, false, false);
      ArrayList<List<TaggedWord>> arrayList0 = new ArrayList<List<TaggedWord>>();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "uxzX7<o1( R";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[3] = "q@8M4";
      stringArray0[4] = "P!";
      stringArray0[5] = "v";
      stringArray0[6] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[7] = "";
      stringArray0[8] = "";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFileAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank(100);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("Z&zC.gz");
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingNoArgumentsThrowsNullPointerException()  throws Throwable  {
      FileSystemHandling.shouldAllThrowIOExceptions();
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel((ObjectInputStream) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"java.io.ObjectInputStream.readObject()\" because \"ois\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNoClassDefFoundErrorAndCopyLexicalizedParser()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("v");
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options(shiftReduceOptions0.tlpParams);
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(shiftReduceOptions0, false, false);
      ArrayList<List<TaggedWord>> arrayList0 = new ArrayList<List<TaggedWord>>();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "v";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromFileAndSaveParserToSerializedAndTrainFromTreebankTaking11And1()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      assertFalse(lexicalizedParser0.requiresTags());
      
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      assertFalse(lexicalizedParser0.requiresTags());
      
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", shiftReduceOptions0);
      assertFalse(lexicalizedParser1.requiresTags());
  }

  @Test(timeout = 4000)
  public void testGetExtraEvalsThrowsNoClassDefFoundError()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      String[] stringArray0 = new String[1];
      stringArray0[0] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseThrowsNullPointerException()  throws Throwable  {
      String string0 = "";
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      // Undeclared exception!
      try { 
        lexicalizedParser0.parse((List<? extends edu.stanford.nlp.ling.HasWord>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"java.util.List.iterator()\" because \"words\" is null
         //
         verifyException("edu.stanford.nlp.parser.common.ParserUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testSetOptionFlagsAndBuildTrainTransformerTakingOptions()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.HebrewTreebankParserParams hebrewTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.HebrewTreebankParserParams();
      edu.stanford.nlp.trees.TreeReaderFactory treeReaderFactory0 = hebrewTreebankParserParams0.treeReaderFactory();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = new edu.stanford.nlp.trees.DiskTreebank(treeReaderFactory0);
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(options0, true, false);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) diskTreebank0, (edu.stanford.nlp.parser.lexparser.GrammarCompactor) exactGrammarCompactor0, options0);
      String[] stringArray0 = lexicalizedParser0.defaultCoreNLPFlags();
      lexicalizedParser0.saveParserToTextFile("BEGIN");
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      lexicalizedParser1.getExtraEvals();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.buildTrainTransformer(options0);
      lexicalizedParser1.setOptionFlags(stringArray0);
      assertFalse(lexicalizedParser1.requiresTags());
  }

  @Test(timeout = 4000)
  public void testMainThrowsNoClassDefFoundErrorAndGetParserFromFile()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      assertFalse(lexicalizedParser0.requiresTags());
      
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromFile("-savetoserializedfile", shiftReduceOptions0);
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-savetoserializedfile";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[3] = "-savetoserializedfile";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNoClassDefFoundErrorAndSaveParserToTextFileAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank(100);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      String[] stringArray0 = new String[6];
      stringArray0[0] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNoClassDefFoundErrorAndTrainFromTreebankTaking11And1WithNonEmptyString()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      String[] stringArray0 = new String[1];
      stringArray0[0] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain2()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams negraPennTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams();
      negraPennTreebankParserParams0.diskTreebank();
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options(negraPennTreebankParserParams0);
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-loadFromTextFile";
      stringArray0[1] = "-loadFromTextFile";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.parserQuery()\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNoClassDefFoundError()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-train";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNoClassDefFoundErrorAndDefaultCoreNLPFlagsAndTrainFromTreebankTaking11And1()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.HebrewTreebankParserParams hebrewTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.HebrewTreebankParserParams();
      edu.stanford.nlp.trees.TreeReaderFactory treeReaderFactory0 = hebrewTreebankParserParams0.treeReaderFactory();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = new edu.stanford.nlp.trees.DiskTreebank(treeReaderFactory0);
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      NetworkHandling.createRemoteTextFile((EvoSuiteURL) null, "@^)4y#Z1Q2zC0/jH0{");
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(options0, true, true);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) diskTreebank0, (edu.stanford.nlp.parser.lexparser.GrammarCompactor) exactGrammarCompactor0, options0);
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor1 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(options0, true, true);
      edu.stanford.nlp.parser.lexparser.Options options1 = new edu.stanford.nlp.parser.lexparser.Options();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) diskTreebank0, (edu.stanford.nlp.parser.lexparser.GrammarCompactor) exactGrammarCompactor0, options1);
      lexicalizedParser0.defaultCoreNLPFlags();
      lexicalizedParser1.saveParserToTextFile("@^)4y#Z1Q2zC0/jH0{");
      String[] stringArray0 = new String[8];
      stringArray0[0] = "@^)4y#Z1Q2zC0/jH0{";
      stringArray0[1] = "BEGIN";
      stringArray0[2] = "BEGIN";
      stringArray0[3] = "BEGIN";
      stringArray0[4] = "@^)4y#Z1Q2zC0/jH0{";
      stringArray0[5] = "BEGIN";
      stringArray0[6] = "@^)4y#Z1Q2zC0/jH0{";
      stringArray0[7] = "-tune";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNoClassDefFoundErrorAndMain()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      String[] stringArray0 = new String[8];
      stringArray0[0] = "-savetoserializedfile";
      stringArray0[1] = "-savetoserializedfile";
      stringArray0[2] = "-traintreebank";
      stringArray0[3] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[4] = "-savetoserializedfile";
      stringArray0[5] = "-savetoserializedfile";
      stringArray0[6] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[7] = "-savetoserializedfile";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetExtraEvalsAndTrainFromTreebankTaking2Arguments0()  throws Throwable  {
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank();
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      List<Eval> list0 = lexicalizedParser0.getExtraEvals();
      assertEquals(0, list0.size());
  }

  @Test(timeout = 4000)
  public void testGetExtraEvals()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.HebrewTreebankParserParams hebrewTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.HebrewTreebankParserParams();
      edu.stanford.nlp.trees.TreeReaderFactory treeReaderFactory0 = hebrewTreebankParserParams0.treeReaderFactory();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = new edu.stanford.nlp.trees.DiskTreebank(treeReaderFactory0);
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      NetworkHandling.createRemoteTextFile((EvoSuiteURL) null, "@^)4y#Z1Q2zC0/jH0{");
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(options0, true, false);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) diskTreebank0, (edu.stanford.nlp.parser.lexparser.GrammarCompactor) exactGrammarCompactor0, options0);
      String[] stringArray0 = lexicalizedParser0.defaultCoreNLPFlags();
      lexicalizedParser0.saveParserToTextFile("BEGIN");
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      lexicalizedParser1.getExtraEvals();
      edu.stanford.nlp.trees.CompositeTreeTransformer compositeTreeTransformer0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.buildTrainTransformer(options0);
      assertNotNull(compositeTreeTransformer0);
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFileThrowsNoClassDefFoundError()  throws Throwable  {
      FileSystemHandling.shouldAllThrowIOExceptions();
      String string0 = "69*69";
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(shiftReduceOptions0, true, false);
      edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams italianTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = italianTreebankParserParams0.diskTreebank();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) diskTreebank0, (edu.stanford.nlp.parser.lexparser.GrammarCompactor) exactGrammarCompactor0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      NumberRangeFileFilter numberRangeFileFilter0 = new NumberRangeFileFilter((-1845204428), 100, false);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("Grammar\t", (FileFilter) numberRangeFileFilter0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0 = new TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser();
      List<edu.stanford.nlp.ling.CoreLabel> list0 = trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0.apply("Grammar\t");
      // Undeclared exception!
      try { 
        lexicalizedParser0.lemmatize(list0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserQueryEvalsAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank();
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      List<edu.stanford.nlp.parser.metrics.ParserQueryEval> list0 = lexicalizedParser0.getParserQueryEvals();
      assertEquals(0, list0.size());
  }

  @Test(timeout = 4000)
  public void testGetParserQueryEvalsAndGetParserQueryEvals()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options(englishTreebankParserParams0);
      String[] stringArray0 = new String[0];
      options0.setOptions(stringArray0, 860, 100);
      edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams italianTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = italianTreebankParserParams0.diskTreebank();
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(options0, false, false);
      ArrayList<List<TaggedWord>> arrayList0 = new ArrayList<List<TaggedWord>>();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromTreebank(diskTreebank0, diskTreebank0, 100, exactGrammarCompactor0, options0, (edu.stanford.nlp.trees.Treebank) null, arrayList0);
      Vector<String> vector0 = new Vector<String>();
      edu.stanford.nlp.trees.Tree tree0 = lexicalizedParser0.parseStrings(vector0);
      assertEquals(Double.NaN, tree0.score(), 0.01);
      
      List<edu.stanford.nlp.parser.metrics.ParserQueryEval> list0 = lexicalizedParser0.getParserQueryEvals();
      assertEquals(0, list0.size());
  }

  @Test(timeout = 4000)
  public void testRequiresTagsAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      boolean boolean0 = lexicalizedParser0.requiresTags();
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void testRequiresTagsAndRequiresTags()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer(100, true);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/Users/amirdeljouyi/se/llm-powered-unit-test-generation-for-nlp-libraries/benchmark");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "");
      Stack<edu.stanford.nlp.ling.CoreLabel> stack0 = new Stack<edu.stanford.nlp.ling.CoreLabel>();
      lexicalizedParser0.parse((List<? extends edu.stanford.nlp.ling.HasWord>) stack0);
      ArrayList<String> arrayList0 = new ArrayList<String>();
      lexicalizedParser0.parseStrings(arrayList0);
      boolean boolean0 = lexicalizedParser0.requiresTags();
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFileThrowsRuntimeException()  throws Throwable  {
      String string0 = "";
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer(100, true);
      lexicalizedParser1.defaultCoreNLPFlags();
      // Undeclared exception!
      try { 
        lexicalizedParser0.saveParserToTextFile("");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.io.FileNotFoundException
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFile()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel();
      assertNull(lexicalizedParser0);
      
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromTextFile("I*#g|)_S{8t", shiftReduceOptions0);
      assertNull(lexicalizedParser1);
  }

  @Test(timeout = 4000)
  public void testGetParserFromFile1()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", shiftReduceOptions0);
      assertNotSame(lexicalizedParser1, lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ThrowsIllegalArgumentException()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.HebrewTreebankParserParams hebrewTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.HebrewTreebankParserParams();
      edu.stanford.nlp.trees.TreeReaderFactory treeReaderFactory0 = hebrewTreebankParserParams0.treeReaderFactory();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = new edu.stanford.nlp.trees.DiskTreebank(treeReaderFactory0);
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      NetworkHandling.createRemoteTextFile((EvoSuiteURL) null, "@^)4y#Z1Q2zC0/jH0{");
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(options0, true, true);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) diskTreebank0, (edu.stanford.nlp.parser.lexparser.GrammarCompactor) exactGrammarCompactor0, options0);
      lexicalizedParser0.defaultCoreNLPFlags();
      lexicalizedParser0.saveParserToTextFile("BEGIN");
      List<String> list0 = List.of("BEGIN", "BEGIN", "ku;>cn y?)u<}|5`oqJ", "BEGIN", "ku;>cn y?)u<}|5`oqJ");
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel("BEGIN", list0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Unknown option: BEGIN
         //
         verifyException("edu.stanford.nlp.parser.lexparser.Options", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetExtraEvalsAndTrainFromTreebankTaking2Arguments1()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      shiftReduceOptions0.doDep = false;
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      List<Eval> list0 = lexicalizedParser0.getExtraEvals();
      assertEquals(0, list0.size());
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking3ArgumentsThrowsNullPointerException()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      String string0 = "-testAtreebank";
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-encoding";
      stringArray0[1] = "-testAtreebank";
      stringArray0[2] = "-tesDlttreebank";
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel("f(vU-^}M;", (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMain2()  throws Throwable  {
      Stack<String> stack0 = new Stack<String>();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-savetoserializedfile";
      stringArray0[1] = "ParserPack is ";
      stringArray0[2] = "-savetoserializedfile";
      stringArray0[3] = "-savetoserializedfile";
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
      assertEquals(4, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMain10()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-~}P";
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException5()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-~}P";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFileThrowsNullPointerException()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      edu.stanford.nlp.parser.lexparser.Lexicon lexicon0 = englishTreebankParserParams0.lex(shiftReduceOptions0, lexicalizedParser0.stateIndex, lexicalizedParser0.stateIndex);
      lexicalizedParser0.lex = lexicon0;
      String string0 = "v";
      lexicalizedParser0.saveParserToSerialized("v");
      // Undeclared exception!
      try { 
        lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.UnknownWordModel.unSeenCounter()\" because the return value of \"edu.stanford.nlp.parser.lexparser.BaseLexicon.getUnknownWordModel()\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.BaseLexicon", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ThrowsNullPointerExceptionAndSaveParserToTextFile()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.HebrewTreebankParserParams hebrewTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.HebrewTreebankParserParams();
      edu.stanford.nlp.trees.TreeReaderFactory treeReaderFactory0 = hebrewTreebankParserParams0.treeReaderFactory();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = new edu.stanford.nlp.trees.DiskTreebank(treeReaderFactory0);
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      NetworkHandling.createRemoteTextFile((EvoSuiteURL) null, "@^)4y#Z1Q2zC0/jH0{");
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(options0, true, false);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) diskTreebank0, (edu.stanford.nlp.parser.lexparser.GrammarCompactor) exactGrammarCompactor0, options0);
      lexicalizedParser0.defaultCoreNLPFlags();
      lexicalizedParser0.saveParserToTextFile("BEGIN");
      List<String> list0 = List.of("\uFFFD\uFFFD\uFFFD", "\uFFFD\uFFFD\uFFFD", "ku;>cn y?)u<}|5`oqJ", "\uFFFD\uFFFD\uFFFD", "ku;>cn y?)u<}|5`oqJ");
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel("\uFFFD\uFFFD\uFFFD", list0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testDefaultCoreNLPFlags()  throws Throwable  {
      TransformingTreebank transformingTreebank0 = new TransformingTreebank();
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      Triple<edu.stanford.nlp.trees.Treebank, edu.stanford.nlp.trees.Treebank, edu.stanford.nlp.trees.Treebank> triple0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(transformingTreebank0, transformingTreebank0, transformingTreebank0, shiftReduceOptions0);
      assertNotNull(triple0);
      
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank(100);
      edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer(100, true);
      Stack<edu.stanford.nlp.ling.CoreLabel> stack0 = new Stack<edu.stanford.nlp.ling.CoreLabel>();
      System.setCurrentTimeMillis(100);
      Vector<String> vector0 = new Vector<String>();
      edu.stanford.nlp.io.RegExFileFilter regExFileFilter0 = new edu.stanford.nlp.io.RegExFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      File file0 = MockFile.createTempFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      regExFileFilter0.accept(file0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) regExFileFilter0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      lexicalizedParser0.parseStrings(vector0);
      lexicalizedParser0.parserQuery();
      String[] stringArray0 = lexicalizedParser0.defaultCoreNLPFlags();
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testBuildTrainTransformerTaking2Arguments()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      LeftHeadFinder leftHeadFinder0 = new LeftHeadFinder();
      edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer treeAnnotatorAndBinarizer0 = new edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer(leftHeadFinder0, leftHeadFinder0, shiftReduceOptions0.tlpParams, false, false, false, shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.buildTrainTransformer((edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0, treeAnnotatorAndBinarizer0);
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.buildTrainBinarizer(shiftReduceOptions0);
      edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer(100, true);
      Stack<edu.stanford.nlp.ling.CoreLabel> stack0 = new Stack<edu.stanford.nlp.ling.CoreLabel>();
      String[] stringArray0 = new String[0];
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
      assertEquals(0, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1ThrowsNullPointerExceptionAndGetAnnotatedBinaryTreebankFromTreebank()  throws Throwable  {
      TransformingTreebank transformingTreebank0 = new TransformingTreebank();
      NetworkHandling.createRemoteTextFile((EvoSuiteURL) null, "No tune treebank path specified.  Using train path: \"");
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(transformingTreebank0, (edu.stanford.nlp.trees.Treebank) null, transformingTreebank0, shiftReduceOptions0);
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank(100);
      edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer(697, false);
      Stack<edu.stanford.nlp.ling.CoreLabel> stack0 = new Stack<edu.stanford.nlp.ling.CoreLabel>();
      System.setCurrentTimeMillis(697);
      Vector<String> vector0 = new Vector<String>();
      edu.stanford.nlp.io.RegExFileFilter regExFileFilter0 = new edu.stanford.nlp.io.RegExFileFilter("\n");
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) regExFileFilter0, (edu.stanford.nlp.parser.lexparser.Options) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"tlpParams\" because \"op\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseTreeAndSetOptionFlagsThrowsIllegalArgumentException()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "Tags are: ";
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank("Tags are: ");
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, options0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.buildTrainBinarizer(options0);
      Stack<edu.stanford.nlp.ling.CoreLabel> stack0 = new Stack<edu.stanford.nlp.ling.CoreLabel>();
      lexicalizedParser0.parseTree(stack0);
      // Undeclared exception!
      try { 
        lexicalizedParser1.setOptionFlags(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Unknown option: Tags are: 
         //
         verifyException("edu.stanford.nlp.parser.lexparser.Options", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetTreePrintThrowsNoClassDefFoundError()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank(100);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      // Undeclared exception!
      try { 
        lexicalizedParser0.getTreePrint();
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetTreePrint()  throws Throwable  {
      String string0 = "";
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      String string1 = "%\"~W";
      lexicalizedParser1.saveParserToSerialized("%\"~W");
      edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer(100, true);
      Stack<edu.stanford.nlp.ling.CoreLabel> stack0 = new Stack<edu.stanford.nlp.ling.CoreLabel>();
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      // Undeclared exception!
      try { 
        lexicalizedParser1.getTreePrint();
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testCopyLexicalizedParserThrowsIllegalArgumentException()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "Tags are: ";
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank("Tags are: ");
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, options0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      // Undeclared exception!
      try { 
        lexicalizedParser1.setOptionFlags(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Unknown option: Tags are: 
         //
         verifyException("edu.stanford.nlp.parser.lexparser.Options", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingNoArgumentsThrowsRuntimeException()  throws Throwable  {
      String[] stringArray0 = new String[1];
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("Tags are: ");
      String string0 = "69*";
      FileSystemHandling.appendLineToFile(evoSuiteFile0, "69*");
      stringArray0[0] = "Tags are: ";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Tags are: : expecting BEGIN block; got 69*
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1ReturningLexicalizedParserWhereRequiresTagsIsFalse()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      lexicalizedParser1.saveParserToSerialized("%\"~W");
      edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer(100, true);
      Stack<edu.stanford.nlp.ling.CoreLabel> stack0 = new Stack<edu.stanford.nlp.ling.CoreLabel>();
      Pattern pattern0 = Pattern.compile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      edu.stanford.nlp.io.RegExFileFilter regExFileFilter0 = new edu.stanford.nlp.io.RegExFileFilter(pattern0);
      ShiftReduceParser shiftReduceParser0 = new ShiftReduceParser(shiftReduceOptions0);
      edu.stanford.nlp.trees.Treebank treebank0 = shiftReduceParser0.readTreebank("", regExFileFilter0);
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(shiftReduceOptions0, true, true);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank(treebank0, (edu.stanford.nlp.parser.lexparser.GrammarCompactor) exactGrammarCompactor0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      MockFile mockFile0 = new MockFile("BEGIN\uFFFD\uFFFD\uFFFD", "U=");
      MockFileInputStream mockFileInputStream0 = null;
      try {
        mockFileInputStream0 = new MockFileInputStream(mockFile0);
        fail("Expecting exception: FileNotFoundException");
      
      } catch(Throwable e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.evosuite.runtime.mock.java.io.MockFileInputStream", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingObjectInputStreamThrowsNullPointerException()  throws Throwable  {
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel((ObjectInputStream) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"java.io.ObjectInputStream.readObject()\" because \"ois\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromFileThrowsRuntimeException()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", shiftReduceOptions0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory: expecting BEGIN block; got edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking3ArgumentsThrowsRuntimeException()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("Tags are: ");
      byte[] byteArray0 = new byte[3];
      byteArray0[0] = (byte) (-1);
      byteArray0[1] = (byte) (-1);
      byteArray0[2] = (byte) (-109);
      FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "Tags are: ";
      options0.setOptions(stringArray0, 94, 94);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.buildTrainTransformer(options0);
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel("Tags are: ", options0, stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Tags are: : expecting BEGIN block; got \uFFFD\uFFFD\uFFFD
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testParserQuery()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("e", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      lexicalizedParser1.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      shiftReduceOptions0.nodePrune = true;
      edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer(100, true);
      Stack<edu.stanford.nlp.ling.CoreLabel> stack0 = new Stack<edu.stanford.nlp.ling.CoreLabel>();
      lexicalizedParser0.parserQuery();
      System.setCurrentTimeMillis(100);
      lexicalizedParser1.lexicalizedParserQuery();
      Vector<String> vector0 = new Vector<String>();
      lexicalizedParser0.parseStrings(vector0);
      System.setCurrentTimeMillis((-1632L));
  }

  @Test(timeout = 4000)
  public void testSetOptionFlagsAndSetOptionFlagsThrowsIllegalArgumentException()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      String[] stringArray0 = new String[8];
      stringArray0[0] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[1] = "";
      stringArray0[2] = "#sI{J=@)*dS|.p\"";
      stringArray0[3] = "";
      stringArray0[4] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[5] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[6] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[7] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        lexicalizedParser0.setOptionFlags(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Unknown option: edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory
         //
         verifyException("edu.stanford.nlp.parser.lexparser.Options", e);
      }
  }

  @Test(timeout = 4000)
  public void testSetOptionFlagsThrowsNullPointerException()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      String[] stringArray0 = new String[2];
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank(stringArray0[0]);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, options0);
      // Undeclared exception!
      try { 
        lexicalizedParser0.setOptionFlags(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.equalsIgnoreCase(String)\" because \"args[i]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.Options", e);
      }
  }

  @Test(timeout = 4000)
  public void testSaveParserToSerializedThrowsRuntimeException()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      // Undeclared exception!
      try { 
        lexicalizedParser1.saveParserToSerialized("");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.io.FileNotFoundException
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLexicalizedParserQueryAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      LexicalizedParserQuery lexicalizedParserQuery0 = lexicalizedParser0.lexicalizedParserQuery();
      assertFalse(lexicalizedParserQuery0.parseFallback());
  }

  @Test(timeout = 4000)
  public void testLexicalizedParserQuery()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      lexicalizedParser1.saveParserToSerialized("%\"~W");
      edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer(100, true);
      Stack<edu.stanford.nlp.ling.CoreLabel> stack0 = new Stack<edu.stanford.nlp.ling.CoreLabel>();
      System.setCurrentTimeMillis(389L);
      lexicalizedParser0.lexicalizedParserQuery();
      Vector<String> vector0 = new Vector<String>();
      edu.stanford.nlp.trees.Tree tree0 = lexicalizedParser0.parseStrings(vector0);
      assertEquals(Double.NaN, tree0.score(), 0.01);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankWithZero()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      String[] stringArray0 = new String[1];
      String string0 = "Tags are: ";
      stringArray0[0] = "Tags are: ";
      options0.setOptions(stringArray0, 94, 94);
      edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams italianTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = italianTreebankParserParams0.diskTreebank();
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(options0, false, false);
      ArrayList<List<TaggedWord>> arrayList0 = new ArrayList<List<TaggedWord>>();
      // Undeclared exception!
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromTreebank(diskTreebank0, diskTreebank0, 0.0, exactGrammarCompactor0, options0, diskTreebank0, arrayList0);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankWithNonEmptyList()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.HebrewTreebankParserParams hebrewTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.HebrewTreebankParserParams();
      edu.stanford.nlp.trees.TreeReaderFactory treeReaderFactory0 = hebrewTreebankParserParams0.treeReaderFactory();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = new edu.stanford.nlp.trees.DiskTreebank(treeReaderFactory0);
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("Tags are: ");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "69*");
      Vector<String> vector0 = new Vector<String>();
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(options0, true, true);
      Vector<TaggedWord> vector1 = new Vector<TaggedWord>();
      List<List<TaggedWord>> list0 = List.of(vector1, vector1);
      List<List<TaggedWord>> list1 = OutsideRuleFilter.reverse(list0);
      // Undeclared exception!
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromTreebank(diskTreebank0, diskTreebank0, 1310.5531, exactGrammarCompactor0, options0, diskTreebank0, list1);
  }

  @Test(timeout = 4000)
  public void testDefaultCoreNLPFlagsAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank(100);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      String[] stringArray0 = lexicalizedParser0.defaultCoreNLPFlags();
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testTreebankLanguagePackAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = new edu.stanford.nlp.trees.DiskTreebank();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) diskTreebank0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.trees.PennTreebankLanguagePack pennTreebankLanguagePack0 = (edu.stanford.nlp.trees.PennTreebankLanguagePack)lexicalizedParser0.treebankLanguagePack();
      assertEquals('-', pennTreebankLanguagePack0.getGfCharacter());
  }

  @Test(timeout = 4000)
  public void testTreebankLanguagePackAndTreebankLanguagePack()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer(100, true);
      Stack<edu.stanford.nlp.ling.CoreLabel> stack0 = new Stack<edu.stanford.nlp.ling.CoreLabel>();
      edu.stanford.nlp.trees.Tree tree0 = lexicalizedParser0.parse((List<? extends edu.stanford.nlp.ling.HasWord>) stack0);
      assertEquals(Double.NaN, tree0.score(), 0.01);
      
      edu.stanford.nlp.trees.PennTreebankLanguagePack pennTreebankLanguagePack0 = (edu.stanford.nlp.trees.PennTreebankLanguagePack)lexicalizedParser0.treebankLanguagePack();
      assertEquals('-', pennTreebankLanguagePack0.getGfCharacter());
  }

  @Test(timeout = 4000)
  public void testGetLexicon()  throws Throwable  {
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank();
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.Lexicon lexicon0 = lexicalizedParser0.getLexicon();
      assertEquals(0, lexicon0.numRules());
  }

  @Test(timeout = 4000)
  public void testGetLexiconAndSaveParserToSerialized()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      lexicalizedParser1.saveParserToSerialized("%\"~W");
      edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer(100, true);
      Stack<edu.stanford.nlp.ling.CoreLabel> stack0 = new Stack<edu.stanford.nlp.ling.CoreLabel>();
      lexicalizedParser0.parse((List<? extends edu.stanford.nlp.ling.HasWord>) stack0);
      edu.stanford.nlp.parser.lexparser.Lexicon lexicon0 = lexicalizedParser0.getLexicon();
      assertEquals(0, lexicon0.numRules());
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1ThrowsNullPointerExceptionAndGetParserFromTextFile()  throws Throwable  {
      TransformingTreebank transformingTreebank0 = new TransformingTreebank();
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(transformingTreebank0, transformingTreebank0, transformingTreebank0, shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.buildTrainTransformer((edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      System.setCurrentTimeMillis(100);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(shiftReduceOptions0, true, false);
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) transformingTreebank0, (edu.stanford.nlp.parser.lexparser.GrammarCompactor) exactGrammarCompactor0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testCreatesLexicalizedParserAndCreatesLexicalizedParser()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      String[] stringArray0 = new String[5];
      stringArray0[0] = "";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "";
      ArrayList<String> arrayList0 = new ArrayList<String>();
      lexicalizedParser0.parseStrings(arrayList0);
      stringArray0[3] = "";
      stringArray0[4] = "";
      shiftReduceOptions0.setOptionsOrWarn(stringArray0);
      edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer(100, true);
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank(nPTmpRetainingTreeNormalizer0);
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(shiftReduceOptions0, true, false);
      edu.stanford.nlp.parser.lexparser.UnaryGrammar unaryGrammar0 = new edu.stanford.nlp.parser.lexparser.UnaryGrammar(lexicalizedParser0.wordIndex);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = new edu.stanford.nlp.parser.lexparser.LexicalizedParser(lexicalizedParser0.lex, lexicalizedParser0.bg, unaryGrammar0, lexicalizedParser0.dg, lexicalizedParser0.stateIndex, lexicalizedParser0.tagIndex, lexicalizedParser0.stateIndex, shiftReduceOptions0);
      InputStream inputStream0 = InputStream.nullInputStream();
      ObjectInputStream objectInputStream0 = null;
      try {
        objectInputStream0 = new ObjectInputStream(inputStream0);
        fail("Expecting exception: EOFException");
      
      } catch(Throwable e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.io.ObjectInputStream$PeekInputStream", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndBuildTrainTransformerTakingOptionsAndCopyLexicalizedParser()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer(100, true);
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank(nPTmpRetainingTreeNormalizer0);
      String[] stringArray0 = new String[0];
      shiftReduceOptions0.setOptions(stringArray0, 955, 955);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.buildTrainTransformer((edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
      assertEquals(0, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithEmptyArray()  throws Throwable  {
      String[] stringArray0 = new String[0];
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
      assertEquals(0, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankThrowsNullPointerException()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank((edu.stanford.nlp.trees.Treebank) null, (edu.stanford.nlp.trees.Treebank) null, (edu.stanford.nlp.trees.Treebank) null, options0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.trees.Treebank.transform(edu.stanford.nlp.trees.TreeTransformer)\" because \"trainTreebank\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseStringsAndParseStringsThrowsNoClassDefFoundError()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      shiftReduceOptions0.doPCFG = true;
      Stack<edu.stanford.nlp.ling.CoreLabel> stack0 = new Stack<edu.stanford.nlp.ling.CoreLabel>();
      Vector<String> vector0 = new Vector<String>();
      vector0.add(" um*'`<G@$gkoB");
      // Undeclared exception!
      try { 
        lexicalizedParser0.parseStrings(vector0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseStringsAndParseStringsWithEmptyList()  throws Throwable  {
      edu.stanford.nlp.io.ExtensionFileFilter extensionFileFilter0 = new edu.stanford.nlp.io.ExtensionFileFilter("Tags are: ");
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("Tags are: ", (FileFilter) extensionFileFilter0, options0);
      Vector<String> vector0 = new Vector<String>();
      edu.stanford.nlp.trees.Tree tree0 = lexicalizedParser0.parseStrings(vector0);
      assertEquals(Double.NaN, tree0.score(), 0.01);
  }

  @Test(timeout = 4000)
  public void testParseTree()  throws Throwable  {
      Stack<edu.stanford.nlp.ling.CoreLabel> stack0 = new Stack<edu.stanford.nlp.ling.CoreLabel>();
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank();
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.trees.Tree tree0 = lexicalizedParser0.parseTree(stack0);
      assertNull(tree0);
  }

  @Test(timeout = 4000)
  public void testGetOpAndTrainFromTreebankTaking2Arguments()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.Options options0 = lexicalizedParser0.getOp();
      assertEquals(100, options0.rerankerKBest);
  }

  @Test(timeout = 4000)
  public void testParseStringsReturningTreeWhereScoreIsPositive()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser1 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      String[] stringArray0 = new String[5];
      stringArray0[0] = "";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "";
      ArrayList<String> arrayList0 = new ArrayList<String>();
      lexicalizedParser1.parseStrings(arrayList0);
      stringArray0[3] = "";
      stringArray0[4] = "";
      shiftReduceOptions0.setOptionsOrWarn(stringArray0);
      edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer(100, true);
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank(nPTmpRetainingTreeNormalizer0);
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(shiftReduceOptions0, true, false);
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main((String[]) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read the array length because \"args\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testParse()  throws Throwable  {
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank();
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      ArrayList<edu.stanford.nlp.ling.CoreLabel> arrayList0 = new ArrayList<edu.stanford.nlp.ling.CoreLabel>();
      edu.stanford.nlp.trees.Tree tree0 = lexicalizedParser0.parse((List<? extends edu.stanford.nlp.ling.HasWord>) arrayList0);
      assertEquals(Double.NaN, tree0.score(), 0.01);
  }

  @Test(timeout = 4000)
  public void testGetParserFromFileAndGetParserFromFile()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      String[] stringArray0 = new String[1];
      options0.display();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromFile("k]b5C7L/!v", options0);
      assertNull(lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileReturningNull()  throws Throwable  {
      String[] stringArray0 = new String[7];
      stringArray0[0] = ",sTU.BOfh";
      stringArray0[1] = "e";
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromTextFile("e", (edu.stanford.nlp.parser.lexparser.Options) null);
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser((edu.stanford.nlp.parser.lexparser.LexicalizedParser) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"lex\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking2ArgumentsThrowsNoClassDefFoundError()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      shiftReduceOptions0.compoundUnaries = true;
      String[] stringArray0 = new String[1];
      stringArray0[0] = "Tags are: ";
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, true, false);
      shiftReduceOptions0.setOptions(stringArray0, 94, 94);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.buildTrainTransformer((edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      String[] stringArray1 = new String[0];
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel("Tags are: ", (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0, stringArray1);
      SpanishTreebankParserParams spanishTreebankParserParams0 = null;
      try {
        spanishTreebankParserParams0 = new SpanishTreebankParserParams();
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.tregex.TregexParser
         //
         verifyException("edu.stanford.nlp.trees.tregex.TregexPatternCompiler", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankWithNullAndGetParserFromTreebankThrowsTooManyResourcesException()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      String string0 = "g$x";
      String string1 = "";
      edu.stanford.nlp.io.ExtensionFileFilter extensionFileFilter0 = new edu.stanford.nlp.io.ExtensionFileFilter("", false);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("g$x", (FileFilter) extensionFileFilter0, options0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer(100, true);
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank(nPTmpRetainingTreeNormalizer0);
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(options0, false, true);
      BasicDocument<Pair<Object, TransformingTreebank>> basicDocument0 = new BasicDocument<Pair<Object, TransformingTreebank>>();
      basicDocument0.blankDocument();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = new edu.stanford.nlp.trees.DiskTreebank(34);
      // Undeclared exception!
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromTreebank(memoryTreebank0, diskTreebank0, 0.0, exactGrammarCompactor0, options0, diskTreebank0, (List<List<TaggedWord>>) null);
  }

  @Test(timeout = 4000)
  public void testCopyLexicalizedParserThrowsNullPointerException()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel();
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser((edu.stanford.nlp.parser.lexparser.LexicalizedParser) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"lex\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1AndTrainFromTreebankTaking11And1ThrowsNullPointerException()  throws Throwable  {
      Pattern pattern0 = Pattern.compile("");
      edu.stanford.nlp.io.RegExFileFilter regExFileFilter0 = new edu.stanford.nlp.io.RegExFileFilter(pattern0);
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      edu.stanford.nlp.parser.lexparser.Options options0 = spanishUnknownWordModelTrainer0.op;
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("u", (FileFilter) regExFileFilter0, (edu.stanford.nlp.parser.lexparser.Options) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"tlpParams\" because \"op\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromSerializedFile()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromSerializedFile((String) null);
      TransformingTreebank transformingTreebank0 = new TransformingTreebank();
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(transformingTreebank0, transformingTreebank0, transformingTreebank0, (edu.stanford.nlp.parser.lexparser.Options) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"tlpParams\" because \"op\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testCopyLexicalizedParser()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank("", (FileFilter) null, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer(100, true);
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank(nPTmpRetainingTreeNormalizer0);
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(shiftReduceOptions0, true, false);
      BasicDocument<Pair<Object, TransformingTreebank>> basicDocument0 = new BasicDocument<Pair<Object, TransformingTreebank>>();
      basicDocument0.blankDocument();
      // Undeclared exception!
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, (-2350.78254), exactGrammarCompactor0, shiftReduceOptions0, memoryTreebank0, (List<List<TaggedWord>>) null);
  }

  @Test(timeout = 4000)
  public void testCopyLexicalizedParserThrowsTooManyResourcesException()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams italianTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams();
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = italianTreebankParserParams0.memoryTreebank();
      edu.stanford.nlp.trees.BobChrisTreeNormalizer bobChrisTreeNormalizer0 = new edu.stanford.nlp.trees.BobChrisTreeNormalizer();
      Comparator<Object> comparator0 = (Comparator<Object>) mock(Comparator.class, new ViolatedAssumptionAnswer());
      memoryTreebank0.sort(comparator0);
      TransformingTreebank transformingTreebank0 = new TransformingTreebank(memoryTreebank0, bobChrisTreeNormalizer0);
      Pair<TransformingTreebank, TransformingTreebank> pair0 = Pair.makePair(transformingTreebank0, null);
      Object object0 = new Object();
      List.of(transformingTreebank0, pair0, object0);
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(options0, true, true);
      // Undeclared exception!
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, 0.0, exactGrammarCompactor0, options0, memoryTreebank0, (List<List<TaggedWord>>) null);
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1AndTrainFromTreebankTaking11And1WithNonNull()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank(100);
      edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor exactGrammarCompactor0 = new edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor(shiftReduceOptions0, true, true);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, (edu.stanford.nlp.parser.lexparser.GrammarCompactor) exactGrammarCompactor0, (edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankThrowsTooManyResourcesException()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = new edu.stanford.nlp.trees.DiskTreebank();
      LinkedList<List<TaggedWord>> linkedList0 = new LinkedList<List<TaggedWord>>();
      // Undeclared exception!
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromTreebank(diskTreebank0, diskTreebank0, 100, (edu.stanford.nlp.parser.lexparser.GrammarCompactor) null, shiftReduceOptions0, diskTreebank0, linkedList0);
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankThrowsNullPointerExceptionAndGetAnnotatedBinaryTreebankFromTreebank()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.trees.BobChrisTreeNormalizer.EmptyFilter bobChrisTreeNormalizer_EmptyFilter0 = new edu.stanford.nlp.trees.BobChrisTreeNormalizer.EmptyFilter();
      Predicate<edu.stanford.nlp.trees.Tree> predicate0 = bobChrisTreeNormalizer_EmptyFilter0.negate();
      edu.stanford.nlp.trees.FilteringTreebank filteringTreebank0 = new edu.stanford.nlp.trees.FilteringTreebank((edu.stanford.nlp.trees.Treebank) null, predicate0);
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank((edu.stanford.nlp.trees.Treebank) null, (edu.stanford.nlp.trees.Treebank) null, (edu.stanford.nlp.trees.Treebank) null, shiftReduceOptions0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.trees.Treebank.transform(edu.stanford.nlp.trees.TreeTransformer)\" because \"trainTreebank\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndGetAnnotatedBinaryTreebankFromTreebankWithNull()  throws Throwable  {
      TransformingTreebank transformingTreebank0 = new TransformingTreebank();
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(transformingTreebank0, transformingTreebank0, (edu.stanford.nlp.trees.Treebank) null, shiftReduceOptions0);
      String[] stringArray0 = new String[9];
      stringArray0[0] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[3] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[4] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[5] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[6] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[7] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[8] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndGetAnnotatedBinaryTreebankFromTreebank()  throws Throwable  {
      TransformingTreebank transformingTreebank0 = new TransformingTreebank();
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(transformingTreebank0, transformingTreebank0, transformingTreebank0, shiftReduceOptions0);
      String[] stringArray0 = new String[9];
      stringArray0[0] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[3] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[4] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[5] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[6] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[7] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[8] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebank()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank();
      Triple<edu.stanford.nlp.trees.Treebank, edu.stanford.nlp.trees.Treebank, edu.stanford.nlp.trees.Treebank> triple0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, (edu.stanford.nlp.trees.Treebank) null, (edu.stanford.nlp.trees.Treebank) null, shiftReduceOptions0);
      assertNotNull(triple0);
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking2Arguments1()  throws Throwable  {
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank();
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) memoryTreebank0, options0);
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking2ArgumentsThrowsNullPointerException()  throws Throwable  {
      edu.stanford.nlp.trees.Treebank treebank0 = null;
      edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams italianTreebankParserParams0 = new edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams();
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options(italianTreebankParserParams0);
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.trainFromTreebank((edu.stanford.nlp.trees.Treebank) null, options0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.trees.Treebank.transform(edu.stanford.nlp.trees.TreeTransformer)\" because \"trainTreebank\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingNoArguments()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel();
      String string0 = "^|KD_l{pW[pF";
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      String[] stringArray0 = new String[4];
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel("^|KD_l{pW[pF", options0, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain3()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.trees.DiskTreebank diskTreebank0 = new edu.stanford.nlp.trees.DiskTreebank();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-escaper";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[3] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[4] = "";
      stringArray0[5] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[6] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[7] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[8] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException6()  throws Throwable  {
      String[] stringArray0 = new String[7];
      stringArray0[0] = ",sTU.BOfh";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain4()  throws Throwable  {
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentExceptionAndMain1()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.trees.MemoryTreebank memoryTreebank0 = new edu.stanford.nlp.trees.MemoryTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-train2";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Constructor argument not valid list of number ranges: edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory
         //
         verifyException("edu.stanford.nlp.io.NumberRangesFileFilter", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain5()  throws Throwable  {
      String[] stringArray0 = new String[8];
      stringArray0[0] = "#3m_fk";
      stringArray0[1] = "s!a!%ZT}c";
      stringArray0[2] = "PP-locy";
      stringArray0[3] = "-tokenizerFactory";
      stringArray0[4] = "94;EhaM%]";
      stringArray0[5] = "i0i?Gy9M+L";
      stringArray0[6] = "GV:BZ_x{7tA{|aHLD(D";
      stringArray0[7] = "@ADVP|CONJP <1 (RB=node1 < /^(?i)as$/) <- (IN|RB=node2 < /^(?i)well$/)";
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException7()  throws Throwable  {
      String[] stringArray0 = new String[19];
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1WithNullAndNull()  throws Throwable  {
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel((String) null, (List<String>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"java.util.List.size()\" because \"extraFlags\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1AndLoadModelTaking1And1AndLoadModelTaking1And1ReturningNull0()  throws Throwable  {
      LinkedList<String> linkedList0 = new LinkedList<String>();
      linkedList0.poll();
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel("(Y", (List<String>) linkedList0);
      assertNull(lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testDefaultCoreNLPFlagsThrowsNullPointerException()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      edu.stanford.nlp.parser.lexparser.Options.LexOptions options_LexOptions0 = shiftReduceOptions0.lexOptions;
      shiftReduceOptions0.lexOptions = options_LexOptions0;
      shiftReduceOptions0.featureFactoryClass = "";
      stringArray0[1] = "";
      stringArray0[2] = " +";
      stringArray0[3] = "";
      stringArray0[4] = "";
      stringArray0[5] = "";
      stringArray0[6] = "";
      options_LexOptions0.flexiTag = false;
      options_LexOptions0.useSignatureForKnownSmoothing = true;
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel((edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testBuildTrainBinarizer()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      edu.stanford.nlp.parser.lexparser.Options options1 = new edu.stanford.nlp.parser.lexparser.Options(options0.tlpParams);
      options1.doPCFG = true;
      edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer treeAnnotatorAndBinarizer0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.buildTrainBinarizer(options1);
      // Undeclared exception!
      try { 
        treeAnnotatorAndBinarizer0.printRuleCounts();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.stats.ClassicCounter.keySet()\" because \"this.annotatedRuleCounts\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ThrowsNullPointerExceptionAndLoadModelTaking1And1WithNonNull()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      String[] stringArray0 = new String[1];
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel(options0, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testBuildTrainTransformerTakingOptionsAndLoadModelTaking3Arguments()  throws Throwable  {
      edu.stanford.nlp.parser.lexparser.Options options0 = new edu.stanford.nlp.parser.lexparser.Options();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "Tags are: ";
      options0.setOptions(stringArray0, 94, 94);
      edu.stanford.nlp.parser.lexparser.LexicalizedParser.buildTrainTransformer(options0);
      // Undeclared exception!
      try { 
        edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel("Tags are: ", options0, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testBuildTrainTransformerTakingOptions()  throws Throwable  {
      edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions shiftReduceOptions0 = new edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions();
      edu.stanford.nlp.trees.CompositeTreeTransformer compositeTreeTransformer0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.buildTrainTransformer((edu.stanford.nlp.parser.lexparser.Options) shiftReduceOptions0);
      assertNotNull(compositeTreeTransformer0);
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1AndLoadModelTaking1And1AndLoadModelTaking1And1ReturningNull1()  throws Throwable  {
      String[] stringArray0 = new String[0];
      edu.stanford.nlp.parser.lexparser.LexicalizedParser lexicalizedParser0 = edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel("P`vEk2?6nVSp]7#4", stringArray0);
      assertNull(lexicalizedParser0);
  }
}
