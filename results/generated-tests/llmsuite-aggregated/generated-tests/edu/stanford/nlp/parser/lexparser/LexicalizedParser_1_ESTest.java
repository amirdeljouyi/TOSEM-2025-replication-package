/*
 * This file was automatically generated by UTestGen and EvoSuite
 * Wed Apr 16 01:10:47 GMT 2025
 */

package edu.stanford.nlp.parser.lexparser;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.shaded.org.mockito.Mockito.*;
import static org.evosuite.runtime.EvoAssertions.*;
import edu.stanford.nlp.ie.PresetSequenceClassifier;
import edu.stanford.nlp.io.ExtensionFileFilter;
import edu.stanford.nlp.io.NumberRangeFileFilter;
import edu.stanford.nlp.io.RegExFileFilter;
import edu.stanford.nlp.ling.BasicDocument;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.ling.HasWord;
import edu.stanford.nlp.ling.IndexedWord;
import edu.stanford.nlp.ling.Label;
import edu.stanford.nlp.ling.LabelFactory;
import edu.stanford.nlp.ling.StringLabel;
import edu.stanford.nlp.ling.TaggedWord;
import edu.stanford.nlp.ling.TaggedWordFactory;
import edu.stanford.nlp.ling.Word;
import edu.stanford.nlp.ling.WordLemmaTag;
import edu.stanford.nlp.ling.WordTag;
import edu.stanford.nlp.objectbank.DelimitRegExIterator;
import edu.stanford.nlp.objectbank.ObjectBank;
import edu.stanford.nlp.objectbank.ReaderIteratorFactory;
import edu.stanford.nlp.parser.common.ParserQuery;
import edu.stanford.nlp.parser.lexparser.BinaryGrammar;
import edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.DependencyGrammar;
import edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor;
import edu.stanford.nlp.parser.lexparser.GrammarCompactor;
import edu.stanford.nlp.parser.lexparser.HebrewTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.HungarianTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.LexicalizedParser;
import edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery;
import edu.stanford.nlp.parser.lexparser.Lexicon;
import edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams;
import edu.stanford.nlp.parser.lexparser.Options;
import edu.stanford.nlp.parser.lexparser.OutsideRuleFilter;
import edu.stanford.nlp.parser.lexparser.SpanishUnknownWordModelTrainer;
import edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer;
import edu.stanford.nlp.parser.lexparser.TreebankLangParserParams;
import edu.stanford.nlp.parser.lexparser.UnaryGrammar;
import edu.stanford.nlp.parser.lexparser.UnknownWordModel;
import edu.stanford.nlp.parser.metrics.Eval;
import edu.stanford.nlp.parser.metrics.ParserQueryEval;
import edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions;
import edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser;
import edu.stanford.nlp.process.WordTokenFactory;
import edu.stanford.nlp.time.TimeFormatter;
import edu.stanford.nlp.trees.BobChrisTreeNormalizer;
import edu.stanford.nlp.trees.CompositeTreeTransformer;
import edu.stanford.nlp.trees.DiskTreebank;
import edu.stanford.nlp.trees.FilteringTreebank;
import edu.stanford.nlp.trees.LabeledScoredTreeFactory;
import edu.stanford.nlp.trees.LabeledScoredTreeNode;
import edu.stanford.nlp.trees.LabeledScoredTreeReaderFactory;
import edu.stanford.nlp.trees.LengthTreeFilter;
import edu.stanford.nlp.trees.MemoryTreebank;
import edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer;
import edu.stanford.nlp.trees.PennTreeReaderFactory;
import edu.stanford.nlp.trees.PennTreebankLanguagePack;
import edu.stanford.nlp.trees.TransformingTreebank;
import edu.stanford.nlp.trees.Tree;
import edu.stanford.nlp.trees.TreeFilters;
import edu.stanford.nlp.trees.TreeGraphNode;
import edu.stanford.nlp.trees.TreeGraphNodeFactory;
import edu.stanford.nlp.trees.TreeReaderFactory;
import edu.stanford.nlp.trees.Treebank;
import edu.stanford.nlp.trees.TreebankLanguagePack;
import edu.stanford.nlp.util.ArrayCoreMap;
import edu.stanford.nlp.util.Filters;
import edu.stanford.nlp.util.HashIndex;
import edu.stanford.nlp.util.Timing;
import edu.stanford.nlp.util.Triple;
import java.io.BufferedReader;
import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;
import java.io.File;
import java.io.FileFilter;
import java.io.ObjectInputStream;
import java.io.ObjectOutputStream;
import java.io.PipedInputStream;
import java.io.StringReader;
import java.lang.reflect.Array;
import java.nio.CharBuffer;
import java.util.ArrayList;
import java.util.Collection;
import java.util.LinkedList;
import java.util.List;
import java.util.Locale;
import java.util.Properties;
import java.util.Stack;
import java.util.Vector;
import java.util.function.Function;
import java.util.function.IntFunction;
import java.util.function.Predicate;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.System;
import org.evosuite.runtime.ViolatedAssumptionAnswer;
import org.evosuite.runtime.mock.java.io.MockFileInputStream;
import org.evosuite.runtime.mock.java.util.MockRandom;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, separateClassLoader = true) 
public class LexicalizedParser_1_ESTest extends LexicalizedParser_1_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void testGetParserFromTreebankAndGetParserFromTreebankWithEmptyList()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.doDep = false;
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      LinkedList<List<TaggedWord>> linkedList0 = new LinkedList<List<TaggedWord>>();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, true, false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, 100, exactGrammarCompactor0, shiftReduceOptions0, memoryTreebank0, linkedList0);
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ReturningLexicalizedParserWhereRequiresTagsIsFalse()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ShiftReduceOptions shiftReduceOptions1 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser.getParserFromSerializedFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      DiskTreebank diskTreebank0 = new DiskTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      Options options0 = new Options(shiftReduceOptions1.tlpParams);
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(diskTreebank0, (Treebank) null, (Treebank) null, options0);
      String[] stringArray0 = new String[0];
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.loadModel("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", stringArray0);
      assertNotSame(lexicalizedParser1, lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking3ArgumentsThrowsRuntimeException()  throws Throwable  {
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-tlpp";
      stringArray0[1] = "edu.stanford.nlp.parser.lexparser.EnglishUnknownWordModel";
      stringArray0[2] = ",,6";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.lang.NoSuchMethodException: edu.stanford.nlp.parser.lexparser.EnglishUnknownWordModel.<init>()
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testDefaultCoreNLPFlagsThrowsRuntimeException()  throws Throwable  {
      ByteArrayOutputStream byteArrayOutputStream0 = new ByteArrayOutputStream();
      ObjectOutputStream objectOutputStream0 = new ObjectOutputStream(byteArrayOutputStream0);
      objectOutputStream0.write(3);
      objectOutputStream0.writeObject("This is not a parser");
      objectOutputStream0.close();
      byte[] byteArray0 = byteArrayOutputStream0.toByteArray();
      ByteArrayInputStream byteArrayInputStream0 = new ByteArrayInputStream(byteArray0);
      ObjectInputStream objectInputStream0 = new ObjectInputStream(byteArrayInputStream0);
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel(objectInputStream0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.io.OptionalDataException
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseMultipleTaking2ArgumentsReturningListWhereIsEmptyIsFalse()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      assertFalse(lexicalizedParser0.requiresTags());
      
      BasicDocument<IndexedWord> basicDocument0 = BasicDocument.init();
      FileSystemHandling.shouldAllThrowIOExceptions();
      LinkedList<BasicDocument<IndexedWord>> linkedList0 = new LinkedList<BasicDocument<IndexedWord>>();
      linkedList0.add(basicDocument0);
      linkedList0.add(basicDocument0);
      List<Tree> list0 = lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) linkedList0, 1);
      assertFalse(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testParseMultipleTakingListAndParseMultipleTaking2Arguments()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      LinkedList<BasicDocument<IndexedWord>> linkedList0 = new LinkedList<BasicDocument<IndexedWord>>();
      BasicDocument<IndexedWord> basicDocument0 = BasicDocument.init();
      linkedList0.add(basicDocument0);
      List<Tree> list0 = lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) linkedList0, 100);
      assertEquals(1, linkedList0.size());
      assertFalse(list0.isEmpty());
      
      List<Tree> list1 = lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) linkedList0);
      assertTrue(list1.equals((Object)list0));
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1AndRequiresTags()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      assertFalse(lexicalizedParser0.requiresTags());
      
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", shiftReduceOptions0);
      assertNotSame(lexicalizedParser1, lexicalizedParser0);
      
      boolean boolean0 = lexicalizedParser0.requiresTags();
      assertFalse(boolean0);
      
      Vector<String> vector0 = new Vector<String>(100, 100);
      LexicalizedParser lexicalizedParser2 = LexicalizedParser.loadModel("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (List<String>) vector0);
      assertNotNull(lexicalizedParser2);
      assertFalse(lexicalizedParser2.requiresTags());
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingObjectInputStreamAndSaveParserToSerializedAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      MockFileInputStream mockFileInputStream0 = new MockFileInputStream("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      ObjectInputStream objectInputStream0 = new ObjectInputStream(mockFileInputStream0);
      LexicalizedParser.loadModel(objectInputStream0);
      CoreLabel coreLabel0 = null;
      try {
        coreLabel0 = new CoreLabel((String[]) null, (String[]) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read the array length because \"keys\" is null
         //
         verifyException("edu.stanford.nlp.ling.CoreLabel", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseMultipleTaking2ArgumentsReturningListWhereIsEmptyIsTrue()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      LinkedList<BasicDocument<IndexedWord>> linkedList0 = new LinkedList<BasicDocument<IndexedWord>>();
      List<Tree> list0 = lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) linkedList0, 100);
      assertTrue(list0.isEmpty());
      
      List<Eval> list1 = lexicalizedParser0.getExtraEvals();
      assertEquals(0, list1.size());
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankReturningLexicalizedParserWhereRequiresTagsIsFalse()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser0.tokenize("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      lexicalizedParser0.saveParserToSerialized(" sec].");
      PennTreebankLanguagePack pennTreebankLanguagePack0 = new PennTreebankLanguagePack();
      TreeReaderFactory treeReaderFactory0 = pennTreebankLanguagePack0.treeReaderFactory();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(100, treeReaderFactory0);
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, true);
      ArrayList<List<TaggedWord>> arrayList0 = new ArrayList<List<TaggedWord>>();
      List<List<TaggedWord>> list0 = OutsideRuleFilter.reverse(arrayList0);
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromTreebank(memoryTreebank0, (Treebank) null, 100, exactGrammarCompactor0, shiftReduceOptions0, (Treebank) null, list0);
      assertFalse(lexicalizedParser1.requiresTags());
  }

  @Test(timeout = 4000)
  public void testGetTLPParamsReturningTreebankLangParserParamsWhereSupportsBasicDependenciesIsFalse()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      shiftReduceOptions0.tlpParams = (TreebankLangParserParams) italianTreebankParserParams0;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("6iQ_+k", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("CHINESE");
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromSerializedFile("CHINESE");
      lexicalizedParser0.getTLPParams();
      LexicalizedParser lexicalizedParser2 = LexicalizedParser.copyLexicalizedParser(lexicalizedParser1);
      assertNotSame(lexicalizedParser2, lexicalizedParser1);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankThrowsNullPointerException()  throws Throwable  {
      String[] stringArray0 = new String[3];
      LengthTreeFilter lengthTreeFilter0 = new LengthTreeFilter((-2624));
      FilteringTreebank filteringTreebank0 = new FilteringTreebank((Treebank) null, lengthTreeFilter0);
      NegraPennTreebankParserParams negraPennTreebankParserParams0 = new NegraPennTreebankParserParams();
      Options options0 = new Options(negraPennTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, false, true);
      LinkedList<List<TaggedWord>> linkedList0 = new LinkedList<List<TaggedWord>>();
      // Undeclared exception!
      try { 
        LexicalizedParser.getParserFromTreebank(filteringTreebank0, filteringTreebank0, 2564.22, exactGrammarCompactor0, options0, (Treebank) null, linkedList0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testDefaultCoreNLPFlagsReturningEmptyArray()  throws Throwable  {
      Options options0 = new Options();
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      options0.tlpParams = (TreebankLangParserParams) italianTreebankParserParams0;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("BEGINBEGIN LEXICON edu.stanford.nlp.parser.lexparser.EnglishUnknownWordModel", (FileFilter) null, options0);
      lexicalizedParser0.getExtraEvals();
      lexicalizedParser0.defaultCoreNLPFlags();
      LabeledScoredTreeFactory labeledScoredTreeFactory0 = new LabeledScoredTreeFactory();
      Tree tree0 = labeledScoredTreeFactory0.newLeaf("ory");
      TreeGraphNode treeGraphNode0 = new TreeGraphNode(tree0);
      ArrayList<CoreLabel> arrayList0 = treeGraphNode0.yieldHasWord();
      Tree tree1 = lexicalizedParser0.parse((List<? extends HasWord>) arrayList0);
      assertEquals(Double.NaN, tree1.score(), 0.01);
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingObjectInputStreamThrowsRuntimeException()  throws Throwable  {
      byte[] byteArray0 = new byte[25];
      byteArray0[0] = (byte) 172;
      byteArray0[1] = (byte) 237;
      byteArray0[2] = (byte) 0;
      byteArray0[3] = (byte) 5;
      byteArray0[4] = (byte) 115;
      byteArray0[5] = (byte) 114;
      byteArray0[6] = (byte) 0;
      byteArray0[7] = (byte) 4;
      byteArray0[8] = (byte) 84;
      byteArray0[9] = (byte) 101;
      byteArray0[10] = (byte) 115;
      byteArray0[11] = (byte) 116;
      byteArray0[12] = (byte) 0;
      byteArray0[13] = (byte) 0;
      byteArray0[14] = (byte) 0;
      byteArray0[15] = (byte) 0;
      byteArray0[16] = (byte) 0;
      byteArray0[17] = (byte) 0;
      byteArray0[18] = (byte) 0;
      byteArray0[19] = (byte) 1;
      byteArray0[20] = (byte) 2;
      byteArray0[21] = (byte) 0;
      byteArray0[22] = (byte) 0;
      byteArray0[23] = (byte) 120;
      byteArray0[24] = (byte) 112;
      ByteArrayInputStream byteArrayInputStream0 = new ByteArrayInputStream(byteArray0);
      ObjectInputStream objectInputStream0 = new ObjectInputStream(byteArrayInputStream0);
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel(objectInputStream0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.lang.ClassNotFoundException: Class 'Test.class' should be in target project, but could not be found!
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testTreebankLanguagePackReturningTreebankLanguagePackWhereSupportsGrammaticalStructuresIsFalse()  throws Throwable  {
      Options options0 = new Options();
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      options0.tlpParams = (TreebankLangParserParams) italianTreebankParserParams0;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("xmF\"", (FileFilter) null, options0);
      lexicalizedParser0.saveParserToSerialized("xmF\"");
      lexicalizedParser0.saveParserToTextFile("xmF\"");
      LexicalizedParser.getParserFromFile("xmF\"", options0);
      TreebankLanguagePack treebankLanguagePack0 = lexicalizedParser0.treebankLanguagePack();
      assertFalse(treebankLanguagePack0.supportsGrammaticalStructures());
  }

  @Test(timeout = 4000)
  public void testCopyLexicalizedParserThrowsNullPointerException()  throws Throwable  {
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.loadModel();
      assertNull(lexicalizedParser0);
      
      // Undeclared exception!
      try { 
        LexicalizedParser.copyLexicalizedParser((LexicalizedParser) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"lex\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesLexicalizedParserAndSaveParserToTextFile()  throws Throwable  {
      Lexicon lexicon0 = mock(Lexicon.class, new ViolatedAssumptionAnswer());
      doReturn((UnknownWordModel) null).when(lexicon0).getUnknownWordModel();
      BinaryGrammar binaryGrammar0 = mock(BinaryGrammar.class, new ViolatedAssumptionAnswer());
      UnaryGrammar unaryGrammar0 = mock(UnaryGrammar.class, new ViolatedAssumptionAnswer());
      DependencyGrammar dependencyGrammar0 = mock(DependencyGrammar.class, new ViolatedAssumptionAnswer());
      HashIndex<String> hashIndex0 = new HashIndex<String>();
      hashIndex0.add("S");
      HashIndex<String> hashIndex1 = new HashIndex<String>();
      hashIndex1.add("hello");
      HashIndex<String> hashIndex2 = new HashIndex<String>();
      hashIndex2.add("NN");
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = new LexicalizedParser(lexicon0, binaryGrammar0, unaryGrammar0, dependencyGrammar0, hashIndex0, hashIndex1, hashIndex2, options0);
      lexicalizedParser0.saveParserToTextFile("output_model.txt.gz");
      File file0 = new File("output_model.txt.gz");
      boolean boolean0 = file0.exists();
      File file1 = new File("output_model.txt.gz");
      boolean boolean1 = file1.delete();
      assertTrue(boolean1 == boolean0);
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFileThrowsNullPointerException()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      NegraPennTreebankParserParams negraPennTreebankParserParams0 = new NegraPennTreebankParserParams();
      ShiftReduceParser shiftReduceParser0 = new ShiftReduceParser(shiftReduceOptions0);
      Options options0 = shiftReduceParser0.getOp();
      Lexicon lexicon0 = negraPennTreebankParserParams0.lex(options0, lexicalizedParser0.tagIndex, lexicalizedParser0.stateIndex);
      lexicalizedParser0.lex = lexicon0;
      // Undeclared exception!
      try { 
        lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.UnknownWordModel.unSeenCounter()\" because the return value of \"edu.stanford.nlp.parser.lexparser.BaseLexicon.getUnknownWordModel()\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.BaseLexicon", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseMultipleTakingList()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      LinkedList<BasicDocument<IndexedWord>> linkedList0 = new LinkedList<BasicDocument<IndexedWord>>();
      BasicDocument<IndexedWord> basicDocument0 = new BasicDocument<IndexedWord>();
      List<Word> list0 = OutsideRuleFilter.reverse(basicDocument0);
      BasicDocument<IndexedWord> basicDocument1 = basicDocument0.init(list0, "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      linkedList0.offerLast(basicDocument1);
      lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) linkedList0);
      lexicalizedParser0.saveParserToTextFile("JIiIrdSavEjp?");
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.loadModel();
      assertNull(lexicalizedParser1);
  }

  @Test(timeout = 4000)
  public void testParseMultipleTakingListWithEmptyList()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      LinkedList<BasicDocument<IndexedWord>> linkedList0 = new LinkedList<BasicDocument<IndexedWord>>();
      List<Tree> list0 = lexicalizedParser0.parseMultiple((List<? extends List<? extends HasWord>>) linkedList0);
      assertTrue(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingObjectInputStreamThrowsClassCastException()  throws Throwable  {
      ByteArrayOutputStream byteArrayOutputStream0 = new ByteArrayOutputStream();
      ObjectOutputStream objectOutputStream0 = new ObjectOutputStream(byteArrayOutputStream0);
      objectOutputStream0.writeObject("This is not a parser");
      objectOutputStream0.close();
      byte[] byteArray0 = byteArrayOutputStream0.toByteArray();
      ByteArrayInputStream byteArrayInputStream0 = new ByteArrayInputStream(byteArray0);
      ObjectInputStream objectInputStream0 = new ObjectInputStream(byteArrayInputStream0);
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel(objectInputStream0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // Wanted LexicalizedParser, got class java.lang.String
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankWithNull0()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      DiskTreebank diskTreebank0 = new DiskTreebank();
      Triple<Treebank, Treebank, Treebank> triple0 = LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(diskTreebank0, (Treebank) null, diskTreebank0, shiftReduceOptions0);
      assertNotNull(triple0);
  }

  @Test(timeout = 4000)
  public void testParseAndGetParserFromSerializedFile()  throws Throwable  {
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("t;6i^~e#<PK", (FileFilter) null, options0);
      lexicalizedParser0.parse((List<? extends HasWord>) arrayList0);
      lexicalizedParser0.saveParserToSerialized("t;6i^~e#<PK");
      StringReader stringReader0 = new StringReader("t;6i^~e#<PK");
      LexicalizedParser.getParserFromSerializedFile("t;6i^~e#<PK");
      LexicalizedParser.getParserFromFile("t;6i^~e#<PK", options0);
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromSerializedFile("t;6i^~e#<PK");
      assertNotSame(lexicalizedParser1, lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testGetParserFromSerializedFileReturningLexicalizedParserWhereRequiresTagsIsFalse()  throws Throwable  {
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("t;I[T6i^~e#<PK", (FileFilter) null, options0);
      lexicalizedParser0.saveParserToSerialized("t;I[T6i^~e#<PK");
      StringReader stringReader0 = new StringReader("t;I[T6i^~e#<PK");
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromSerializedFile("t;I[T6i^~e#<PK");
      Tree tree0 = lexicalizedParser1.parseTree(arrayList0);
      assertNull(tree0);
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain0()  throws Throwable  {
      DiskTreebank diskTreebank0 = new DiskTreebank();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-savetraintrees";
      stringArray0[1] = "-ijcai03";
      stringArray0[2] = "MO5yVa";
      stringArray0[3] = "MO5yVa";
      stringArray0[4] = "-ijcai03";
      stringArray0[5] = "-ijcai03";
      stringArray0[6] = "MO5yVa";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException0()  throws Throwable  {
      String[] stringArray0 = new String[11];
      stringArray0[0] = "-savetraintrees";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1AndMain()  throws Throwable  {
      DiskTreebank diskTreebank0 = new DiskTreebank();
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      String[] stringArray0 = new String[0];
      LexicalizedParser.main(stringArray0);
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.loadModel(options0, stringArray0);
      assertNull(lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentExceptionAndSaveParserToSerialized()  throws Throwable  {
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("t;I[T6i^~e#<PK", (FileFilter) null, options0);
      lexicalizedParser0.saveParserToSerialized("t;I[T6i^~e#<PK");
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-ejci03";
      stringArray0[1] = "-ejci03";
      stringArray0[2] = "t;I[T6i^~e#<PK";
      stringArray0[3] = "-ejci03";
      stringArray0[4] = "-ejci03";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Unknown option: -ejci03
         //
         verifyException("edu.stanford.nlp.parser.lexparser.Options", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentExceptionAndMain0()  throws Throwable  {
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-treebank";
      stringArray0[1] = "-tokenizerfpcor";
      stringArray0[2] = "-tokenizerfpcor";
      stringArray0[3] = "-tokenizerfpcor";
      stringArray0[4] = "-tokenizerfpcor";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -test
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentException0()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-treebank";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -test
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testCopyLexicalizedParserAndSaveParserToTextFile()  throws Throwable  {
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("-saveToSerializedFile");
      shiftReduceOptions0.doDep = false;
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "-train2");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("-train2", (FileFilter) null, (Options) shiftReduceOptions0);
      LabeledScoredTreeNode labeledScoredTreeNode0 = new LabeledScoredTreeNode();
      LexicalizedParser.getParserFromTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("-?aveToSerializedFile");
      LexicalizedParser.getParserFromFile("-?aveToSerializedFile", shiftReduceOptions0);
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      assertNotSame(lexicalizedParser1, lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFileAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.doDep = false;
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1AndTrainFromTreebankTaking11And1WithNonNull()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      shiftReduceOptions0.doDep = false;
      RegExFileFilter regExFileFilter0 = new RegExFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) regExFileFilter0, (Options) shiftReduceOptions0);
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testGetTreePrintAndLoadModelTaking1And1ThrowsNullPointerException()  throws Throwable  {
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("-", (FileFilter) null, options0);
      NegraPennTreebankParserParams negraPennTreebankParserParams0 = new NegraPennTreebankParserParams();
      options0.tlpParams = (TreebankLangParserParams) negraPennTreebankParserParams0;
      options0.useUnigramWordSmoothing = true;
      lexicalizedParser0.getExtraEvals();
      lexicalizedParser0.getTreePrint();
      LexicalizedParser.buildTrainTransformer(options0);
      String[] stringArray0 = new String[8];
      stringArray0[0] = "-";
      stringArray0[1] = "-";
      stringArray0[2] = "3N~?Nz";
      stringArray0[3] = "-";
      stringArray0[4] = "-";
      stringArray0[5] = "BEGINBEGIN UNARY_GRAMMAR";
      stringArray0[6] = "-";
      stringArray0[7] = "-";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("-", stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsRuntimeExceptionAndMain()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("<?]}g");
      String string0 = "-tlpp";
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "-tlpp");
      String[] stringArray0 = new String[6];
      stringArray0[0] = "-tlpp";
      stringArray0[1] = "<?]}g";
      stringArray0[3] = "-tlpp";
      stringArray0[4] = "<?]}g";
      stringArray0[5] = "<?]}g";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.lang.ClassNotFoundException: Class '<?]}g.class' should be in target project, but could not be found!
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException1()  throws Throwable  {
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-tlpp";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException2()  throws Throwable  {
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-test";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[...]\" is null
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromFileReturningLexicalizedParserWhereRequiresTagsIsFalse()  throws Throwable  {
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("-savetoserializedfile", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser0.apply((List<? extends HasWord>) arrayList0);
      LexicalizedParser.getParserFromTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("-saveToSerializedFile");
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromFile("-saveToSerializedFile", shiftReduceOptions0);
      assertNotSame(lexicalizedParser1, lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingObjectInputStreamAndLoadModelTakingObjectInputStreamThrowsNullPointerException()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel((ObjectInputStream) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"java.io.ObjectInputStream.readObject()\" because \"ois\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ThrowsNoClassDefFoundError()  throws Throwable  {
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("t;I[OT-i^&~e#<!K", (FileFilter) null, options0);
      lexicalizedParser0.saveParserToSerialized("t;I[OT-i^&~e#<!K");
      StringReader stringReader0 = new StringReader("t;I[OT-i^&~e#<!K");
      String[] stringArray0 = new String[7];
      stringArray0[0] = "t;I[OT-i^&~e#<!K";
      stringArray0[1] = "t;I[OT-i^&~e#<!K";
      stringArray0[2] = "t;I[OT-i^&~e#<!K";
      stringArray0[3] = "t;I[OT-i^&~e#<!K";
      stringArray0[4] = "t;I[OT-i^&~e#<!K";
      stringArray0[5] = "t;I[OT-i^&~e#<!K";
      stringArray0[6] = "t;I[OT-i^&~e#<!K";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain1()  throws Throwable  {
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-escaper";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentExceptionAndGetExtraEvals()  throws Throwable  {
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("-savetos6rializedfile", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser0.apply((List<? extends HasWord>) arrayList0);
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.trainFromTreebank("yHY}k;i93SU9t7Z}W", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser1.getExtraEvals();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-testtreebank";
      stringArray0[1] = "-savetos6rializedfile";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -test
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndSaveParserToSerialized()  throws Throwable  {
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("t;I[OT-i^&~e#<!K", (FileFilter) null, options0);
      lexicalizedParser0.saveParserToSerialized("-test");
      StringReader stringReader0 = new StringReader("-test");
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-test";
      stringArray0[1] = "t;I[OT-i^&~e#<!K";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException3()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-testtreebank";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[...]\" is null
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsRuntimeException0()  throws Throwable  {
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("<?]}g");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "");
      String[] stringArray0 = new String[8];
      stringArray0[0] = "-tokenizerfactory";
      stringArray0[1] = "";
      stringArray0[2] = "<?]}g";
      stringArray0[3] = "<?]}g";
      stringArray0[4] = "&M";
      stringArray0[5] = "-savetoserializedfile";
      stringArray0[6] = "B]F1P-Du FBB\"PI.C";
      stringArray0[7] = "-trainTreebank";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // <?]}g: expecting BEGIN block; got end of file.
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileThrowsRuntimeException0()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "");
      // Undeclared exception!
      try { 
        LexicalizedParser.getParserFromTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", shiftReduceOptions0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory: expecting BEGIN block; got end of file.
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesLexicalizedParserAndCreatesLexicalizedParserAndTrainFromTreebankTaking11And1()  throws Throwable  {
      DiskTreebank diskTreebank0 = new DiskTreebank();
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options();
      String string0 = "treeTransformer";
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("-train", true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("treeTransformer", (FileFilter) extensionFileFilter0, options0);
      Options options1 = new Options(options0.tlpParams);
      LexicalizedParser lexicalizedParser1 = new LexicalizedParser(lexicalizedParser0.lex, lexicalizedParser0.bg, lexicalizedParser0.ug, lexicalizedParser0.dg, lexicalizedParser0.stateIndex, lexicalizedParser0.stateIndex, lexicalizedParser0.tagIndex, options1);
      TaggedWordFactory taggedWordFactory0 = new TaggedWordFactory('F');
      NPTmpRetainingTreeNormalizer nPTmpRetainingTreeNormalizer0 = new NPTmpRetainingTreeNormalizer((-1617121393), true);
      LabeledScoredTreeReaderFactory labeledScoredTreeReaderFactory0 = new LabeledScoredTreeReaderFactory(taggedWordFactory0, nPTmpRetainingTreeNormalizer0);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(labeledScoredTreeReaderFactory0, "treeTransformer");
      TreeGraphNode treeGraphNode0 = null;
      try {
        treeGraphNode0 = new TreeGraphNode((Label) null, memoryTreebank0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.ling.Label.value()\" because \"oldLabel\" is null
         //
         verifyException("edu.stanford.nlp.ling.CoreLabel$CoreLabelFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain2()  throws Throwable  {
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      Options options0 = new Options();
      String[] stringArray0 = new String[6];
      stringArray0[0] = "-parseinside";
      stringArray0[1] = "-savetoserializedfile";
      stringArray0[2] = "-savetoserializedfile";
      stringArray0[3] = "-savetoserializedfile";
      stringArray0[4] = "-savetoserializedfile";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[...]\" is null
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException4()  throws Throwable  {
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-parseinside";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNoClassDefFoundErrorAndMain0()  throws Throwable  {
      DiskTreebank diskTreebank0 = new DiskTreebank();
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-train";
      stringArray0[1] = "MO5yVa";
      stringArray0[2] = "-ijcai03";
      stringArray0[3] = "-saveToSerializedFile";
      stringArray0[4] = "-saveToSerializedFile";
      stringArray0[5] = "newTokenizerFactory";
      stringArray0[6] = "h";
      stringArray0[7] = "MO5yVa";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ThrowsNullPointerExceptionAndMain()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-encoding";
      stringArray0[1] = "-encoding";
      LexicalizedParser.main(stringArray0);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel((Options) shiftReduceOptions0, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray0()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-encoding";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileThrowsNullPointerException()  throws Throwable  {
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory();
      FileFilter fileFilter0 = null;
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("-sedtances", (FileFilter) null, options0);
      // Undeclared exception!
      try { 
        lexicalizedParser0.apply((List<? extends HasWord>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"java.util.List.iterator()\" because \"words\" is null
         //
         verifyException("edu.stanford.nlp.parser.common.ParserUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseStringsThrowsNoClassDefFoundError()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      List<String> list0 = List.of("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", "# These keywords determines the features extracted.  'generic' is language independent.", "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      // Undeclared exception!
      try { 
        lexicalizedParser0.parseStrings(list0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNoClassDefFoundErrorAndMain1()  throws Throwable  {
      DiskTreebank diskTreebank0 = new DiskTreebank();
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-train";
      stringArray0[1] = "MO5yVa";
      stringArray0[2] = "-ijcai03";
      stringArray0[3] = "-saveToSerializedFile";
      stringArray0[4] = "Zl4un3-tAyx";
      stringArray0[5] = "newTokenizerFactory";
      stringArray0[6] = "h";
      stringArray0[7] = "MO5yVa";
      String[] stringArray1 = new String[4];
      stringArray1[0] = "-train";
      stringArray1[1] = "trainFiles";
      stringArray1[2] = "7";
      stringArray1[3] = "h";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray1);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsArrayIndexOutOfBoundsException0()  throws Throwable  {
      DiskTreebank diskTreebank0 = new DiskTreebank();
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-tokenizeroptions";
      stringArray0[1] = "-tokenizeroptions";
      stringArray0[2] = "-tokenizeroptions";
      stringArray0[3] = "-tokenizeroptions";
      stringArray0[4] = "-tokenizeroptions";
      stringArray0[5] = "-tokenizeroptions";
      stringArray0[6] = "-tokenizeroptions";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 7 out of bounds for length 7
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseAndParse()  throws Throwable  {
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, true);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(100);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      ReaderIteratorFactory readerIteratorFactory0 = new ReaderIteratorFactory((Collection<?>) linkedList0);
      DelimitRegExIterator.DelimitRegExIteratorFactory<String> delimitRegExIterator_DelimitRegExIteratorFactory0 = new DelimitRegExIterator.DelimitRegExIteratorFactory<String>(";bD-=-NQ", (Function<String, String>) null);
      ObjectBank<String> objectBank0 = new ObjectBank<String>(readerIteratorFactory0, delimitRegExIterator_DelimitRegExIteratorFactory0);
      List<String> list0 = new Stack<String>();
      lexicalizedParser0.parseStrings(list0);
      Stack<CoreLabel> stack0 = new Stack<CoreLabel>();
      Tree tree0 = lexicalizedParser0.parse((List<? extends HasWord>) stack0);
      assertEquals(Double.NaN, tree0.score(), 0.01);
  }

  @Test(timeout = 4000)
  public void testMainThrowsArrayIndexOutOfBoundsExceptionAndMain0()  throws Throwable  {
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory();
      FileSystemHandling.shouldAllThrowIOExceptions();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-tokenizeroptions";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray1()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-tokenizerOptions";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain3()  throws Throwable  {
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "-tokenized");
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-tokenized";
      stringArray0[1] = "-tokenized";
      stringArray0[2] = "<?]}g";
      stringArray0[3] = "-tokenized";
      stringArray0[4] = "-tune";
      stringArray0[5] = "<?]}g";
      stringArray0[6] = "-tokenized";
      stringArray0[7] = "-tokenizerfactory";
      stringArray0[8] = "-tokenized";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray2()  throws Throwable  {
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "----";
      stringArray0[1] = "-tokenized";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testGetParserFromFileAndSaveParserToTextFileAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      assertFalse(lexicalizedParser0.requiresTags());
      
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", shiftReduceOptions0);
      assertFalse(lexicalizedParser1.requiresTags());
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileReturningLexicalizedParserWhereRequiresTagsIsFalse()  throws Throwable  {
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("-savetoserializedfile", (FileFilter) null, options0);
      lexicalizedParser0.apply((List<? extends HasWord>) arrayList0);
      LexicalizedParser.getParserFromTextFile("-savetoserializedfile", options0);
      LabelFactory labelFactory0 = StringLabel.factory();
      TreeGraphNodeFactory treeGraphNodeFactory0 = new TreeGraphNodeFactory(labelFactory0);
      BobChrisTreeNormalizer bobChrisTreeNormalizer0 = new BobChrisTreeNormalizer();
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory(treeGraphNodeFactory0, bobChrisTreeNormalizer0);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(115029, pennTreeReaderFactory0);
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, memoryTreebank0, options0);
      lexicalizedParser0.saveParserToTextFile("-saveToSerializedFile");
      LexicalizedParser.getParserFromTextFile("-saveToSerializedFile", options0);
      String[] stringArray0 = new String[2];
      stringArray0[0] = "\"\"XG5k";
      stringArray0[1] = "?{";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("?{", stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMain0()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("<?]}g");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "`|f,+$`=by");
      EvoSuiteFile evoSuiteFile1 = new EvoSuiteFile("<?]}g");
      FileSystemHandling.appendStringToFile(evoSuiteFile1, "-tokenizerfactory");
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-tune";
      stringArray0[1] = "<?]}g";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsRuntimeException1()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-tune";
      stringArray0[1] = "`|f,+$`=by";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // MemoryTreebank.processFile IOException in file `|f,+$`=by
         //
         verifyException("edu.stanford.nlp.trees.MemoryTreebank", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankThrowsNullPointerException()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      // Undeclared exception!
      try { 
        LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank((Treebank) null, (Treebank) null, (Treebank) null, shiftReduceOptions0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.trees.Treebank.transform(edu.stanford.nlp.trees.TreeTransformer)\" because \"trainTreebank\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException5()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      DiskTreebank diskTreebank0 = new DiskTreebank();
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-train2";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "-train2";
      shiftReduceOptions0.featureFactoryClass = shiftReduceOptions0.featureFactoryClass;
      stringArray0[4] = "*9Sbj!fz-#yM(p";
      stringArray0[5] = "OPTIONS";
      stringArray0[6] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[7] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[8] = "GiHEO*1=>djB";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[...]\" is null
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNoClassDefFoundErrorAndSaveParserToSerializedAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToSerialized("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      String[] stringArray0 = new String[4];
      stringArray0[0] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNoClassDefFoundErrorAndMain2()  throws Throwable  {
      DiskTreebank diskTreebank0 = new DiskTreebank();
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-train";
      stringArray0[1] = "MO5yVa";
      stringArray0[2] = "-ijcai03";
      stringArray0[3] = "MO5yVa";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNoClassDefFoundError0()  throws Throwable  {
      String[] stringArray0 = new String[6];
      stringArray0[0] = "-train";
      stringArray0[1] = "MB_";
      stringArray0[2] = "-(pejcl03";
      stringArray0[3] = "-saveToSerializedFile";
      stringArray0[4] = "MB_";
      stringArray0[5] = "-(pejcl03";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNoClassDefFoundError1()  throws Throwable  {
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-train";
      stringArray0[1] = "MB_";
      stringArray0[2] = "-UpejcLVA3";
      stringArray0[3] = "-saveToSerializedFile";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain4()  throws Throwable  {
      DiskTreebank diskTreebank0 = new DiskTreebank();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-loadfromtextfile";
      stringArray0[1] = "German";
      stringArray0[2] = "-sentences";
      stringArray0[3] = "German";
      stringArray0[4] = "-sentences";
      stringArray0[5] = "-ejci03";
      stringArray0[6] = "-ejci03";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.parserQuery()\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException6()  throws Throwable  {
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-train";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[...]\" is null
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException7()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-loadfromtextfile";
      stringArray0[1] = "-loadfromtextfile";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.parserQuery()\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNoClassDefFoundErrorAndMain3()  throws Throwable  {
      DiskTreebank diskTreebank0 = new DiskTreebank();
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-train";
      stringArray0[1] = "MO5yVa";
      stringArray0[2] = "-ijcai03";
      stringArray0[3] = "-saveToSerializedFile";
      stringArray0[4] = "Zl4un3-tAyx";
      stringArray0[5] = "newTokenizerFactory";
      stringArray0[6] = "h";
      stringArray0[7] = "5fdke=V%HyLEIlZ";
      stringArray0[8] = ")Wg9T?Uv'5Zp@)N";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNoClassDefFoundError2()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-train";
      stringArray0[1] = "MO5a";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray3()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-tagseparator";
      stringArray0[1] = "-tagseparator";
      LexicalizedParser.main(stringArray0);
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      assertTrue(arrayList0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankAndGetAnnotatedBinaryTreebankFromTreebankThrowsNullPointerException()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank(" K0M{lgQqX7)", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser0.parserQuery();
      Timing.startTime();
      List<Eval> list0 = lexicalizedParser0.getExtraEvals();
      assertEquals(0, list0.size());
      
      // Undeclared exception!
      try { 
        LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank((Treebank) null, (Treebank) null, (Treebank) null, shiftReduceOptions0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.trees.Treebank.transform(edu.stanford.nlp.trees.TreeTransformer)\" because \"trainTreebank\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentExceptionAndMain1()  throws Throwable  {
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory();
      FileSystemHandling.shouldAllThrowIOExceptions();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-sentejes";
      stringArray0[1] = "-sentejes";
      stringArray0[2] = "-sentejes";
      stringArray0[3] = "-sentejes";
      stringArray0[4] = "-train2";
      stringArray0[5] = "-sentejes";
      stringArray0[6] = "-sentejes";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -train2
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException8()  throws Throwable  {
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-train2";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[...]\" is null
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsStringIndexOutOfBoundsException()  throws Throwable  {
      Options options0 = new Options();
      String[] stringArray0 = new String[6];
      stringArray0[0] = "-loadfromtextfile";
      stringArray0[1] = "shin";
      stringArray0[2] = "";
      stringArray0[3] = "IWAlPH3E)Bt@";
      stringArray0[4] = "ile";
      stringArray0[5] = "Illegal access";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: StringIndexOutOfBoundsException");
      
      } catch(StringIndexOutOfBoundsException e) {
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray4()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-loadfromtextfile";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndBuildTrainBinarizer()  throws Throwable  {
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory();
      DiskTreebank diskTreebank0 = new DiskTreebank();
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options(englishTreebankParserParams0);
      options0.useSmoothTagProjection = false;
      LexicalizedParser.buildTrainBinarizer(options0);
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-model";
      stringArray0[1] = "-model";
      stringArray0[2] = "-model";
      stringArray0[3] = "-model";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException9()  throws Throwable  {
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-escaper";
      stringArray0[1] = "-escaper";
      stringArray0[2] = "-model";
      stringArray0[3] = "-escaper";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingObjectInputStreamThrowsNullPointerException()  throws Throwable  {
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "f=6?F@o%:j:-aFza";
      stringArray0[1] = "(ZwV";
      stringArray0[2] = "DEPENDENCY_GRAMMAR";
      stringArray0[3] = "A$>";
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      System.setCurrentTimeMillis(100);
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel((ObjectInputStream) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"java.io.ObjectInputStream.readObject()\" because \"ois\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsArrayIndexOutOfBoundsExceptionAndMain1()  throws Throwable  {
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, true, true);
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-savetotextfile";
      stringArray0[1] = "P/~PG)>oSSyl$";
      String[] stringArray1 = new String[1];
      stringArray1[0] = "-tagseparator";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray1);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray5()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-tagseparator";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsArrayIndexOutOfBoundsExceptionAndBuildTrainBinarizer()  throws Throwable  {
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory();
      DiskTreebank diskTreebank0 = new DiskTreebank();
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options(englishTreebankParserParams0);
      LexicalizedParser.buildTrainBinarizer(options0);
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-model";
      stringArray0[1] = "-model";
      stringArray0[2] = "-model";
      stringArray0[3] = "-model";
      stringArray0[4] = "-model";
      stringArray0[5] = "-model";
      stringArray0[6] = "-model";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 7 out of bounds for length 7
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsArrayIndexOutOfBoundsException1()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-model";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain5()  throws Throwable  {
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, true);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      FileSystemHandling.createFolder((EvoSuiteFile) null);
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-savetotextfile";
      stringArray0[1] = "P/~PG)>oSSyl$";
      stringArray0[2] = "RnQ&`0P93;kYBuLl";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsArrayIndexOutOfBoundsException2()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-savetotextfile";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 1 out of bounds for length 1
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetLexiconAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      Lexicon lexicon0 = lexicalizedParser0.getLexicon();
      assertEquals(0, lexicon0.numRules());
  }

  @Test(timeout = 4000)
  public void testGetLexiconAndGetParserFromSerializedFile()  throws Throwable  {
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, true);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      ReaderIteratorFactory readerIteratorFactory0 = new ReaderIteratorFactory((Collection<?>) linkedList0);
      linkedList0.removeAll(memoryTreebank0);
      DelimitRegExIterator.DelimitRegExIteratorFactory<String> delimitRegExIterator_DelimitRegExIteratorFactory0 = new DelimitRegExIterator.DelimitRegExIteratorFactory<String>(";bD-=-NQ", (Function<String, String>) null);
      ObjectBank<String> objectBank0 = new ObjectBank<String>(readerIteratorFactory0, delimitRegExIterator_DelimitRegExIteratorFactory0);
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.EXTENDED_FILTERING;
      List<String> list0 = Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) objectBank0, locale_FilteringMode0);
      lexicalizedParser0.parseStrings(list0);
      lexicalizedParser0.getLexicon();
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromSerializedFile("-tokenizermethod");
      assertNull(lexicalizedParser1);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileAndGetParserFromTextFile0()  throws Throwable  {
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("-tune", (FileFilter) null, options0);
      assertFalse(lexicalizedParser0.requiresTags());
      
      LexicalizedParser.getParserFromTextFile("-tune", options0);
      lexicalizedParser0.saveParserToTextFile("XXXX-XX-XX");
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileThrowsRuntimeException1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      // Undeclared exception!
      try { 
        LexicalizedParser.getParserFromTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", shiftReduceOptions0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory: expecting BEGIN block; got edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsRuntimeException2()  throws Throwable  {
      Options options0 = new Options();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-tokenizerfactory";
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("<?]}g");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "-tokenizerfactory");
      stringArray0[2] = "<?]}g";
      stringArray0[3] = ".Je:6|f.N\"9]ij";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // <?]}g: expecting BEGIN block; got -tokenizerfactory
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileAndGetParserFromTextFile1()  throws Throwable  {
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("-savetoserializedfile", (FileFilter) null, options0);
      lexicalizedParser0.apply((List<? extends HasWord>) arrayList0);
      LexicalizedParser.getParserFromTextFile("-savetoserializedfile", options0);
      lexicalizedParser0.saveParserToTextFile("-saveToSerializedFile");
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testMainThrowsArrayIndexOutOfBoundsException3()  throws Throwable  {
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-tagSeparator";
      stringArray0[1] = "BEGINBEGIN UNARY_GRAMMAR";
      stringArray0[2] = "-tokenizermethod";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index 3 out of bounds for length 3
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentExceptionAndMain2()  throws Throwable  {
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "-savetoserializedfile";
      String[] stringArray1 = new String[5];
      stringArray1[0] = "-traintreebank";
      stringArray1[1] = "-savetoserializedfile";
      stringArray1[2] = "R39'qo?Ot";
      stringArray1[3] = "R39'qo?Ot";
      stringArray1[4] = "-savetoserializedfile";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray1);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -train
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException10()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-traintreebank";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[...]\" is null
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndGetExtraEvals()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      NumberRangeFileFilter numberRangeFileFilter0 = new NumberRangeFileFilter(100, 100, true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("-saveToSerializedFile", (FileFilter) numberRangeFileFilter0, (Options) shiftReduceOptions0);
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-saveToSerializedFile";
      stringArray0[1] = "-saveToSerializedFile";
      stringArray0[2] = "-saveToSerializedFile";
      LexicalizedParser.main(stringArray0);
      lexicalizedParser0.getExtraEvals();
      PipedInputStream pipedInputStream0 = null;
      try {
        pipedInputStream0 = new PipedInputStream(0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Pipe Size <= 0
         //
         verifyException("java.io.PipedInputStream", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray6()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-savetoserializedfile";
      LexicalizedParser.main(stringArray0);
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray7()  throws Throwable  {
      String[] stringArray0 = new String[2];
      stringArray0[0] = "-saveToSerializedFile";
      stringArray0[1] = "Recovering using fall through strategy: will construct an (X ...) tree.";
      LexicalizedParser.main(stringArray0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain6()  throws Throwable  {
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "-savetoserializedfile";
      stringArray0[1] = "R39'qo?Ot";
      stringArray0[2] = "LkzQMnXN[yZ;;JO/Bo+";
      stringArray0[3] = "pK:>YBx9s',";
      stringArray0[4] = "-distanceBins";
      stringArray0[5] = "-train2";
      stringArray0[6] = "Extracting Dependencies...";
      stringArray0[7] = "6kV&:^aEN";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentException1()  throws Throwable  {
      String[] stringArray0 = new String[8];
      stringArray0[0] = "-tune";
      stringArray0[1] = "7`r+Qw u?.7(_";
      stringArray0[2] = "-tune";
      stringArray0[3] = "7`r+Qw u?.7(_";
      stringArray0[4] = "-tune";
      stringArray0[5] = "7`r+Qw u?.7(_";
      stringArray0[6] = "Writing out binary trees to ";
      stringArray0[7] = "7`r+Qw u?.7(_";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Constructor argument not valid list of number ranges: Writing out binary trees to 
         //
         verifyException("edu.stanford.nlp.io.NumberRangesFileFilter", e);
      }
  }

  @Test(timeout = 4000)
  public void testBuildTrainTransformerTaking2Arguments()  throws Throwable  {
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      NPTmpRetainingTreeNormalizer.NPTmpAdvRetainingTreeReaderFactory nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0 = new NPTmpRetainingTreeNormalizer.NPTmpAdvRetainingTreeReaderFactory();
      StringReader stringReader0 = new StringReader("-tune");
      nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0.newTreeReader(stringReader0);
      nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0.newTreeReader(stringReader0);
      TransformingTreebank[] transformingTreebankArray0 = new TransformingTreebank[3];
      TransformingTreebank transformingTreebank0 = new TransformingTreebank();
      Options options0 = new Options();
      TreeAnnotatorAndBinarizer treeAnnotatorAndBinarizer0 = new TreeAnnotatorAndBinarizer(options0.tlpParams, true, true, true, options0);
      CompositeTreeTransformer compositeTreeTransformer0 = LexicalizedParser.buildTrainTransformer(options0, treeAnnotatorAndBinarizer0);
      TransformingTreebank transformingTreebank1 = new TransformingTreebank(transformingTreebank0, compositeTreeTransformer0);
      transformingTreebankArray0[0] = transformingTreebank1;
      // Undeclared exception!
      try { 
        transformingTreebank1.textualSummary();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankReturningNonNull()  throws Throwable  {
      String string0 = "-escaper";
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-escaper";
      NegraPennTreebankParserParams negraPennTreebankParserParams0 = new NegraPennTreebankParserParams();
      DiskTreebank diskTreebank0 = negraPennTreebankParserParams0.diskTreebank();
      Options options0 = new Options(negraPennTreebankParserParams0);
      LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(diskTreebank0, (Treebank) null, diskTreebank0, options0);
      TimeFormatter.CustomDateFormatExtractor timeFormatter_CustomDateFormatExtractor0 = null;
      try {
        timeFormatter_CustomDateFormatExtractor0 = new TimeFormatter.CustomDateFormatExtractor("-escaper", "-escaper");
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // org/joda/time/format/DateTimeFormatterBuilder
         //
         verifyException("edu.stanford.nlp.time.TimeFormatter$FormatterBuilder", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1AndGetAnnotatedBinaryTreebankFromTreebank()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      TreebankLanguagePack treebankLanguagePack0 = shiftReduceOptions0.langpack();
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams(treebankLanguagePack0);
      DiskTreebank diskTreebank0 = hebrewTreebankParserParams0.diskTreebank();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (GrammarCompactor) exactGrammarCompactor0, (Options) shiftReduceOptions0);
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      ReaderIteratorFactory readerIteratorFactory0 = new ReaderIteratorFactory((Collection<?>) diskTreebank0);
      readerIteratorFactory0.remove(diskTreebank0);
      DelimitRegExIterator.DelimitRegExIteratorFactory<String> delimitRegExIterator_DelimitRegExIteratorFactory0 = DelimitRegExIterator.DelimitRegExIteratorFactory.defaultDelimitRegExIteratorFactory("jE6cH9");
      ObjectBank<String> objectBank0 = new ObjectBank<String>(readerIteratorFactory0, delimitRegExIterator_DelimitRegExIteratorFactory0);
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.AUTOSELECT_FILTERING;
      Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) objectBank0, locale_FilteringMode0);
      Vector<String> vector0 = new Vector<String>();
      lexicalizedParser0.parseStrings(vector0);
      Options options0 = new Options();
      LexicalizedParser.buildTrainTransformer(options0);
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      DiskTreebank diskTreebank1 = italianTreebankParserParams0.diskTreebank();
      Triple<Treebank, Treebank, Treebank> triple0 = LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(diskTreebank0, diskTreebank1, (Treebank) null, shiftReduceOptions0);
      assertNotNull(triple0);
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ReturningNullAndGetAnnotatedBinaryTreebankFromTreebank()  throws Throwable  {
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory();
      DiskTreebank diskTreebank0 = new DiskTreebank((-3358), pennTreeReaderFactory0);
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options(englishTreebankParserParams0);
      LexicalizedParser.buildTrainBinarizer(options0);
      Vector<String> vector0 = new Vector<String>();
      LexicalizedParser.loadModel("-model", (List<String>) vector0);
      Triple<Treebank, Treebank, Treebank> triple0 = LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(diskTreebank0, diskTreebank0, diskTreebank0, options0);
      assertNotNull(triple0);
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebankWithNull1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      Triple<Treebank, Treebank, Treebank> triple0 = LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, (Treebank) null, shiftReduceOptions0);
      assertNotNull(triple0);
  }

  @Test(timeout = 4000)
  public void testGetAnnotatedBinaryTreebankFromTreebank()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      Triple<Treebank, Treebank, Treebank> triple0 = LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank(memoryTreebank0, memoryTreebank0, memoryTreebank0, shiftReduceOptions0);
      assertNotNull(triple0);
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain7()  throws Throwable  {
      Options options0 = new Options();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-tokenizerfactory";
      stringArray0[1] = ",==!rDi.gz";
      stringArray0[2] = "<?]}g";
      stringArray0[3] = ".Je:6|f.N\"9]ij";
      stringArray0[4] = "Writing parser in text grammar format to file ";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException11()  throws Throwable  {
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-tokenizerfactory";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMainAndMainWithEmptyArray()  throws Throwable  {
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-tune";
      stringArray0[1] = "-tune";
      stringArray0[2] = "-tune";
      String[] stringArray1 = new String[0];
      LexicalizedParser.main(stringArray1);
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      assertTrue(arrayList0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithEmptyArray()  throws Throwable  {
      String[] stringArray0 = new String[0];
      LexicalizedParser.main(stringArray0);
      assertEquals(0, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFile()  throws Throwable  {
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("Yh$jRWcjbE,\r");
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      TransformingTreebank[] transformingTreebankArray0 = new TransformingTreebank[1];
      NPTmpRetainingTreeNormalizer.NPTmpAdvRetainingTreeReaderFactory nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0 = new NPTmpRetainingTreeNormalizer.NPTmpAdvRetainingTreeReaderFactory();
      StringReader stringReader0 = new StringReader("");
      nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0.newTreeReader(stringReader0);
      TransformingTreebank transformingTreebank0 = new TransformingTreebank(nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0);
      MockRandom mockRandom0 = new MockRandom();
      nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0.newTreeReader(stringReader0);
      transformingTreebankArray0[0] = transformingTreebank0;
      arrayList0.toArray(transformingTreebankArray0);
      ArrayCoreMap arrayCoreMap0 = new ArrayCoreMap();
      lexicalizedParser0.getExtraEvals();
      lexicalizedParser0.parseTree(arrayList0);
      lexicalizedParser0.saveParserToTextFile(".gz");
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFile()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      lexicalizedParser0.saveParserToTextFile(".gz");
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.getParserFromTextFile("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", shiftReduceOptions0);
      assertNull(lexicalizedParser1);
  }

  @Test(timeout = 4000)
  public void testDefaultCoreNLPFlagsAndGetTreePrintThrowsNoClassDefFoundError()  throws Throwable  {
      LabelFactory labelFactory0 = WordTag.factory();
      LabeledScoredTreeReaderFactory labeledScoredTreeReaderFactory0 = new LabeledScoredTreeReaderFactory(labelFactory0);
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      StringReader stringReader0 = new StringReader("3");
      BufferedReader bufferedReader0 = new BufferedReader(stringReader0);
      labeledScoredTreeReaderFactory0.newTreeReader(bufferedReader0);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(34, labeledScoredTreeReaderFactory0);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      lexicalizedParser0.defaultCoreNLPFlags();
      lexicalizedParser0.tokenize("-test");
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, true, true);
      LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (GrammarCompactor) exactGrammarCompactor0, (Options) shiftReduceOptions0);
      // Undeclared exception!
      try { 
        lexicalizedParser0.getTreePrint();
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testDefaultCoreNLPFlagsAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      RegExFileFilter regExFileFilter0 = new RegExFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) regExFileFilter0, (Options) shiftReduceOptions0);
      String[] stringArray0 = lexicalizedParser0.defaultCoreNLPFlags();
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testTreebankLanguagePackAndTrainFromTreebankTaking11And1WithNonNull()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      RegExFileFilter regExFileFilter0 = new RegExFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) regExFileFilter0, (Options) shiftReduceOptions0);
      TreebankLanguagePack treebankLanguagePack0 = lexicalizedParser0.treebankLanguagePack();
      assertTrue(treebankLanguagePack0.supportsGrammaticalStructures());
  }

  @Test(timeout = 4000)
  public void testTreebankLanguagePackAndGetTreePrintThrowsNoClassDefFoundError()  throws Throwable  {
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("-tune", (FileFilter) null, options0);
      LexicalizedParser.getParserFromTextFile("-tune", options0);
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(100, pennTreeReaderFactory0);
      Predicate<Tree>[] predicateArray0 = (Predicate<Tree>[]) Array.newInstance(Predicate.class, 4);
      TreebankLanguagePack treebankLanguagePack0 = lexicalizedParser0.treebankLanguagePack();
      TreeFilters.HasMatchingChild treeFilters_HasMatchingChild0 = new TreeFilters.HasMatchingChild(treebankLanguagePack0, "HD");
      predicateArray0[0] = (Predicate<Tree>) treeFilters_HasMatchingChild0;
      Filters.RandomFilter<Tree> filters_RandomFilter0 = new Filters.RandomFilter<Tree>();
      predicateArray0[1] = (Predicate<Tree>) filters_RandomFilter0;
      BobChrisTreeNormalizer.EmptyFilter bobChrisTreeNormalizer_EmptyFilter0 = new BobChrisTreeNormalizer.EmptyFilter();
      Predicate<Tree> predicate0 = bobChrisTreeNormalizer_EmptyFilter0.and(treeFilters_HasMatchingChild0);
      predicateArray0[2] = predicate0;
      Filters.RandomFilter<Tree> filters_RandomFilter1 = new Filters.RandomFilter<Tree>(500.370157);
      predicateArray0[3] = (Predicate<Tree>) filters_RandomFilter1;
      Filters.ConjFilter<Tree> filters_ConjFilter0 = new Filters.ConjFilter<Tree>(predicateArray0);
      FilteringTreebank filteringTreebank0 = new FilteringTreebank(memoryTreebank0, filters_ConjFilter0);
      LexicalizedParser.trainFromTreebank((Treebank) filteringTreebank0, options0);
      lexicalizedParser0.saveParserToTextFile("XXXX-XX-XX");
      // Undeclared exception!
      try { 
        lexicalizedParser0.getTreePrint();
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testBuildTrainBinarizer()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      FileSystemHandling.shouldAllThrowIOExceptions();
      LexicalizedParser.buildTrainTransformer((Options) shiftReduceOptions0);
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(100);
      LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      TreeAnnotatorAndBinarizer treeAnnotatorAndBinarizer0 = LexicalizedParser.buildTrainBinarizer(shiftReduceOptions0);
      assertNotNull(treeAnnotatorAndBinarizer0);
  }

  @Test(timeout = 4000)
  public void testGetTLPParamsThrowsStringIndexOutOfBoundsException()  throws Throwable  {
      LexicalizedParser.getParserFromSerializedFile("Yh$jRWcjbE,\r");
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-sentences";
      stringArray0[1] = "";
      stringArray0[2] = "";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: StringIndexOutOfBoundsException");
      
      } catch(StringIndexOutOfBoundsException e) {
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException12()  throws Throwable  {
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-sentences";
      stringArray0[1] = "-sentences";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking3Arguments()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      HungarianTreebankParserParams hungarianTreebankParserParams0 = new HungarianTreebankParserParams();
      Options options0 = new Options(shiftReduceOptions0.tlpParams);
      String[] stringArray0 = new String[0];
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.loadModel("uynf{[}!qeNO L5_8r", (Options) shiftReduceOptions0, stringArray0);
      assertNull(lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testSaveParserToSerializedThrowsRuntimeException()  throws Throwable  {
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("-tune", (FileFilter) null, options0);
      LexicalizedParser.buildTrainTransformer(options0);
      options0.dcTags = false;
      LexicalizedParser.getParserFromTextFile("]", options0);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("-tune");
      FileSystemHandling.createFolder(evoSuiteFile0);
      // Undeclared exception!
      try { 
        lexicalizedParser0.saveParserToSerialized("-tune");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.io.FileNotFoundException
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsIllegalArgumentExceptionAndMain3()  throws Throwable  {
      String[] stringArray0 = new String[6];
      stringArray0[0] = "-sentn.Zes";
      stringArray0[1] = "-tokenizermethod";
      stringArray0[2] = "-tune";
      stringArray0[3] = "-tune";
      stringArray0[4] = "-sentn.Zes";
      stringArray0[5] = "-tune";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Bad arguments after -tune
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException13()  throws Throwable  {
      String[] stringArray0 = new String[7];
      stringArray0[0] = "-tune";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[...]\" is null
         //
         verifyException("edu.stanford.nlp.parser.common.ArgUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException14()  throws Throwable  {
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-sentences";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromFileAndGetParserFromFile()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.getParserFromFile("-trainTreebank", shiftReduceOptions0);
      assertNull(lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ReturningNullAndLoadModelTaking1And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      String[] stringArray0 = new String[0];
      LexicalizedParser.loadModel("Sorry, but parsers with rerankers cannot be saved to text file", stringArray0);
      ShiftReduceOptions shiftReduceOptions1 = new ShiftReduceOptions();
      ItalianTreebankParserParams italianTreebankParserParams1 = new ItalianTreebankParserParams();
      italianTreebankParserParams1.memoryTreebank();
      WordTokenFactory wordTokenFactory0 = new WordTokenFactory();
  }

  @Test(timeout = 4000)
  public void testLexicalizedParserQueryAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      LexicalizedParserQuery lexicalizedParserQuery0 = lexicalizedParser0.lexicalizedParserQuery();
      assertEquals(Double.NEGATIVE_INFINITY, lexicalizedParserQuery0.getBestScore(), 0.01);
  }

  @Test(timeout = 4000)
  public void testLexicalizedParserQueryAndLexicalizedParserQuery()  throws Throwable  {
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory();
      DiskTreebank diskTreebank0 = new DiskTreebank((-3358), pennTreeReaderFactory0);
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options(englishTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      ReaderIteratorFactory readerIteratorFactory0 = new ReaderIteratorFactory((Collection<?>) linkedList0);
      englishTreebankParserParams0.treebank();
      DelimitRegExIterator.DelimitRegExIteratorFactory<String> delimitRegExIterator_DelimitRegExIteratorFactory0 = DelimitRegExIterator.DelimitRegExIteratorFactory.defaultDelimitRegExIteratorFactory((String) null);
      ObjectBank<String> objectBank0 = new ObjectBank<String>(readerIteratorFactory0, delimitRegExIterator_DelimitRegExIteratorFactory0);
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.EXTENDED_FILTERING;
      List<String> list0 = Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) objectBank0, locale_FilteringMode0);
      lexicalizedParser0.parseStrings(list0);
      WordTokenFactory wordTokenFactory0 = new WordTokenFactory();
      LexicalizedParserQuery lexicalizedParserQuery0 = lexicalizedParser0.lexicalizedParserQuery();
      assertFalse(lexicalizedParserQuery0.parseFallback());
  }

  @Test(timeout = 4000)
  public void testGetTreePrintThrowsNoClassDefFoundError()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      assertFalse(lexicalizedParser0.requiresTags());
      
      // Undeclared exception!
      try { 
        lexicalizedParser0.getTreePrint();
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetTreePrintAndGetTreePrintThrowsNoClassDefFoundError()  throws Throwable  {
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory();
      DiskTreebank diskTreebank0 = new DiskTreebank((-3358), pennTreeReaderFactory0);
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options(englishTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      lexicalizedParser0.getTLPParams();
      // Undeclared exception!
      try { 
        lexicalizedParser0.getTreePrint();
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testRequiresTagsAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      boolean boolean0 = lexicalizedParser0.requiresTags();
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void testRequiresTagsAndRequiresTags()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      MemoryTreebank memoryTreebank0 = italianTreebankParserParams0.memoryTreebank();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (Options) shiftReduceOptions0);
      LexicalizedParser lexicalizedParser1 = LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      String[] stringArray0 = new String[0];
      lexicalizedParser1.setOptionFlags(stringArray0);
      lexicalizedParser1.requiresTags();
      Options options0 = new Options(italianTreebankParserParams0);
      assertTrue(options0.genStop);
  }

  @Test(timeout = 4000)
  public void testSaveParserToTextFileThrowsRuntimeException()  throws Throwable  {
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("Yh$jRWcjbE,\r");
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      NPTmpRetainingTreeNormalizer.NPTmpAdvRetainingTreeReaderFactory nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0 = new NPTmpRetainingTreeNormalizer.NPTmpAdvRetainingTreeReaderFactory();
      StringReader stringReader0 = new StringReader("");
      nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0.newTreeReader(stringReader0);
      TransformingTreebank transformingTreebank0 = new TransformingTreebank(nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0);
      MockRandom mockRandom0 = new MockRandom();
      nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0.newTreeReader(stringReader0);
      ArrayCoreMap arrayCoreMap0 = new ArrayCoreMap();
      Vector<Locale.LanguageRange> vector0 = new Vector<Locale.LanguageRange>();
      ObjectBank.getLineIterator("6ndercut", (String) null);
      FileSystemHandling.shouldAllThrowIOExceptions();
      WordTokenFactory wordTokenFactory0 = new WordTokenFactory();
      // Undeclared exception!
      try { 
        lexicalizedParser0.saveParserToTextFile("");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // java.io.FileNotFoundException
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking3ArgumentsThrowsNullPointerExceptionAndLoadModelTaking3ArgumentsWithNonEmptyString()  throws Throwable  {
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      Options options0 = spanishUnknownWordModelTrainer0.op;
      String[] stringArray0 = new String[1];
      stringArray0[0] = "|*<Ob~Ka{did ";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("|*<Ob~Ka{did ", (Options) null, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankAndGetParserFromTreebankThrowsTooManyResourcesException()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      MemoryTreebank memoryTreebank0 = englishTreebankParserParams0.memoryTreebank();
      Stack<Predicate<Tree>> stack0 = new Stack<Predicate<Tree>>();
      boolean boolean0 = true;
      englishTreebankParserParams0.setEvaluateGrammaticalFunctions(true);
      Filters.ConjFilter<Tree> filters_ConjFilter0 = new Filters.ConjFilter<Tree>(stack0);
      FilteringTreebank filteringTreebank0 = new FilteringTreebank(memoryTreebank0, filters_ConjFilter0);
      Options options0 = new Options(englishTreebankParserParams0);
      LexicalizedParser.trainFromTreebank((Treebank) filteringTreebank0, options0);
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      italianTreebankParserParams0.memoryTreebank();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      Stack<TaggedWord> stack1 = new Stack<TaggedWord>();
      Vector<TaggedWord> vector0 = new Vector<TaggedWord>();
      List<List<TaggedWord>> list0 = List.of(stack1, stack1, stack1, stack1, stack1, vector0);
      // Undeclared exception!
      LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, 2205.5359394, exactGrammarCompactor0, options0, memoryTreebank0, list0);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankWithNonEmptyList()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LinkedList<List<TaggedWord>> linkedList0 = new LinkedList<List<TaggedWord>>();
      Vector<TaggedWord> vector0 = new Vector<TaggedWord>();
      linkedList0.add((List<TaggedWord>) vector0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, false);
      // Undeclared exception!
      LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, 100, exactGrammarCompactor0, shiftReduceOptions0, memoryTreebank0, linkedList0);
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankThrowsTooManyResourcesException()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, true, true);
      LinkedList<List<TaggedWord>> linkedList0 = new LinkedList<List<TaggedWord>>();
      // Undeclared exception!
      LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, 100, exactGrammarCompactor0, shiftReduceOptions0, memoryTreebank0, linkedList0);
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingNoArguments()  throws Throwable  {
      List<String> list0 = new Vector<String>();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.loadModel();
      assertNull(lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testSetOptionFlagsThrowsNullPointerException()  throws Throwable  {
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory();
      DiskTreebank diskTreebank0 = new DiskTreebank((-3358), pennTreeReaderFactory0);
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options(englishTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      ReaderIteratorFactory readerIteratorFactory0 = new ReaderIteratorFactory((Collection<?>) linkedList0);
      englishTreebankParserParams0.treebank();
      lexicalizedParser0.getParserQueryEvals();
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      lexicalizedParser0.parseTree(arrayList0);
      String[] stringArray0 = new String[4];
      stringArray0[0] = null;
      stringArray0[1] = null;
      stringArray0[2] = "s%#|oX5";
      stringArray0[3] = null;
      // Undeclared exception!
      try { 
        lexicalizedParser0.setOptionFlags(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.equalsIgnoreCase(String)\" because \"args[i]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.Options", e);
      }
  }

  @Test(timeout = 4000)
  public void testSetOptionFlags()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      String[] stringArray0 = new String[0];
      lexicalizedParser0.setOptionFlags(stringArray0);
      List<Eval> list0 = lexicalizedParser0.getExtraEvals();
      assertTrue(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testGetExtraEvalsAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      List<Eval> list0 = lexicalizedParser0.getExtraEvals();
      assertEquals(0, list0.size());
  }

  @Test(timeout = 4000)
  public void testParseTreeAndTrainFromTreebankTaking11And1()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      Stack<WordLemmaTag> stack0 = new Stack<WordLemmaTag>();
      Tree tree0 = lexicalizedParser0.parseTree(stack0);
      assertNull(tree0);
  }

  @Test(timeout = 4000)
  public void testGetExtraEvalsAndParseTree()  throws Throwable  {
      String string0 = "";
      String string1 = "Yh$jRWcjbE,\\r";
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("Yh$jRWcjbE,\r");
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      TransformingTreebank[] transformingTreebankArray0 = new TransformingTreebank[1];
      NPTmpRetainingTreeNormalizer.NPTmpAdvRetainingTreeReaderFactory nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0 = new NPTmpRetainingTreeNormalizer.NPTmpAdvRetainingTreeReaderFactory();
      StringReader stringReader0 = new StringReader("");
      nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0.newTreeReader(stringReader0);
      TransformingTreebank transformingTreebank0 = new TransformingTreebank(nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0);
      MockRandom mockRandom0 = new MockRandom();
      nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0.newTreeReader(stringReader0);
      transformingTreebankArray0[0] = transformingTreebank0;
      arrayList0.toArray(transformingTreebankArray0);
      ArrayCoreMap arrayCoreMap0 = new ArrayCoreMap();
      lexicalizedParser0.getExtraEvals();
      lexicalizedParser0.parseTree(arrayList0);
      // Undeclared exception!
      try { 
        LexicalizedParser.trainFromTreebank((Treebank) transformingTreebank0, (Options) shiftReduceOptions0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testCopyLexicalizedParserReturningLexicalizedParserWhereRequiresTagsIsFalse()  throws Throwable  {
      Options options0 = new Options();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "5xegsoGK+";
      stringArray0[1] = "";
      stringArray0[2] = "";
      stringArray0[3] = "";
      RegExFileFilter regExFileFilter0 = new RegExFileFilter("5xegsoGK+");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("bed", (FileFilter) regExFileFilter0, options0);
      Function.identity();
      lexicalizedParser0.loadTagger();
      LexicalizedParser.copyLexicalizedParser(lexicalizedParser0);
      MockFileInputStream mockFileInputStream0 = null;
      try {
        mockFileInputStream0 = new MockFileInputStream((String) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.evosuite.runtime.mock.java.io.MockFileInputStream", e);
      }
  }

  @Test(timeout = 4000)
  public void testSaveParserToSerialized()  throws Throwable  {
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("-tune", (FileFilter) null, options0);
      LexicalizedParser.getParserFromTextFile("]", options0);
      lexicalizedParser0.saveParserToSerialized("-tune");
      lexicalizedParser0.saveParserToTextFile("XXXX-XX-XX");
      assertFalse(lexicalizedParser0.requiresTags());
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1WithEmptyString()  throws Throwable  {
      String string0 = "";
      String string1 = "Yh$jRWcjbE,\\r";
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("Yh$jRWcjbE,\r");
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser.trainFromTreebank("", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      Properties properties0 = shiftReduceOptions0.testOptions.evals;
      PresetSequenceClassifier<CoreLabel> presetSequenceClassifier0 = new PresetSequenceClassifier<CoreLabel>(properties0);
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      presetSequenceClassifier0.classify((List<CoreLabel>) arrayList0);
      TransformingTreebank[] transformingTreebankArray0 = new TransformingTreebank[1];
      NPTmpRetainingTreeNormalizer.NPTmpAdvRetainingTreeReaderFactory nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0 = new NPTmpRetainingTreeNormalizer.NPTmpAdvRetainingTreeReaderFactory();
      StringReader stringReader0 = new StringReader("");
      nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0.newTreeReader(stringReader0);
      // Undeclared exception!
      try { 
        CharBuffer.wrap((CharSequence) "Yh$jRWcjbE,\r", 3, 1136);
        fail("Expecting exception: IndexOutOfBoundsException");
      
      } catch(IndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.nio.CharBuffer", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserQueryEvals()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      List<ParserQueryEval> list0 = lexicalizedParser0.getParserQueryEvals();
      assertEquals(0, list0.size());
  }

  @Test(timeout = 4000)
  public void testGetOpAndGetParserQueryEvals()  throws Throwable  {
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      MemoryTreebank memoryTreebank0 = englishTreebankParserParams0.memoryTreebank();
      Stack<Predicate<Tree>> stack0 = new Stack<Predicate<Tree>>();
      englishTreebankParserParams0.setEvaluateGrammaticalFunctions(true);
      Filters.ConjFilter<Tree> filters_ConjFilter0 = new Filters.ConjFilter<Tree>(stack0);
      FilteringTreebank filteringTreebank0 = new FilteringTreebank(memoryTreebank0, filters_ConjFilter0);
      Options options0 = new Options(englishTreebankParserParams0);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) filteringTreebank0, options0);
      Properties properties0 = options0.testOptions.evals;
      PresetSequenceClassifier<CoreLabel> presetSequenceClassifier0 = new PresetSequenceClassifier<CoreLabel>(properties0);
      options0.wordFunction = (Function<String, String>) presetSequenceClassifier0;
      lexicalizedParser0.getParserQueryEvals();
      lexicalizedParser0.getTLPParams();
      Options options1 = lexicalizedParser0.getOp();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "M1$>&Rn!MS1Y6GI";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel(options1, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testCopyLexicalizedParserAndCopyLexicalizedParserThrowsNullPointerException()  throws Throwable  {
      // Undeclared exception!
      try { 
        LexicalizedParser.copyLexicalizedParser((LexicalizedParser) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"lex\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ThrowsNullPointerExceptionAndParseTreeAndTrainFromTreebankTaking11And1()  throws Throwable  {
      Options options0 = new Options();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("Constructor argument not valid list of number ranges (too many hyphens): ", (FileFilter) null, options0);
      Vector<WordLemmaTag> vector0 = new Vector<WordLemmaTag>();
      lexicalizedParser0.parseTree(vector0);
      String[] stringArray0 = new String[5];
      stringArray0[0] = "Constructor argument not valid list of number ranges (too many hyphens): ";
      stringArray0[1] = "Constructor argument not valid list of number ranges (too many hyphens): ";
      stringArray0[2] = "Constructor argument not valid list of number ranges (too many hyphens): ";
      stringArray0[3] = "Constructor argument not valid list of number ranges (too many hyphens): ";
      stringArray0[4] = "Constructor argument not valid list of number ranges (too many hyphens): ";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel(options0, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ThrowsNullPointerExceptionAndLoadModelTaking1And1()  throws Throwable  {
      Options options0 = new Options();
      String[] stringArray0 = new String[6];
      stringArray0[0] = "-tokenizerOptions";
      stringArray0[1] = "-[k\nm`";
      options0.dcTags = true;
      stringArray0[2] = "}";
      stringArray0[3] = "";
      stringArray0[4] = "";
      stringArray0[5] = "5xegsoGK+";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel(options0, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseStringsAndParseStringsThrowsNoClassDefFoundError()  throws Throwable  {
      ExtensionFileFilter extensionFileFilter0 = new ExtensionFileFilter("Yh$jRWcjbE,\r");
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("# encoding = UTF-8", (FileFilter) extensionFileFilter0, (Options) shiftReduceOptions0);
      ArrayList<CoreLabel> arrayList0 = new ArrayList<CoreLabel>();
      TransformingTreebank[] transformingTreebankArray0 = new TransformingTreebank[6];
      NPTmpRetainingTreeNormalizer.NPTmpAdvRetainingTreeReaderFactory nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0 = new NPTmpRetainingTreeNormalizer.NPTmpAdvRetainingTreeReaderFactory();
      StringReader stringReader0 = new StringReader("# encoding = UTF-8");
      stringReader0.ready();
      nPTmpRetainingTreeNormalizer_NPTmpAdvRetainingTreeReaderFactory0.newTreeReader(stringReader0);
      arrayList0.toArray(transformingTreebankArray0);
      List<String> list0 = List.of("Basic usage (see Javadoc for more): java edu.stanford.nlp.parser.lexparser.LexicalizedParser parserFileOrUrl filename*", "# encoding = UTF-8", "-parseinside", "`U]N", "scam", "# encoding = UTF-8", "-loadFromTextFile", "k]Ig|&rt");
      // Undeclared exception!
      try { 
        lexicalizedParser0.parseStrings(list0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.UniversalSemanticHeadFinder
         //
         verifyException("edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams", e);
      }
  }

  @Test(timeout = 4000)
  public void testParseStringsAndParseStringsWithEmptyList()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      RegExFileFilter regExFileFilter0 = new RegExFileFilter("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) regExFileFilter0, (Options) shiftReduceOptions0);
      Stack<String> stack0 = new Stack<String>();
      Tree tree0 = lexicalizedParser0.parseStrings(stack0);
      assertEquals(Double.NaN, tree0.score(), 0.01);
  }

  @Test(timeout = 4000)
  public void testParserQuery()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      ParserQuery parserQuery0 = lexicalizedParser0.parserQuery();
      assertEquals(Double.NEGATIVE_INFINITY, parserQuery0.getPCFGScore(), 0.01);
  }

  @Test(timeout = 4000)
  public void testParseStringsReturningTreeWhereScoreIsPositive()  throws Throwable  {
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory();
      DiskTreebank diskTreebank0 = new DiskTreebank((-3358), pennTreeReaderFactory0);
      EnglishTreebankParserParams englishTreebankParserParams0 = new EnglishTreebankParserParams();
      Options options0 = new Options(englishTreebankParserParams0);
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, false);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) diskTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      LinkedList<Locale.LanguageRange> linkedList0 = new LinkedList<Locale.LanguageRange>();
      ReaderIteratorFactory readerIteratorFactory0 = new ReaderIteratorFactory((Collection<?>) linkedList0);
      String string0 = null;
      englishTreebankParserParams0.treebank();
      DelimitRegExIterator.DelimitRegExIteratorFactory<String> delimitRegExIterator_DelimitRegExIteratorFactory0 = DelimitRegExIterator.DelimitRegExIteratorFactory.defaultDelimitRegExIteratorFactory((String) null);
      ObjectBank<String> objectBank0 = new ObjectBank<String>(readerIteratorFactory0, delimitRegExIterator_DelimitRegExIteratorFactory0);
      Locale.FilteringMode locale_FilteringMode0 = Locale.FilteringMode.EXTENDED_FILTERING;
      List<String> list0 = Locale.filterTags((List<Locale.LanguageRange>) linkedList0, (Collection<String>) objectBank0, locale_FilteringMode0);
      lexicalizedParser0.parseStrings(list0);
      String[] stringArray0 = new String[9];
      stringArray0[0] = null;
      stringArray0[1] = null;
      stringArray0[2] = null;
      stringArray0[3] = null;
      stringArray0[4] = null;
      stringArray0[5] = null;
      stringArray0[6] = null;
      IntFunction<List<Class<CoreLabel>>[]> intFunction0 = (IntFunction<List<Class<CoreLabel>>[]>) mock(IntFunction.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(intFunction0).apply(anyInt());
      // Undeclared exception!
      try { 
        diskTreebank0.toArray(intFunction0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read the array length because \"a\" is null
         //
         verifyException("java.util.AbstractCollection", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking11And1AndTrainFromTreebankTaking11And1WithNull()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      Stack<WordLemmaTag> stack0 = new Stack<WordLemmaTag>();
      Tree tree0 = lexicalizedParser0.apply((List<? extends HasWord>) stack0);
      assertEquals(Double.NaN, tree0.score(), 0.01);
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1WithNonEmptyList()  throws Throwable  {
      List<String> list0 = List.of("k9E`:\"JOPup>eu", "k9E`:\"JOPup>eu", "k9E`:\"JOPup>eu", "NT");
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("4C(J6BN%d{AUYV\">y", list0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankWithNull()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(2862);
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      MemoryTreebank memoryTreebank1 = italianTreebankParserParams0.memoryTreebank();
      // Undeclared exception!
      LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, 0.0, (GrammarCompactor) null, shiftReduceOptions0, memoryTreebank1, (List<List<TaggedWord>>) null);
  }

  @Test(timeout = 4000)
  public void testGetTLPParams()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory", (FileFilter) null, (Options) shiftReduceOptions0);
      TreebankLangParserParams treebankLangParserParams0 = lexicalizedParser0.getTLPParams();
      assertEquals("UTF-8", treebankLangParserParams0.getInputEncoding());
  }

  @Test(timeout = 4000)
  public void testGetParserFromTreebankWithZeroAndNull()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank("edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory");
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(shiftReduceOptions0, false, true);
      // Undeclared exception!
      LexicalizedParser.getParserFromTreebank(memoryTreebank0, memoryTreebank0, 0.0, exactGrammarCompactor0, shiftReduceOptions0, memoryTreebank0, (List<List<TaggedWord>>) null);
  }

  @Test(timeout = 4000)
  public void testGetTLPParamsAndTrainFromTreebankTaking11And1()  throws Throwable  {
      HebrewTreebankParserParams hebrewTreebankParserParams0 = new HebrewTreebankParserParams();
      TreeReaderFactory treeReaderFactory0 = hebrewTreebankParserParams0.treeReaderFactory();
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(treeReaderFactory0);
      Options options0 = new Options();
      ExactGrammarCompactor exactGrammarCompactor0 = new ExactGrammarCompactor(options0, true, true);
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, (GrammarCompactor) exactGrammarCompactor0, options0);
      TreebankLangParserParams treebankLangParserParams0 = lexicalizedParser0.getTLPParams();
      assertTrue(treebankLangParserParams0.supportsBasicDependencies());
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain8()  throws Throwable  {
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain9()  throws Throwable  {
      PennTreeReaderFactory pennTreeReaderFactory0 = new PennTreeReaderFactory();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-sedtAnces";
      stringArray0[1] = "-sedtAnces";
      stringArray0[2] = "-sedtAnces";
      stringArray0[3] = "[;>k{E{'^@=S$";
      stringArray0[4] = "-sedtAnces";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainAndMain1()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-tlpp";
      LexicalizedParser.main(stringArray0);
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainAndMainWithNonEmptyArray8()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "-distanceBins";
      LexicalizedParser.main(stringArray0);
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException15()  throws Throwable  {
      String[] stringArray0 = new String[9];
      stringArray0[0] = "!m/#XrhTOa";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerExceptionAndMain10()  throws Throwable  {
      String[] stringArray0 = new String[5];
      stringArray0[0] = "-loadfromserializedfile";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testMainThrowsNullPointerException16()  throws Throwable  {
      String[] stringArray0 = new String[1];
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.charAt(int)\" because \"args[argIndex]\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetTLPParamsThrowsNullPointerException()  throws Throwable  {
      LexicalizedParser.getParserFromSerializedFile("ADJP=l=DT");
      String[] stringArray0 = new String[1];
      stringArray0[0] = "ADJP=l=DT";
      // Undeclared exception!
      try { 
        LexicalizedParser.main(stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"op\" because \"lp\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking3ArgumentsThrowsNullPointerExceptionAndLoadModelTaking3Arguments()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      String[] stringArray0 = new String[6];
      stringArray0[0] = null;
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "word-processing";
      stringArray0[3] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[4] = null;
      stringArray0[5] = null;
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel((String) null, (Options) shiftReduceOptions0, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Attempt to open file with null name
         //
         verifyException("edu.stanford.nlp.io.IOUtils", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking2ArgumentsThrowsNullPointerException()  throws Throwable  {
      NegraPennTreebankParserParams negraPennTreebankParserParams0 = new NegraPennTreebankParserParams();
      negraPennTreebankParserParams0.treebank();
      MemoryTreebank memoryTreebank0 = negraPennTreebankParserParams0.memoryTreebank();
      Options options0 = new Options();
      String string0 = "))UHXh\"y/{\\E-EJiO";
      NPTmpRetainingTreeNormalizer.NPTmpRetainingTreeReaderFactory nPTmpRetainingTreeNormalizer_NPTmpRetainingTreeReaderFactory0 = new NPTmpRetainingTreeNormalizer.NPTmpRetainingTreeReaderFactory();
      String string1 = "+8'7Ad3nC'lb8RxY[vr";
      StringReader stringReader0 = new StringReader("+8'7Ad3nC'lb8RxY[vr");
      nPTmpRetainingTreeNormalizer_NPTmpRetainingTreeReaderFactory0.newTreeReader(stringReader0);
      Tree.valueOf("))UHXh\"y/{E-EJiO", (TreeReaderFactory) nPTmpRetainingTreeNormalizer_NPTmpRetainingTreeReaderFactory0);
      memoryTreebank0.add((Tree) null);
      // Undeclared exception!
      try { 
        LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank0, options0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.trees.Tree.deepCopy(edu.stanford.nlp.trees.TreeFactory)\" because \"t\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.TreeAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ThrowsNullPointerException0()  throws Throwable  {
      String[] stringArray0 = new String[6];
      stringArray0[0] = "J#| a7Ac";
      stringArray0[1] = "J#| a7Ac";
      stringArray0[2] = "J#| a7Ac";
      stringArray0[3] = "J#| a7Ac";
      stringArray0[4] = "J#| a7Ac";
      stringArray0[5] = "J#| a7Ac";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("J#| a7Ac", stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ThrowsNullPointerException1()  throws Throwable  {
      String[] stringArray0 = new String[2];
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("B", stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.parser.lexparser.LexicalizedParser.setOptionFlags(String[])\" because \"parser\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1ThrowsNullPointerExceptionAndLoadModelTaking1And1WithNonEmptyString()  throws Throwable  {
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("null", (List<String>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"java.util.List.size()\" because \"extraFlags\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1AndLoadModelTaking1And1ThrowsNullPointerException()  throws Throwable  {
      String string0 = "hg";
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("hg", (List<String>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"java.util.List.size()\" because \"extraFlags\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking2ArgumentsWithNull()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      // Undeclared exception!
      try { 
        LexicalizedParser.trainFromTreebank((Treebank) null, (Options) shiftReduceOptions0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testTrainFromTreebankTaking2Arguments()  throws Throwable  {
      MemoryTreebank memoryTreebank0 = new MemoryTreebank(551);
      ItalianTreebankParserParams italianTreebankParserParams0 = new ItalianTreebankParserParams();
      TreeReaderFactory treeReaderFactory0 = italianTreebankParserParams0.treeReaderFactory();
      MemoryTreebank memoryTreebank1 = new MemoryTreebank(memoryTreebank0, treeReaderFactory0, (String) null);
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      Options options0 = spanishUnknownWordModelTrainer0.op;
      // Undeclared exception!
      try { 
        LexicalizedParser.trainFromTreebank((Treebank) memoryTreebank1, (Options) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testParserQueryThrowsNullPointerException()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      String[] stringArray0 = null;
      shiftReduceOptions0.freeDependencies = false;
      int int0 = 701;
      shiftReduceOptions0.setOptionsOrWarn((String[]) null, 701, 701);
      LexicalizedParser.buildTrainTransformer((Options) shiftReduceOptions0);
      // Undeclared exception!
      try { 
        LexicalizedParser.loadModel("Sorry, but parsers with rerankers cannot be saved to text file", (String[]) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read the array length because \"extraFlags\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testLoadModelTaking1And1AndLoadModelTaking1And1WithNonEmptyStringAndLoadModelTaking1And1WithEmptyArray()  throws Throwable  {
      String[] stringArray0 = new String[0];
      LexicalizedParser lexicalizedParser0 = LexicalizedParser.loadModel("-tokenizerfactory", stringArray0);
      assertNull(lexicalizedParser0);
  }

  @Test(timeout = 4000)
  public void testBuildTrainTransformerTakingOptions()  throws Throwable  {
      Options options0 = new Options();
      CompositeTreeTransformer compositeTreeTransformer0 = LexicalizedParser.buildTrainTransformer(options0);
      assertNotNull(compositeTreeTransformer0);
  }

  @Test(timeout = 4000)
  public void testLoadModelTakingNoArgumentsThrowsNullPointerException()  throws Throwable  {
      String string0 = "O{S^cD4a";
      SpanishUnknownWordModelTrainer spanishUnknownWordModelTrainer0 = new SpanishUnknownWordModelTrainer();
      Options options0 = spanishUnknownWordModelTrainer0.op;
      // Undeclared exception!
      try { 
        LexicalizedParser.trainFromTreebank("O{S^cD4a", (FileFilter) null, (Options) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read field \"tlpParams\" because \"op\" is null
         //
         verifyException("edu.stanford.nlp.parser.lexparser.LexicalizedParser", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetParserFromTextFileReturningNull()  throws Throwable  {
      ShiftReduceOptions shiftReduceOptions0 = new ShiftReduceOptions();
      String[] stringArray0 = new String[6];
      stringArray0[0] = "";
      stringArray0[1] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[2] = "o[Zs\"[U$%";
      stringArray0[3] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[4] = "edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory";
      stringArray0[5] = "o[Zs\"[U$%";
      shiftReduceOptions0.setOptions(stringArray0, 1, 1);
      LexicalizedParser.getParserFromTextFile("o[Zs\"[U$%", shiftReduceOptions0);
      ChineseTreebankParserParams chineseTreebankParserParams0 = new ChineseTreebankParserParams();
      // Undeclared exception!
      try { 
        chineseTreebankParserParams0.memoryTreebank();
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class edu.stanford.nlp.trees.international.pennchinese.CTBErrorCorrectingTreeNormalizer
         //
         verifyException("edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams", e);
      }
  }
}
