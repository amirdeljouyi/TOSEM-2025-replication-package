/*
 * This file was automatically generated by UTestGen and EvoSuite
 * Wed Apr 16 15:21:15 GMT 2025
 */

package edu.stanford.nlp.pipeline;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import edu.stanford.nlp.ling.BasicDocument;
import edu.stanford.nlp.ling.CoreAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.ling.Word;
import edu.stanford.nlp.pipeline.Annotation;
import edu.stanford.nlp.pipeline.TokenizerAnnotator;
import edu.stanford.nlp.process.CodepointCoreLabelProcessor;
import edu.stanford.nlp.process.PTBTokenizer;
import edu.stanford.nlp.process.Tokenizer;
import edu.stanford.nlp.trees.TreeGraphNode;
import edu.stanford.nlp.util.CoreMap;
import java.io.Reader;
import java.io.StringReader;
import java.lang.reflect.Array;
import java.util.ArrayList;
import java.util.List;
import java.util.Properties;
import java.util.Set;
import java.util.Stack;
import java.util.Vector;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, separateClassLoader = true) 
public class TokenizerAnnotator_4_ESTest extends TokenizerAnnotator_4_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingPropertiesThrowsRuntimeException0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.put("cdc_tokenize.model", "cdc_tokenize.model");
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // org.evosuite.runtime.mock.java.lang.MockThrowable: Unable to open \"cdc_tokenize.model\" as class path, filename or URL
         //
         verifyException("edu.stanford.nlp.process.stattok.StatTokSent", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetTokenizerType0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.class", "PTBTokenizer");
      properties0.setProperty("tokenize.whitespace", "true");
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      assertEquals(TokenizerAnnotator.TokenizerType.Whitespace, tokenizerAnnotator_TokenizerType0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("ssplit.isOneSentence", "true");
      properties0.setProperty("ssplit.newlineIsSentenceBreak", "never");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Annotation annotation0 = new Annotation("Line1\nLine2");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      CoreLabel coreLabel0 = list0.get(0);
      Class<CoreAnnotations.IsNewlineAnnotation> class1 = CoreAnnotations.IsNewlineAnnotation.class;
      Boolean boolean0 = (Boolean)coreLabel0.get(class1);
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndAnnotate0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.whitespace", "true");
      properties0.setProperty("ssplit.newlineIsSentenceBreak", "always");
      properties0.setProperty("ssplit.isOneSentence", "false");
      Annotation annotation0 = new Annotation("x\ny");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      CoreLabel coreLabel0 = list0.get(0);
      coreLabel0.word();
      CoreLabel coreLabel1 = list0.get(1);
      Class<CoreAnnotations.IsNewlineAnnotation> class1 = CoreAnnotations.IsNewlineAnnotation.class;
      coreLabel1.get(class1);
      assertEquals(10, coreLabel1.size());
      assertEquals(2, list0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate1()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.whitespace", "true");
      properties0.setProperty("tokenize.keepeol", "false");
      properties0.setProperty("ssplit.isOneSentence", "false");
      properties0.setProperty("ssplit.newlineIsSentenceBreak", "always");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Annotation annotation0 = new Annotation("Line1\nLine2");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      int int0 = list0.size();
      assertEquals(2, int0);
  }

  @Test(timeout = 4000)
  public void test0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "xx");
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property xx
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate2()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "ar");
      properties0.setProperty("tokenize.whitespace", "true");
      Annotation annotation0 = new Annotation("word1 word2 word3");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      list0.size();
      CoreLabel coreLabel0 = list0.get(0);
      coreLabel0.word();
      CoreLabel coreLabel1 = list0.get(1);
      String string0 = coreLabel1.word();
      CoreLabel coreLabel2 = list0.get(2);
      String string1 = coreLabel2.word();
      assertFalse(string1.equals((Object)string0));
  }

  @Test(timeout = 4000)
  public void testAnnotate0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.ssplit", "false");
      Annotation annotation0 = new Annotation("Hello sentence splitter.");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.SentencesAnnotation> class0 = CoreAnnotations.SentencesAnnotation.class;
      Object object0 = (Object)annotation0.get(class0);
      assertNull(object0);
  }

  @Test(timeout = 4000)
  public void testAnnotate1()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.codepoint", "true");
      Annotation annotation0 = new Annotation("abc");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      int int0 = list0.size();
      assertEquals(1, int0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndAnnotate1()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.codepoint", "true");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0);
      Annotation annotation0 = new Annotation("Test 123");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      assertFalse(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void test1()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.class", "UnknownTokenizerClass");
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.class property UnknownTokenizerClass
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate3()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      Annotation annotation0 = new Annotation("Hello\nWorld");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      assertEquals(2, list0.size());
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsRuntimeException()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.postProcessor", "edu.stanford.nlp.pipeline.CodepointCoreLabelProcessor");
      properties0.setProperty("tokenize.codepoint", "true");
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Loading: edu.stanford.nlp.pipeline.CodepointCoreLabelProcessor failed with: Error creating edu.stanford.nlp.pipeline.CodepointCoreLabelProcessor
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingPropertiesThrowsRuntimeException1()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.codepoint", "true");
      properties0.setProperty("tokenize.postProcessor", "edu.stanford.nlp.pipeline.CodepointCoreLabelProcessor");
      Annotation annotation0 = new Annotation("AB");
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Loading: edu.stanford.nlp.pipeline.CodepointCoreLabelProcessor failed with: Error creating edu.stanford.nlp.pipeline.CodepointCoreLabelProcessor
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsRuntimeExceptionAndAnnotate()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      Annotation annotation0 = new Annotation("");
      Class<CoreAnnotations.TextAnnotation> class0 = CoreAnnotations.TextAnnotation.class;
      annotation0.remove(class0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate(annotation0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Tokenizer unable to find text in annotation: null
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsRuntimeExceptionAndCreatesTokenizerAnnotatorTakingNoArguments()  throws Throwable  {
      Annotation annotation0 = new Annotation("");
      Class<CoreAnnotations.TextAnnotation> class0 = CoreAnnotations.TextAnnotation.class;
      annotation0.remove(class0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate(annotation0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Tokenizer unable to find text in annotation: null
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate4()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.whitespace", "true");
      properties0.setProperty("tokenize.keepeol", "true");
      Annotation annotation0 = new Annotation("alpha\nbeta");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      CoreLabel coreLabel0 = list0.get(0);
      coreLabel0.word();
      // Undeclared exception!
      try { 
        list0.get(2);
        fail("Expecting exception: IndexOutOfBoundsException");
      
      } catch(IndexOutOfBoundsException e) {
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate5()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.whitespace", "true");
      properties0.setProperty("tokenize.keepeol", "true");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Annotation annotation0 = new Annotation("a\nb");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      assertEquals(2, list0.size());
  }

  @Test(timeout = 4000)
  public void testGetTokenizerType1()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.whitespace", "true");
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      assertEquals(TokenizerAnnotator.TokenizerType.Whitespace, tokenizerAnnotator_TokenizerType0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3ArgumentsAndAnnotate()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.options", "invertible");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0, "tokenizeNLs,");
      Annotation annotation0 = new Annotation("Hello there!");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      int int0 = list0.size();
      assertEquals(3, int0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate6()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.options", "invertible,ptb3Escaping=false");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Annotation annotation0 = new Annotation("mixed options test.");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      boolean boolean0 = list0.isEmpty();
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate7()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("ssplit.newlineIsSentenceBreak", "always");
      properties0.setProperty("ssplit.isOneSentence", "false");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Annotation annotation0 = new Annotation("Line1\nLine2");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      list0.isEmpty();
      assertEquals(2, list0.size());
  }

  @Test(timeout = 4000)
  public void testGetTokenizerType2()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.class", "WhitespaceTokenizer");
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      assertEquals(TokenizerAnnotator.TokenizerType.Whitespace, tokenizerAnnotator_TokenizerType0);
  }

  @Test(timeout = 4000)
  public void testAnnotate2()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("statTokSent.model", "edu/stanford/nlp/models/statssplitter/english-bidirectional.tagger");
      properties0.setProperty("tokenize.cleanxml", "true");
      Annotation annotation0 = new Annotation("test cdc");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      assertFalse(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate8()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.cleanxml", "true");
      Annotation annotation0 = new Annotation("<xml>This & That</xml>");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      assertEquals(3, list0.size());
  }

  @Test(timeout = 4000)
  public void testAdjustFinalToken0()  throws Throwable  {
      CoreLabel coreLabel0 = new CoreLabel();
      Class<CoreAnnotations.AfterAnnotation> class0 = CoreAnnotations.AfterAnnotation.class;
      coreLabel0.set(class0, " ");
      List<CoreLabel> list0 = new ArrayList<CoreLabel>();
      list0.add(coreLabel0);
      TokenizerAnnotator.adjustFinalToken(list0);
      Class<CoreAnnotations.AfterAnnotation> class1 = CoreAnnotations.AfterAnnotation.class;
      Object object0 = coreLabel0.get(class1);
      assertEquals("", object0);
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsIllegalArgumentException()  throws Throwable  {
      Annotation annotation0 = new Annotation("*NL*");
      Annotation annotation1 = new Annotation(annotation0);
      Properties properties0 = new Properties();
      String[] stringArray0 = new String[2];
      stringArray0[0] = "*NL*";
      stringArray0[1] = "*NL*";
      annotation0.toShortString(stringArray0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0, "tokenize.options,");
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate(annotation1);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // PTBLexer: Invalid options key in constructor: tokenize.options
         //
         verifyException("edu.stanford.nlp.process.PTBLexer", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3Arguments0()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0, "sha,");
  }

  @Test(timeout = 4000)
  public void testAdjustFinalToken1()  throws Throwable  {
      CodepointCoreLabelProcessor codepointCoreLabelProcessor0 = new CodepointCoreLabelProcessor();
      Vector<CoreLabel> vector0 = new Vector<CoreLabel>();
      Word word0 = Word.EMPTY;
      TreeGraphNode treeGraphNode0 = new TreeGraphNode(word0);
      TreeGraphNode treeGraphNode1 = treeGraphNode0.highestNodeWithSameHead();
      List<CoreLabel> list0 = treeGraphNode1.yield(vector0);
      PTBTokenizer.PTBTokenizerFactory<Word> pTBTokenizer_PTBTokenizerFactory0 = PTBTokenizer.PTBTokenizerFactory.newWordTokenizerFactory("X%[ ^i!");
      BasicDocument<Class<CoreAnnotations.OriginalTextAnnotation>> basicDocument0 = new BasicDocument<Class<CoreAnnotations.OriginalTextAnnotation>>(pTBTokenizer_PTBTokenizerFactory0);
      basicDocument0.blankDocument();
      List<CoreLabel> list1 = treeGraphNode1.taggedLabeledYield();
      TokenizerAnnotator.adjustFinalToken(list0);
      assertFalse(list0.equals((Object)list1));
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsIllegalArgumentException0()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.French;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
      FileSystemHandling.shouldAllThrowIOExceptions();
      TokenizerAnnotator tokenizerAnnotator1 = null;
      try {
        tokenizerAnnotator1 = new TokenizerAnnotator("");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property 
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString0()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("fr");
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingStringAndCreatesTokenizerAnnotatorTaking2Arguments()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.German;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
      TokenizerAnnotator tokenizerAnnotator1 = new TokenizerAnnotator((String) null);
      assertFalse(tokenizerAnnotator1.equals((Object)tokenizerAnnotator0));
  }

  @Test(timeout = 4000)
  public void testAdjustFinalToken2()  throws Throwable  {
      CoreLabel coreLabel0 = new CoreLabel();
      List<CoreLabel> list0 = new ArrayList<CoreLabel>();
      list0.add(coreLabel0);
      TokenizerAnnotator.adjustFinalToken(list0);
      assertFalse(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAdjustFinalToken()  throws Throwable  {
      CoreLabel coreLabel0 = new CoreLabel();
      Class<CoreAnnotations.AfterAnnotation> class0 = CoreAnnotations.AfterAnnotation.class;
      coreLabel0.set(class0, "");
      List<CoreLabel> list0 = new ArrayList<CoreLabel>();
      list0.add(coreLabel0);
      TokenizerAnnotator.adjustFinalToken(list0);
      assertEquals(1, list0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate9()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("ssplit.isOneSentence", "false");
      properties0.setProperty("ssplit.newlineIsSentenceBreak", "always");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Annotation annotation0 = new Annotation("Test\nTokenizer\n");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      CoreLabel coreLabel0 = list0.get(1);
      Class<CoreAnnotations.IsNewlineAnnotation> class1 = CoreAnnotations.IsNewlineAnnotation.class;
      coreLabel0.get(class1);
      assertEquals(2, list0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndCreatesTokenizerAnnotatorTaking2Arguments()  throws Throwable  {
      Properties properties0 = new Properties();
      Properties properties1 = new Properties(properties0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties1);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2Arguments0()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0);
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAdjustFinalTokenWithNull()  throws Throwable  {
      TokenizerAnnotator.adjustFinalToken((List<CoreLabel>) null);
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenThrowsIllegalArgumentException()  throws Throwable  {
      CoreLabel coreLabel0 = new CoreLabel();
      Class<CoreAnnotations.AfterAnnotation> class0 = CoreAnnotations.AfterAnnotation.class;
      coreLabel0.set(class0, "\t");
      List<CoreLabel> list0 = new ArrayList<CoreLabel>();
      list0.add(coreLabel0);
      // Undeclared exception!
      try { 
        TokenizerAnnotator.adjustFinalToken(list0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // adjustFinalToken: Unexpected final char: |\t| (9)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndRequires()  throws Throwable  {
      Properties properties0 = new Properties();
      CoreAnnotations.StateAnnotation coreAnnotations_StateAnnotation0 = new CoreAnnotations.StateAnnotation();
      Class<CoreLabel> class0 = coreAnnotations_StateAnnotation0.getType();
      properties0.put(class0, class0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      TokenizerAnnotator.adjustFinalToken((List<CoreLabel>) null);
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      TokenizerAnnotator.adjustFinalToken((List<CoreLabel>) null);
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      tokenizerAnnotator0.requirementsSatisfied();
      Reader reader0 = Reader.nullReader();
      tokenizerAnnotator0.getTokenizer(reader0);
      tokenizerAnnotator0.requires();
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.valueOf("");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // No enum constant edu.stanford.nlp.pipeline.TokenizerAnnotator.TokenizerType.
         //
         verifyException("java.lang.Enum", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3ArgumentsAndCreatesTokenizerAnnotatorTaking3Arguments0()  throws Throwable  {
      String string0 = null;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, (String) null, (String) null);
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.German;
      Annotation annotation0 = null;
      try {
        annotation0 = new Annotation((List<CoreMap>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"java.util.List.iterator()\" because \"sentences\" is null
         //
         verifyException("edu.stanford.nlp.pipeline.Annotation", e);
      }
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsNullPointerExceptionAndAnnotateWithAnnotationWhereSizeIsPositive()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator((String) null);
      Annotation annotation0 = new Annotation((String) null);
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate(annotation0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.substring(int, int)\" because \"text\" is null
         //
         verifyException("edu.stanford.nlp.pipeline.WordsToSentencesAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenThrowsUnsupportedOperationException()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Unspecified;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      Class<CoreLabel>[] classArray0 = (Class<CoreLabel>[]) Array.newInstance(Class.class, 7);
      Class<CoreLabel> class0 = CoreLabel.class;
      classArray0[0] = class0;
      Class<CoreLabel> class1 = CoreLabel.class;
      classArray0[1] = class1;
      Class<CoreLabel> class2 = CoreLabel.class;
      classArray0[2] = class2;
      Class<CoreLabel> class3 = CoreLabel.class;
      classArray0[3] = class3;
      Class<CoreLabel> class4 = CoreLabel.class;
      classArray0[4] = class4;
      Class<CoreLabel> class5 = CoreLabel.class;
      classArray0[5] = class5;
      Class<CoreLabel> class6 = CoreLabel.class;
      classArray0[6] = class6;
      String[] stringArray0 = new String[6];
      stringArray0[0] = "f?I&v]6";
      stringArray0[1] = "";
      stringArray0[2] = "tokenize.codepoint";
      stringArray0[3] = "";
      stringArray0[4] = "`~ZIwj`K_BT}ymS!)@p";
      stringArray0[5] = "P0gy]hq$Eu[ADGu~";
      CoreLabel coreLabel0 = null;
      try {
        coreLabel0 = new CoreLabel(classArray0, stringArray0);
        fail("Expecting exception: UnsupportedOperationException");
      
      } catch(UnsupportedOperationException e) {
         //
         // Argument array lengths differ: [class edu.stanford.nlp.ling.CoreLabel, class edu.stanford.nlp.ling.CoreLabel, class edu.stanford.nlp.ling.CoreLabel, class edu.stanford.nlp.ling.CoreLabel, class edu.stanford.nlp.ling.CoreLabel, class edu.stanford.nlp.ling.CoreLabel, class edu.stanford.nlp.ling.CoreLabel] vs. [f?I&v]6, , tokenize.codepoint, , `~ZIwj`K_BT}ymS!)@p, P0gy]hq$Eu[ADGu~]
         //
         verifyException("edu.stanford.nlp.ling.CoreLabel", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("Whitespace");
  }

  @Test(timeout = 4000)
  public void testGetDefaultOptions()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Spanish;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      tokenizerAnnotator0.requires();
      tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.valueOf("invertible,ellipses=ascii,splitAll=false");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // No enum constant edu.stanford.nlp.pipeline.TokenizerAnnotator.TokenizerType.invertible,ellipses=ascii,splitAll=false
         //
         verifyException("java.lang.Enum", e);
      }
  }

  @Test(timeout = 4000)
  public void testRequirementsSatisfied()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false);
      tokenizerAnnotator0.requirementsSatisfied();
      StringReader stringReader0 = new StringReader("OU^BK\"MH%!9v/");
      char[] charArray0 = new char[5];
      charArray0[0] = '(';
      charArray0[1] = 'S';
      charArray0[2] = 'Z';
      charArray0[3] = 'j';
      charArray0[4] = 'T';
      stringReader0.read(charArray0);
      stringReader0.reset();
      tokenizerAnnotator0.getTokenizer(stringReader0);
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requirementsSatisfied();
      assertEquals(15, set0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArgumentsAndRequirementsSatisfied()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requirementsSatisfied();
      assertEquals(15, set0.size());
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsIllegalArgumentException()  throws Throwable  {
      String string0 = "a`u+;";
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(false, "a`u+;");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property a`u+;
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingStringAndFailsToCreateTokenizerAnnotatorTakingStringThrowsIllegalArgumentException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("PXM'Ea1");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property PXM'Ea1
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking3ArgumentsThrowsRuntimeException()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.put("cdc_tokenize.model", "cdc_tokenize.model");
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0, "cdc_tokenize.model");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // org.evosuite.runtime.mock.java.lang.MockThrowable: Unable to open \"cdc_tokenize.model\" as class path, filename or URL
         //
         verifyException("edu.stanford.nlp.process.stattok.StatTokSent", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3Arguments1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, "German", "German");
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2Arguments1()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.German;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      Annotation annotation0 = new Annotation("I#5coAAy_qa;hUE;{W");
      Annotation annotation1 = new Annotation(annotation0);
      String[] stringArray0 = new String[7];
      stringArray0[0] = "I#5coAAy_qa;hUE;{W";
      stringArray0[1] = "I#5coAAy_qa;hUE;{W";
      stringArray0[2] = "I#5coAAy_qa;hUE;{W";
      stringArray0[3] = "I#5coAAy_qa;hUE;{W";
      stringArray0[4] = "I#5coAAy_qa;hUE;{W";
      stringArray0[5] = "I#5coAAy_qa;hUE;{W";
      stringArray0[6] = "I#5coAAy_qa;hUE;{W";
      annotation0.toShorterString(stringArray0);
      // Undeclared exception!
      try { 
        annotation1.setCapacity(0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // You cannot set capacity to smaller than the current size.
         //
         verifyException("edu.stanford.nlp.util.ArrayCoreMap", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString2()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("de");
  }

  @Test(timeout = 4000)
  public void testAnnotateAndCreatesTokenizerAnnotatorTaking2ArgumentsAndRequires()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Whitespace;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      tokenizerAnnotator0.requires();
      TokenizerAnnotator.TokenizerType.values();
      TokenizerAnnotator.TokenizerType.values();
      Stack<CoreMap> stack0 = new Stack<CoreMap>();
      Annotation annotation0 = new Annotation(stack0);
      tokenizerAnnotator0.annotate(annotation0);
      assertEquals(3, annotation0.size());
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsNullPointerException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("Unspecified");
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate((Annotation) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.pipeline.Annotation.containsKey(java.lang.Class)\" because \"annotation\" is null
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenWithEmptyList()  throws Throwable  {
      List<CoreLabel> list0 = new ArrayList<CoreLabel>();
      TokenizerAnnotator.adjustFinalToken(list0);
      assertTrue(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArgumentsAndAnnotate()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Annotation annotation0 = new Annotation("L");
      tokenizerAnnotator0.annotate(annotation0);
      assertEquals(3, annotation0.size());
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsNullPointerExceptionAndCreatesTokenizerAnnotatorTakingNoArguments()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate((Annotation) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.pipeline.Annotation.containsKey(java.lang.Class)\" because \"annotation\" is null
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString3()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("Spanish");
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString4()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("en");
  }

  @Test(timeout = 4000)
  public void testAnnotateAndGetTokenizerType()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Spanish;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
      Properties properties0 = new Properties();
      properties0.toString();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      tokenizerAnnotator0.requires();
      Annotation annotation0 = new Annotation("");
      Annotation annotation1 = new Annotation(annotation0);
      tokenizerAnnotator0.annotate(annotation1);
      assertFalse(annotation0.equals((Object)annotation1));
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArgumentsAndGetTokenizer()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Reader reader0 = Reader.nullReader();
      Tokenizer<CoreLabel> tokenizer0 = tokenizerAnnotator0.getTokenizer(reader0);
      assertNotNull(tokenizer0);
  }

  @Test(timeout = 4000)
  public void testRequiresThrowsRuntimeException()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.clear();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Arabic;
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ArabicSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArgumentsAndCallsRequires()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requires();
      assertTrue(set0.isEmpty());
      
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Spanish;
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.getTokenizerType((Properties) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"java.util.Properties.getProperty(String, String)\" because \"props\" is null
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsIllegalArgumentException1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("X%[ ^i!");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property X%[ ^i!
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3ArgumentsAndCreatesTokenizerAnnotatorTaking3Arguments1()  throws Throwable  {
      Properties properties0 = new Properties();
      CoreAnnotations.AnswerObjectAnnotation coreAnnotations_AnswerObjectAnnotation0 = new CoreAnnotations.AnswerObjectAnnotation();
      Object object0 = new Object();
      properties0.put(coreAnnotations_AnswerObjectAnnotation0, object0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0, "0'1H:R3<*'^<");
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking3ArgumentsThrowsIllegalArgumentException()  throws Throwable  {
      String string0 = "invertible,splitCompounds=false,splitContractions=false,quotes=ORIGINAL";
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(true, "invertible,splitCompounds=false,splitContractions=false,quotes=ORIGINAL", "invertible,splitCompounds=false,splitContractions=false,quotes=ORIGINAL");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property invertible,splitCompounds=false,splitContractions=false,quotes=ORIGINAL
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingPropertiesThrowsNullPointerException()  throws Throwable  {
      Properties properties0 = null;
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator((Properties) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"java.util.Properties.getProperty(String, String)\" because \"properties\" is null
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingProperties()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsRuntimeException0()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("zh");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsRuntimeException1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("Arabic");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ArabicSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsRuntimeException()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Chinese;
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator", e);
      }
  }
}
