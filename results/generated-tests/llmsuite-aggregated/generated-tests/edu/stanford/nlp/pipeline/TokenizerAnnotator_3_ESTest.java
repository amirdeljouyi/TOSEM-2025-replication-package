/*
 * This file was automatically generated by UTestGen and EvoSuite
 * Wed Apr 16 09:11:21 GMT 2025
 */

package edu.stanford.nlp.pipeline;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import edu.stanford.nlp.ling.CoreAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.ling.Label;
import edu.stanford.nlp.ling.WordLemmaTag;
import edu.stanford.nlp.pipeline.Annotation;
import edu.stanford.nlp.pipeline.TokenizerAnnotator;
import edu.stanford.nlp.process.Tokenizer;
import edu.stanford.nlp.sequences.TrueCasingForNISTDocumentReaderAndWriter;
import edu.stanford.nlp.trees.BasicCategoryTreeTransformer;
import edu.stanford.nlp.trees.PennTreebankLanguagePack;
import edu.stanford.nlp.trees.Tree;
import edu.stanford.nlp.trees.TreeGraphNode;
import edu.stanford.nlp.trees.UniversalSemanticHeadFinder;
import edu.stanford.nlp.util.CoreMap;
import java.io.Reader;
import java.util.ArrayList;
import java.util.LinkedList;
import java.util.List;
import java.util.Properties;
import java.util.Set;
import java.util.Stack;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, separateClassLoader = true) 
public class TokenizerAnnotator_3_ESTest extends TokenizerAnnotator_3_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void testGetTokenizerType0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.class", "PTBTokenizer");
      properties0.setProperty("tokenize.whitespace", "true");
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      assertEquals(TokenizerAnnotator.TokenizerType.Whitespace, tokenizerAnnotator_TokenizerType0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndAnnotate0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.whitespace", "true");
      properties0.setProperty("ssplit.newlineIsSentenceBreak", "always");
      properties0.setProperty("ssplit.isOneSentence", "false");
      Annotation annotation0 = new Annotation("x\ny");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      CoreLabel coreLabel0 = list0.get(0);
      String string0 = coreLabel0.word();
      assertEquals("x", string0);
      
      CoreLabel coreLabel1 = list0.get(1);
      Class<CoreAnnotations.IsNewlineAnnotation> class1 = CoreAnnotations.IsNewlineAnnotation.class;
      coreLabel1.get(class1);
      assertEquals(10, coreLabel1.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.whitespace", "true");
      properties0.setProperty("tokenize.keepeol", "false");
      properties0.setProperty("ssplit.isOneSentence", "false");
      properties0.setProperty("ssplit.newlineIsSentenceBreak", "always");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Annotation annotation0 = new Annotation("Line1\nLine2");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      int int0 = list0.size();
      assertEquals(2, int0);
  }

  @Test(timeout = 4000)
  public void test0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "xx");
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property xx
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testAnnotate0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.ssplit", "false");
      Annotation annotation0 = new Annotation("Hello sentence splitter.");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.SentencesAnnotation> class0 = CoreAnnotations.SentencesAnnotation.class;
      Object object0 = (Object)annotation0.get(class0);
      assertNull(object0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndAnnotate1()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.codepoint", "true");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0);
      Annotation annotation0 = new Annotation("Test 123");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      assertFalse(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void test1()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.class", "UnknownTokenizerClass");
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.class property UnknownTokenizerClass
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate1()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      Annotation annotation0 = new Annotation("Hello\nWorld");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      assertEquals(2, list0.size());
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsRuntimeException0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.postProcessor", "edu.stanford.nlp.pipeline.CodepointCoreLabelProcessor");
      properties0.setProperty("tokenize.codepoint", "true");
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Loading: edu.stanford.nlp.pipeline.CodepointCoreLabelProcessor failed with: Error creating edu.stanford.nlp.pipeline.CodepointCoreLabelProcessor
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingPropertiesThrowsRuntimeException()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.codepoint", "true");
      properties0.setProperty("tokenize.postProcessor", "edu.stanford.nlp.pipeline.CodepointCoreLabelProcessor");
      Annotation annotation0 = new Annotation("AB");
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Loading: edu.stanford.nlp.pipeline.CodepointCoreLabelProcessor failed with: Error creating edu.stanford.nlp.pipeline.CodepointCoreLabelProcessor
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsRuntimeExceptionAndCreatesTokenizerAnnotatorTakingNoArguments()  throws Throwable  {
      Annotation annotation0 = new Annotation("");
      Class<CoreAnnotations.TextAnnotation> class0 = CoreAnnotations.TextAnnotation.class;
      annotation0.remove(class0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate(annotation0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Tokenizer unable to find text in annotation: null
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate2()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.whitespace", "true");
      properties0.setProperty("tokenize.keepeol", "true");
      Annotation annotation0 = new Annotation("alpha\nbeta");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      CoreLabel coreLabel0 = list0.get(0);
      coreLabel0.word();
      // Undeclared exception!
      try { 
        list0.get(2);
        fail("Expecting exception: IndexOutOfBoundsException");
      
      } catch(IndexOutOfBoundsException e) {
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate3()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.whitespace", "true");
      properties0.setProperty("tokenize.keepeol", "true");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Annotation annotation0 = new Annotation("a\nb");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      assertEquals(2, list0.size());
  }

  @Test(timeout = 4000)
  public void testGetTokenizerType1()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.whitespace", "true");
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      assertEquals(TokenizerAnnotator.TokenizerType.Whitespace, tokenizerAnnotator_TokenizerType0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3Arguments0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.put("tokenize.options", "tokenize.options");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0, "tokenize.options");
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate4()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("ssplit.newlineIsSentenceBreak", "always");
      properties0.setProperty("ssplit.isOneSentence", "false");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Annotation annotation0 = new Annotation("Line1\nLine2");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      list0.isEmpty();
      assertEquals(2, list0.size());
  }

  @Test(timeout = 4000)
  public void testGetTokenizerType2()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.class", "WhitespaceTokenizer");
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      assertEquals(TokenizerAnnotator.TokenizerType.Whitespace, tokenizerAnnotator_TokenizerType0);
  }

  @Test(timeout = 4000)
  public void testAnnotate1()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("statTokSent.model", "edu/stanford/nlp/models/statssplitter/english-bidirectional.tagger");
      properties0.setProperty("tokenize.cleanxml", "true");
      Annotation annotation0 = new Annotation("test cdc");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      assertEquals(2, list0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate5()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.cleanxml", "true");
      Annotation annotation0 = new Annotation("<xml>This & That</xml>");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      assertEquals(3, list0.size());
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAdjustFinalTokenWithNonEmptyList0()  throws Throwable  {
      CoreLabel coreLabel0 = new CoreLabel();
      Class<CoreAnnotations.AfterAnnotation> class0 = CoreAnnotations.AfterAnnotation.class;
      coreLabel0.set(class0, " ");
      List<CoreLabel> list0 = new ArrayList<CoreLabel>();
      list0.add(coreLabel0);
      TokenizerAnnotator.adjustFinalToken(list0);
      Class<CoreAnnotations.AfterAnnotation> class1 = CoreAnnotations.AfterAnnotation.class;
      Object object0 = coreLabel0.get(class1);
      assertEquals("", object0);
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsRuntimeException1()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Arabic;
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ArabicSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsRuntimeException0()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("ar");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ArabicSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetTokenizerTypeAndAnnotate()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Unspecified;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType1 = TokenizerAnnotator.TokenizerType.German;
      TokenizerAnnotator tokenizerAnnotator1 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType1);
      Annotation annotation0 = new Annotation(":U=iQ}\no\"");
      tokenizerAnnotator0.requires();
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator2 = new TokenizerAnnotator(false, properties0);
      Annotation annotation1 = new Annotation(annotation0);
      tokenizerAnnotator0.annotate(annotation1);
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType2 = TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      assertEquals(TokenizerAnnotator.TokenizerType.English, tokenizerAnnotator_TokenizerType2);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString0()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("de");
  }

  @Test(timeout = 4000)
  public void testAnnotateAndCreatesTokenizerAnnotatorTaking2Arguments()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Properties properties0 = new Properties();
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.French;
      TokenizerAnnotator tokenizerAnnotator1 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      Annotation annotation0 = new Annotation("re-model");
      Properties properties1 = new Properties();
      TokenizerAnnotator tokenizerAnnotator2 = new TokenizerAnnotator(true, properties0);
      tokenizerAnnotator1.annotate(annotation0);
      assertFalse(tokenizerAnnotator1.equals((Object)tokenizerAnnotator2));
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("French");
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsRuntimeException1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("Chinese");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3Arguments1()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0, "YsQdSA#tyyu,");
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2Arguments()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0);
  }

  @Test(timeout = 4000)
  public void testGetTokenizerAndGetTokenizer()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Spanish;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
      TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0 = new TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser();
      List<CoreLabel> list0 = trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0.apply("tokenize.verbose");
      TokenizerAnnotator.adjustFinalToken(list0);
      tokenizerAnnotator0.requires();
      tokenizerAnnotator0.requires();
      TokenizerAnnotator.TokenizerType[] tokenizerAnnotator_TokenizerTypeArray0 = TokenizerAnnotator.TokenizerType.values();
      TokenizerAnnotator.adjustFinalToken((List<CoreLabel>) null);
      tokenizerAnnotator0.getTokenizer((Reader) null);
      TokenizerAnnotator.TokenizerType[] tokenizerAnnotator_TokenizerTypeArray1 = TokenizerAnnotator.TokenizerType.values();
      assertFalse(tokenizerAnnotator_TokenizerTypeArray1.equals((Object)tokenizerAnnotator_TokenizerTypeArray0));
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndCreatesTokenizerAnnotatorTaking2ArgumentsAndRequires()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Whitespace;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0 = new TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser();
      List<CoreLabel> list0 = trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0.apply("tokenize.verbose");
      TokenizerAnnotator.adjustFinalToken(list0);
      tokenizerAnnotator0.requires();
      tokenizerAnnotator0.requires();
      TokenizerAnnotator.TokenizerType.values();
      TokenizerAnnotator.adjustFinalToken((List<CoreLabel>) null);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString2()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("Spanish");
  }

  @Test(timeout = 4000)
  public void testGetDefaultOptions()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0, "1*-yAom");
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Arabic;
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requirementsSatisfied();
      Set<Class<? extends CoreAnnotation>> set1 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requirementsSatisfied();
      assertNotSame(set1, set0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingStringAndRequires()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator((String) null);
      tokenizerAnnotator0.requires();
      // Undeclared exception!
      try { 
        List.of(null, null, null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.util.Objects", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString3()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("Whitespace");
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAdjustFinalTokenWithNonEmptyList1()  throws Throwable  {
      TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0 = new TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser();
      List<CoreLabel> list0 = trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0.apply("xF1");
      TokenizerAnnotator.adjustFinalToken(list0);
      assertEquals(1, list0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString4()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("Unspecified");
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAdjustFinalTokenAndCreatesTokenizerAnnotatorTaking2Arguments()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Unspecified;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0 = new TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser();
      List<CoreLabel> list0 = trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0.apply("tokenize.verbose");
      TokenizerAnnotator.adjustFinalToken(list0);
      tokenizerAnnotator0.requires();
      tokenizerAnnotator0.requires();
      TokenizerAnnotator.TokenizerType.values();
      TokenizerAnnotator.adjustFinalToken((List<CoreLabel>) null);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3ArgumentsAndAnnotate()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.options", "invertible");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0, "tokenizeNLs,");
      Annotation annotation0 = new Annotation("Hello there!");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      int int0 = list0.size();
      assertEquals(3, int0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3ArgumentsAndCreatesTokenizerAnnotatorTaking3Arguments()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.elements();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0, "'4+'G:![48oV5`T");
      tokenizerAnnotator0.requires();
      PennTreebankLanguagePack pennTreebankLanguagePack0 = new PennTreebankLanguagePack();
      BasicCategoryTreeTransformer basicCategoryTreeTransformer0 = new BasicCategoryTreeTransformer(pennTreebankLanguagePack0);
      UniversalSemanticHeadFinder universalSemanticHeadFinder0 = null;
      try {
        universalSemanticHeadFinder0 = new UniversalSemanticHeadFinder(false);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3Arguments2()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, "German", "German");
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAdjustFinalToken()  throws Throwable  {
      CoreLabel coreLabel0 = new CoreLabel();
      Class<CoreAnnotations.AfterAnnotation> class0 = CoreAnnotations.AfterAnnotation.class;
      coreLabel0.set(class0, "");
      List<CoreLabel> list0 = new ArrayList<CoreLabel>();
      list0.add(coreLabel0);
      TokenizerAnnotator.adjustFinalToken(list0);
      assertTrue(list0.contains(coreLabel0));
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsNullPointerExceptionAndAnnotateWithAnnotationWhereSizeIsPositive()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator((String) null);
      Annotation annotation0 = new Annotation((String) null);
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate(annotation0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.substring(int, int)\" because \"text\" is null
         //
         verifyException("edu.stanford.nlp.pipeline.WordsToSentencesAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsNullPointerException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator((String) null);
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate((Annotation) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.pipeline.Annotation.containsKey(java.lang.Class)\" because \"annotation\" is null
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAnnotate2()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.codepoint", "true");
      Annotation annotation0 = new Annotation("abc");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      int int0 = list0.size();
      assertEquals(1, int0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate6()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("ssplit.isOneSentence", "false");
      properties0.setProperty("ssplit.newlineIsSentenceBreak", "always");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Annotation annotation0 = new Annotation("Test\nTokenizer\n");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      assertEquals(2, list0.size());
      
      CoreLabel coreLabel0 = list0.get(1);
      Class<CoreAnnotations.IsNewlineAnnotation> class1 = CoreAnnotations.IsNewlineAnnotation.class;
      coreLabel0.get(class1);
      assertEquals(12, coreLabel0.size());
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsRuntimeExceptionAndAnnotate()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      Annotation annotation0 = new Annotation("");
      Class<CoreAnnotations.TextAnnotation> class0 = CoreAnnotations.TextAnnotation.class;
      annotation0.remove(class0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate(annotation0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Tokenizer unable to find text in annotation: null
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAdjustFinalTokenWithNull()  throws Throwable  {
      TokenizerAnnotator.adjustFinalToken((List<CoreLabel>) null);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArgumentsAndAnnotate()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Annotation annotation0 = new Annotation("re-model");
      tokenizerAnnotator0.annotate(annotation0);
      assertEquals(3, annotation0.size());
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsNullPointerExceptionAndCreatesTokenizerAnnotatorTakingNoArguments()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate((Annotation) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.pipeline.Annotation.containsKey(java.lang.Class)\" because \"annotation\" is null
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAnnotate()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.English;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      tokenizerAnnotator0.requires();
      TokenizerAnnotator.adjustFinalToken((List<CoreLabel>) null);
      LinkedList<CoreMap> linkedList0 = new LinkedList<CoreMap>();
      Annotation annotation0 = new Annotation(linkedList0);
      Annotation annotation1 = new Annotation(annotation0);
      tokenizerAnnotator0.annotate(annotation1);
      tokenizerAnnotator0.requires();
      TokenizerAnnotator.TokenizerType.values();
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.valueOf("hareleg");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // No enum constant edu.stanford.nlp.pipeline.TokenizerAnnotator.TokenizerType.hareleg
         //
         verifyException("java.lang.Enum", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetTokenizerAndCreatesTokenizerAnnotatorTakingNoArguments()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Tokenizer<CoreLabel> tokenizer0 = tokenizerAnnotator0.getTokenizer((Reader) null);
      assertNotNull(tokenizer0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndCallsRequirementsSatisfied()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.English;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
      tokenizerAnnotator0.requirementsSatisfied();
      Properties properties0 = new Properties();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      String string0 = "FrenchTokenizer";
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.valueOf("FrenchTokenizer");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // No enum constant edu.stanford.nlp.pipeline.TokenizerAnnotator.TokenizerType.FrenchTokenizer
         //
         verifyException("java.lang.Enum", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingBoolean()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true);
  }

  @Test(timeout = 4000)
  public void testRequirementsSatisfied()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requirementsSatisfied();
      assertEquals(15, set0.size());
  }

  @Test(timeout = 4000)
  public void testGetTokenizerType3()  throws Throwable  {
      Properties properties0 = new Properties();
      Object object0 = new Object();
      CoreLabel coreLabel0 = CoreLabel.wordFromString("humbug");
      coreLabel0.setTag("humbug");
      coreLabel0.setIsMWT(true);
      properties0.put(object0, coreLabel0);
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      boolean boolean0 = false;
      String string0 = ":(c~ht";
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.valueOf(":(c~ht");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // No enum constant edu.stanford.nlp.pipeline.TokenizerAnnotator.TokenizerType.:(c~ht
         //
         verifyException("java.lang.Enum", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingStringAndFailsToCreateTokenizerAnnotatorTakingStringThrowsIllegalArgumentException()  throws Throwable  {
      String string0 = "x`XtZFU";
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("x`XtZFU");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property x`XtZFU
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString5()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("en");
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenThrowsIllegalArgumentException()  throws Throwable  {
      CoreLabel coreLabel0 = new CoreLabel();
      Class<CoreAnnotations.AfterAnnotation> class0 = CoreAnnotations.AfterAnnotation.class;
      coreLabel0.set(class0, "\t");
      List<CoreLabel> list0 = new ArrayList<CoreLabel>();
      list0.add(coreLabel0);
      // Undeclared exception!
      try { 
        TokenizerAnnotator.adjustFinalToken(list0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // adjustFinalToken: Unexpected final char: |\t| (9)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAdjustFinalTokenAndAdjustFinalTokenWithEmptyList()  throws Throwable  {
      WordLemmaTag wordLemmaTag0 = new WordLemmaTag(" words per second.", "invertible,ptb3Escaping=false,splitHyphenated=true", "ar");
      Stack<Tree> stack0 = new Stack<Tree>();
      TreeGraphNode treeGraphNode0 = new TreeGraphNode(wordLemmaTag0, stack0);
      TreeGraphNode treeGraphNode1 = treeGraphNode0.highestNodeWithSameHead();
      List<CoreLabel> list0 = treeGraphNode1.taggedLabeledYield();
      TokenizerAnnotator.adjustFinalToken(list0);
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.valueOf("");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // No enum constant edu.stanford.nlp.pipeline.TokenizerAnnotator.TokenizerType.
         //
         verifyException("java.lang.Enum", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAdjustFinalTokenWithEmptyList()  throws Throwable  {
      List<CoreLabel> list0 = new ArrayList<CoreLabel>();
      TokenizerAnnotator.adjustFinalToken(list0);
      assertTrue(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingBooleanAndCreatesTokenizerAnnotatorTakingBoolean()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false);
      CoreLabel coreLabel0 = null;
      try {
        coreLabel0 = new CoreLabel((Label) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.ling.Label.value()\" because \"label\" is null
         //
         verifyException("edu.stanford.nlp.ling.CoreLabel", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate7()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("ssplit.isOneSentence", "true");
      properties0.setProperty("ssplit.newlineIsSentenceBreak", "never");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Annotation annotation0 = new Annotation("Line1\nLine2");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      CoreLabel coreLabel0 = list0.get(0);
      Class<CoreAnnotations.IsNewlineAnnotation> class1 = CoreAnnotations.IsNewlineAnnotation.class;
      coreLabel0.get(class1);
      assertEquals(2, list0.size());
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenThrowsNullPointerException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, (String) null, (String) null);
      tokenizerAnnotator0.requirementsSatisfied();
      tokenizerAnnotator0.requires();
      Annotation annotation0 = new Annotation((String) null);
      Stack<CoreLabel> stack0 = new Stack<CoreLabel>();
      TokenizerAnnotator.adjustFinalToken(stack0);
      annotation0.toString();
      annotation0.keySet();
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate(annotation0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"String.substring(int, int)\" because \"text\" is null
         //
         verifyException("edu.stanford.nlp.pipeline.WordsToSentencesAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3Arguments3()  throws Throwable  {
      FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      Reader.nullReader();
      TokenizerAnnotator.TokenizerType.values();
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0, "bR2=@j#%`@x*q,");
      TokenizerAnnotator.TokenizerType[] tokenizerAnnotator_TokenizerTypeArray0 = TokenizerAnnotator.TokenizerType.values();
      assertEquals(8, tokenizerAnnotator_TokenizerTypeArray0.length);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArgumentsAndRequires()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requires();
      assertEquals(0, set0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndCallsRequires()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.requires();
      Object object0 = new Object();
      Object object1 = new Object();
      Object object2 = new Object();
      properties0.put(object0, object2);
      properties0.put(object0, object1);
      MockFile mockFile0 = new MockFile("R!yib#RFfA", "onlap");
      MockFile mockFile1 = null;
      try {
        mockFile1 = new MockFile(mockFile0, (String) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.evosuite.runtime.mock.java.io.MockFile", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsIllegalArgumentException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("2`x6y");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property 2`x6y
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsRuntimeException2()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Whitespace;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType1 = TokenizerAnnotator.TokenizerType.Chinese;
      TokenizerAnnotator tokenizerAnnotator1 = null;
      try {
        tokenizerAnnotator1 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType1);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate8()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "ar");
      properties0.setProperty("tokenize.whitespace", "true");
      Annotation annotation0 = new Annotation("word1 word2 word3");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      int int0 = list0.size();
      assertEquals(3, int0);
      
      CoreLabel coreLabel0 = list0.get(0);
      coreLabel0.word();
      CoreLabel coreLabel1 = list0.get(1);
      coreLabel1.word();
      CoreLabel coreLabel2 = list0.get(2);
      coreLabel2.word();
      assertEquals(10, coreLabel2.size());
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsIllegalArgumentException()  throws Throwable  {
      String string0 = "";
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(true, "");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property 
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }
}
