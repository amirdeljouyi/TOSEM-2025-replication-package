/*
 * This file was automatically generated by UTestGen and EvoSuite
 * Wed Apr 16 21:53:18 GMT 2025
 */

package edu.stanford.nlp.pipeline;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import edu.stanford.nlp.ie.AbstractSequenceClassifier;
import edu.stanford.nlp.ie.ClassifierCombiner;
import edu.stanford.nlp.ie.PresetSequenceClassifier;
import edu.stanford.nlp.ling.CoreAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.pipeline.Annotation;
import edu.stanford.nlp.pipeline.TokenizerAnnotator;
import edu.stanford.nlp.sequences.TrueCasingForNISTDocumentReaderAndWriter;
import edu.stanford.nlp.util.CoreMap;
import java.io.BufferedReader;
import java.io.IOException;
import java.io.Reader;
import java.io.StringReader;
import java.lang.reflect.Array;
import java.nio.CharBuffer;
import java.util.ArrayList;
import java.util.LinkedList;
import java.util.List;
import java.util.Properties;
import java.util.Set;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, separateClassLoader = true) 
public class TokenizerAnnotator_5_ESTest extends TokenizerAnnotator_5_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingPropertiesThrowsRuntimeException0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.put("cdc_tokenize.model", "cdc_tokenize.model");
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // org.evosuite.runtime.mock.java.lang.MockThrowable: Unable to open \"cdc_tokenize.model\" as class path, filename or URL
         //
         verifyException("edu.stanford.nlp.process.stattok.StatTokSent", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetTokenizerType0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.class", "PTBTokenizer");
      properties0.setProperty("tokenize.whitespace", "true");
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      assertEquals(TokenizerAnnotator.TokenizerType.Whitespace, tokenizerAnnotator_TokenizerType0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("ssplit.isOneSentence", "true");
      properties0.setProperty("ssplit.newlineIsSentenceBreak", "never");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Annotation annotation0 = new Annotation("Line1\nLine2");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      CoreLabel coreLabel0 = list0.get(0);
      Class<CoreAnnotations.IsNewlineAnnotation> class1 = CoreAnnotations.IsNewlineAnnotation.class;
      Boolean boolean0 = (Boolean)coreLabel0.get(class1);
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndAnnotate0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.whitespace", "true");
      properties0.setProperty("ssplit.newlineIsSentenceBreak", "always");
      properties0.setProperty("ssplit.isOneSentence", "false");
      Annotation annotation0 = new Annotation("x\ny");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      CoreLabel coreLabel0 = list0.get(0);
      coreLabel0.word();
      assertEquals(2, list0.size());
      
      CoreLabel coreLabel1 = list0.get(1);
      Class<CoreAnnotations.IsNewlineAnnotation> class1 = CoreAnnotations.IsNewlineAnnotation.class;
      coreLabel1.get(class1);
      assertEquals(10, coreLabel1.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate1()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.whitespace", "true");
      properties0.setProperty("tokenize.keepeol", "false");
      properties0.setProperty("ssplit.isOneSentence", "false");
      properties0.setProperty("ssplit.newlineIsSentenceBreak", "always");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Annotation annotation0 = new Annotation("Line1\nLine2");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      int int0 = list0.size();
      assertEquals(2, int0);
  }

  @Test(timeout = 4000)
  public void test0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "xx");
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property xx
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate2()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "ar");
      properties0.setProperty("tokenize.whitespace", "true");
      Annotation annotation0 = new Annotation("word1 word2 word3");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      list0.size();
      CoreLabel coreLabel0 = list0.get(0);
      String string0 = coreLabel0.word();
      assertEquals("word1", string0);
      
      CoreLabel coreLabel1 = list0.get(1);
      coreLabel1.word();
      CoreLabel coreLabel2 = list0.get(2);
      coreLabel2.word();
      assertEquals(10, coreLabel2.size());
  }

  @Test(timeout = 4000)
  public void testAnnotate0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.ssplit", "false");
      Annotation annotation0 = new Annotation("Hello sentence splitter.");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.SentencesAnnotation> class0 = CoreAnnotations.SentencesAnnotation.class;
      Object object0 = (Object)annotation0.get(class0);
      assertNull(object0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate3()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.put("tokenize.ssplit", "tokenize.ssplit");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Annotation annotation0 = new Annotation("D:?Jl");
      tokenizerAnnotator0.annotate(annotation0);
      assertEquals(2, annotation0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndAnnotate1()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.codepoint", "true");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0);
      Annotation annotation0 = new Annotation("Test 123");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      assertEquals(2, list0.size());
  }

  @Test(timeout = 4000)
  public void test1()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.class", "UnknownTokenizerClass");
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.class property UnknownTokenizerClass
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate4()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      Annotation annotation0 = new Annotation("Hello\nWorld");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      assertEquals(2, list0.size());
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsRuntimeException0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.postProcessor", "edu.stanford.nlp.pipeline.CodepointCoreLabelProcessor");
      properties0.setProperty("tokenize.codepoint", "true");
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Loading: edu.stanford.nlp.pipeline.CodepointCoreLabelProcessor failed with: Error creating edu.stanford.nlp.pipeline.CodepointCoreLabelProcessor
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingPropertiesThrowsRuntimeException1()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.codepoint", "true");
      properties0.setProperty("tokenize.postProcessor", "edu.stanford.nlp.pipeline.CodepointCoreLabelProcessor");
      Annotation annotation0 = new Annotation("AB");
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Loading: edu.stanford.nlp.pipeline.CodepointCoreLabelProcessor failed with: Error creating edu.stanford.nlp.pipeline.CodepointCoreLabelProcessor
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsRuntimeExceptionAndCreatesTokenizerAnnotatorTakingNoArguments()  throws Throwable  {
      Annotation annotation0 = new Annotation("");
      Class<CoreAnnotations.TextAnnotation> class0 = CoreAnnotations.TextAnnotation.class;
      annotation0.remove(class0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate(annotation0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Tokenizer unable to find text in annotation: null
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate5()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.whitespace", "true");
      properties0.setProperty("tokenize.keepeol", "true");
      Annotation annotation0 = new Annotation("alpha\nbeta");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      CoreLabel coreLabel0 = list0.get(0);
      coreLabel0.word();
      // Undeclared exception!
      try { 
        list0.get(2);
        fail("Expecting exception: IndexOutOfBoundsException");
      
      } catch(IndexOutOfBoundsException e) {
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate6()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.whitespace", "true");
      properties0.setProperty("tokenize.keepeol", "true");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Annotation annotation0 = new Annotation("a\nb");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      assertEquals(2, list0.size());
  }

  @Test(timeout = 4000)
  public void testGetTokenizerType1()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.whitespace", "true");
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      assertEquals(TokenizerAnnotator.TokenizerType.Whitespace, tokenizerAnnotator_TokenizerType0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingProperties0()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.put("tokenize.options", "tokenize.options");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate7()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("ssplit.newlineIsSentenceBreak", "always");
      properties0.setProperty("ssplit.isOneSentence", "false");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Annotation annotation0 = new Annotation("Line1\nLine2");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      boolean boolean0 = list0.isEmpty();
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void testGetTokenizerType2()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.class", "WhitespaceTokenizer");
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      assertEquals(TokenizerAnnotator.TokenizerType.Whitespace, tokenizerAnnotator_TokenizerType0);
  }

  @Test(timeout = 4000)
  public void testAnnotate1()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("statTokSent.model", "edu/stanford/nlp/models/statssplitter/english-bidirectional.tagger");
      properties0.setProperty("tokenize.cleanxml", "true");
      Annotation annotation0 = new Annotation("test cdc");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      assertEquals(2, list0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate8()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.cleanxml", "true");
      Annotation annotation0 = new Annotation("<xml>This & That</xml>");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      assertEquals(3, list0.size());
  }

  @Test(timeout = 4000)
  public void testAdjustFinalToken0()  throws Throwable  {
      CoreLabel coreLabel0 = new CoreLabel();
      Class<CoreAnnotations.AfterAnnotation> class0 = CoreAnnotations.AfterAnnotation.class;
      coreLabel0.set(class0, " ");
      List<CoreLabel> list0 = new ArrayList<CoreLabel>();
      list0.add(coreLabel0);
      TokenizerAnnotator.adjustFinalToken(list0);
      Class<CoreAnnotations.AfterAnnotation> class1 = CoreAnnotations.AfterAnnotation.class;
      Object object0 = coreLabel0.get(class1);
      assertEquals("", object0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndCreatesTokenizerAnnotatorTaking3Arguments()  throws Throwable  {
      CoreLabel coreLabel0 = new CoreLabel(12);
      coreLabel0.setSentIndex(12);
      List.of(coreLabel0, coreLabel0, coreLabel0, coreLabel0, coreLabel0, coreLabel0, coreLabel0, coreLabel0);
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0, "( zs,");
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.German;
      TokenizerAnnotator tokenizerAnnotator1 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
      assertFalse(tokenizerAnnotator1.equals((Object)tokenizerAnnotator0));
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3Arguments0()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0, ",");
  }

  @Test(timeout = 4000)
  public void testRequiresThrowsIllegalArgumentException()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.German;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      TokenizerAnnotator tokenizerAnnotator1 = null;
      try {
        tokenizerAnnotator1 = new TokenizerAnnotator("_");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property _
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString0()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("German");
  }

  @Test(timeout = 4000)
  public void testRequirementsSatisfied()  throws Throwable  {
      CoreLabel coreLabel0 = new CoreLabel(12);
      List<CoreLabel> list0 = new ArrayList<CoreLabel>();
      TokenizerAnnotator.adjustFinalToken(list0);
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.French;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
      byte[] byteArray0 = new byte[2];
      byteArray0[0] = (byte) (-6);
      byteArray0[1] = (byte)55;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      tokenizerAnnotator0.requirementsSatisfied();
      tokenizerAnnotator0.requires();
      tokenizerAnnotator0.requires();
      Properties properties0 = new Properties();
      PresetSequenceClassifier<CoreLabel> presetSequenceClassifier0 = new PresetSequenceClassifier<CoreLabel>(properties0);
      Reader.nullReader();
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType1 = TokenizerAnnotator.TokenizerType.Whitespace;
      TokenizerAnnotator tokenizerAnnotator1 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType1);
      assertFalse(tokenizerAnnotator1.equals((Object)tokenizerAnnotator0));
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2Arguments0()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.French;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndGetTokenizerType()  throws Throwable  {
      Reader.nullReader();
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Spanish;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
      TokenizerAnnotator.TokenizerType.values();
      Properties properties0 = new Properties();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.valueOf((String) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Name is null
         //
         verifyException("java.lang.Enum", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("es");
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsRuntimeException1()  throws Throwable  {
      boolean boolean0 = false;
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Arabic;
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(false, tokenizerAnnotator_TokenizerType0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ArabicSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetDefaultOptions()  throws Throwable  {
      TokenizerAnnotator.TokenizerType.values();
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Unspecified;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
      tokenizerAnnotator0.requires();
      tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      tokenizerAnnotator0.requirementsSatisfied();
      Properties properties0 = new Properties();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      ArrayList<CoreMap> arrayList0 = new ArrayList<CoreMap>();
      Annotation annotation0 = new Annotation(arrayList0);
      Annotation annotation1 = new Annotation("invertible,ptb3Escaping=true");
      Annotation annotation2 = new Annotation(annotation1);
      annotation2.copy();
      tokenizerAnnotator0.annotate(annotation2);
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.valueOf("invertible,ptb3Escaping=true");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // No enum constant edu.stanford.nlp.pipeline.TokenizerAnnotator.TokenizerType.invertible,ptb3Escaping=true
         //
         verifyException("java.lang.Enum", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString2()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("Unspecified");
  }

  @Test(timeout = 4000)
  public void testAdjustFinalToken1()  throws Throwable  {
      TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0 = new TrueCasingForNISTDocumentReaderAndWriter.LineToTrueCasesParser();
      List<CoreLabel> list0 = trueCasingForNISTDocumentReaderAndWriter_LineToTrueCasesParser0.apply("$VALUES");
      TokenizerAnnotator.adjustFinalToken(list0);
      assertFalse(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAdjustFinalToken0()  throws Throwable  {
      CoreLabel coreLabel0 = new CoreLabel(12);
      List<CoreLabel> list0 = List.of(coreLabel0, coreLabel0, coreLabel0, coreLabel0, coreLabel0, coreLabel0, coreLabel0, coreLabel0);
      TokenizerAnnotator.adjustFinalToken(list0);
      String string0 = null;
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.valueOf((String) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Name is null
         //
         verifyException("java.lang.Enum", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2Arguments1()  throws Throwable  {
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Whitespace;
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingStringAndAnnotate()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("French");
      Annotation annotation0 = new Annotation("French");
      tokenizerAnnotator0.annotate(annotation0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString3()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator("Whitespace");
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking3ArgumentsThrowsIllegalArgumentException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(false, "?", "?");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property ?
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenThrowsIOException()  throws Throwable  {
      TokenizerAnnotator.TokenizerType.values();
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      boolean boolean0 = false;
      boolean boolean1 = true;
      AbstractSequenceClassifier<CoreLabel>[] abstractSequenceClassifierArray0 = (AbstractSequenceClassifier<CoreLabel>[]) Array.newInstance(AbstractSequenceClassifier.class, 2);
      String[] stringArray0 = new String[8];
      stringArray0[0] = "it";
      stringArray0[1] = "";
      stringArray0[2] = "";
      stringArray0[3] = "";
      stringArray0[4] = ",'T6h0;E\"]";
      stringArray0[5] = "";
      stringArray0[6] = "Q)";
      stringArray0[7] = "";
      ClassifierCombiner<CoreLabel> classifierCombiner0 = null;
      try {
        classifierCombiner0 = new ClassifierCombiner<CoreLabel>(stringArray0);
        fail("Expecting exception: IOException");
      
      } catch(Throwable e) {
         //
         // Couldn't load classifier from it
         //
         verifyException("edu.stanford.nlp.ie.ClassifierCombiner", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsRuntimeException0()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("Chinese");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTakingStringThrowsRuntimeException1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("ar");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ArabicSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsRuntimeException()  throws Throwable  {
      boolean boolean0 = true;
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Chinese;
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(true, tokenizerAnnotator_TokenizerType0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Expected a property segment.model
         //
         verifyException("edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3ArgumentsAndAnnotate()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.options", "invertible");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0, "tokenizeNLs,");
      Annotation annotation0 = new Annotation("Hello there!");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      int int0 = list0.size();
      assertEquals(3, int0);
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking3ArgumentsThrowsRuntimeException()  throws Throwable  {
      Annotation annotation0 = new Annotation("<?rb[Zv-\"^+R1eJrR'p");
      Properties properties0 = new Properties();
      properties0.put("cdc_tokenize.model", "<?rb[Zv-\"^+R1eJrR'p");
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0, "cdc_tokenize.model");
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // org.evosuite.runtime.mock.java.lang.MockThrowable: Unable to open \"<?rb[Zv-\"^+R1eJrR'p\" as class path, filename or URL
         //
         verifyException("edu.stanford.nlp.process.stattok.StatTokSent", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking3Arguments1()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, "en", "en");
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsNullPointerExceptionAndCreatesTokenizerAnnotatorTakingBoolean()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true);
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate((Annotation) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.pipeline.Annotation.containsKey(java.lang.Class)\" because \"annotation\" is null
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2Arguments2()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, (String) null);
      Annotation annotation0 = null;
      try {
        annotation0 = new Annotation((List<CoreMap>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"java.util.List.iterator()\" because \"sentences\" is null
         //
         verifyException("edu.stanford.nlp.pipeline.Annotation", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingBoolean()  throws Throwable  {
      TokenizerAnnotator.TokenizerType.values();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true);
      Class<Object>[] classArray0 = (Class<Object>[]) Array.newInstance(Class.class, 1);
      Class<Object> class0 = Object.class;
      classArray0[0] = class0;
      String[] stringArray0 = new String[5];
      stringArray0[0] = "ar";
      stringArray0[1] = "J@'WY7G`u4~bvd9";
      stringArray0[2] = "Whitespace";
      stringArray0[3] = "Y=e";
      stringArray0[4] = "tokenize.class";
      CoreLabel coreLabel0 = null;
      try {
        coreLabel0 = new CoreLabel(classArray0, stringArray0);
        fail("Expecting exception: UnsupportedOperationException");
      
      } catch(UnsupportedOperationException e) {
         //
         // Argument array lengths differ: [class java.lang.Object] vs. [ar, J@'WY7G`u4~bvd9, Whitespace, Y=e, tokenize.class]
         //
         verifyException("edu.stanford.nlp.ling.CoreLabel", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingBooleanAndCallsGetTokenizer()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false);
      tokenizerAnnotator0.getTokenizer((Reader) null);
      Properties properties0 = new Properties();
      Object object0 = new Object();
      String string0 = null;
      CoreAnnotations.OriginalTextAnnotation coreAnnotations_OriginalTextAnnotation0 = new CoreAnnotations.OriginalTextAnnotation();
      // Undeclared exception!
      try { 
        properties0.put(coreAnnotations_OriginalTextAnnotation0, (Object) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.util.concurrent.ConcurrentHashMap", e);
      }
  }

  @Test(timeout = 4000)
  public void testFailsToCreateTokenizerAnnotatorTaking2ArgumentsThrowsIllegalArgumentException()  throws Throwable  {
      String string0 = "9`UM";
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator(false, "9`UM");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property 9`UM
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingStringAndFailsToCreateTokenizerAnnotatorTakingStringThrowsIllegalArgumentException()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = null;
      try {
        tokenizerAnnotator0 = new TokenizerAnnotator("o");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // TokenizerAnnotator: unknown tokenize.language property o
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenAndAdjustFinalToken1()  throws Throwable  {
      CoreLabel coreLabel0 = new CoreLabel();
      Class<CoreAnnotations.AfterAnnotation> class0 = CoreAnnotations.AfterAnnotation.class;
      coreLabel0.set(class0, "");
      List<CoreLabel> list0 = new ArrayList<CoreLabel>();
      list0.add(coreLabel0);
      TokenizerAnnotator.adjustFinalToken(list0);
      assertEquals(1, list0.size());
  }

  @Test(timeout = 4000)
  public void testAnnotate2()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      properties0.setProperty("tokenize.codepoint", "true");
      Annotation annotation0 = new Annotation("abc");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      int int0 = list0.size();
      assertEquals(1, int0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingPropertiesAndAnnotate9()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("ssplit.isOneSentence", "false");
      properties0.setProperty("ssplit.newlineIsSentenceBreak", "always");
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      Annotation annotation0 = new Annotation("Test\nTokenizer\n");
      tokenizerAnnotator0.annotate(annotation0);
      Class<CoreAnnotations.TokensAnnotation> class0 = CoreAnnotations.TokensAnnotation.class;
      List<CoreLabel> list0 = (List<CoreLabel>)annotation0.get(class0);
      CoreLabel coreLabel0 = list0.get(1);
      Class<CoreAnnotations.IsNewlineAnnotation> class1 = CoreAnnotations.IsNewlineAnnotation.class;
      coreLabel0.get(class1);
      assertEquals(2, list0.size());
      assertEquals(12, coreLabel0.size());
  }

  @Test(timeout = 4000)
  public void testGetTokenizerWithNonNull()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0, "");
      StringReader stringReader0 = new StringReader(")m;}o0W|(Hz1}#8O");
      tokenizerAnnotator0.getTokenizer(stringReader0);
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.German;
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType1 = TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      TokenizerAnnotator.TokenizerType.values();
      tokenizerAnnotator0.requirementsSatisfied();
      tokenizerAnnotator_TokenizerType1.getDefaultOptions();
      tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      TokenizerAnnotator.TokenizerType.values();
      tokenizerAnnotator0.getTokenizer(stringReader0);
      LinkedList<CoreMap> linkedList0 = new LinkedList<CoreMap>();
      Annotation annotation0 = new Annotation(linkedList0);
      tokenizerAnnotator0.annotate(annotation0);
      BufferedReader bufferedReader0 = new BufferedReader(stringReader0, 833);
      CharBuffer charBuffer0 = CharBuffer.allocate(833);
      bufferedReader0.read(charBuffer0);
      tokenizerAnnotator0.getTokenizer(bufferedReader0);
      StringReader stringReader1 = null;
      try {
        stringReader1 = new StringReader((String) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsRuntimeExceptionAndAnnotate()  throws Throwable  {
      Properties properties0 = new Properties();
      properties0.setProperty("tokenize.language", "en");
      Annotation annotation0 = new Annotation("");
      Class<CoreAnnotations.TextAnnotation> class0 = CoreAnnotations.TextAnnotation.class;
      annotation0.remove(class0);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate(annotation0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Tokenizer unable to find text in annotation: null
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenWithEmptyList()  throws Throwable  {
      List<CoreLabel> list0 = new ArrayList<CoreLabel>();
      TokenizerAnnotator.adjustFinalToken(list0);
      assertEquals(0, list0.size());
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArgumentsAndAnnotate()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Annotation annotation0 = new Annotation("zlB5)V,.RV@C110#-");
      tokenizerAnnotator0.annotate(annotation0);
      assertEquals(3, annotation0.size());
  }

  @Test(timeout = 4000)
  public void testAnnotateThrowsNullPointerExceptionAndCreatesTokenizerAnnotatorTakingNoArguments()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      // Undeclared exception!
      try { 
        tokenizerAnnotator0.annotate((Annotation) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot invoke \"edu.stanford.nlp.pipeline.Annotation.containsKey(java.lang.Class)\" because \"annotation\" is null
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingNoArguments()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requirementsSatisfied();
      assertEquals(15, set0.size());
      
      String string0 = "invertible,splitCompounds=false,splitContractions=false,quotes=ORIGINAL";
      Annotation annotation0 = new Annotation("invertible,splitCompounds=false,splitContractions=false,quotes=ORIGINAL");
      tokenizerAnnotator0.annotate(annotation0);
      Properties properties0 = new Properties();
      Annotation annotation1 = new Annotation("invertible,splitCompounds=false,splitContractions=false,quotes=ORIGINAL");
      tokenizerAnnotator0.annotate(annotation1);
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      tokenizerAnnotator_TokenizerType0.getDefaultOptions();
      tokenizerAnnotator0.requirementsSatisfied();
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      TokenizerAnnotator.TokenizerType.getTokenizerType(properties0);
      String[] stringArray0 = new String[8];
      stringArray0[0] = "invertible,splitCompounds=false,splitContractions=false,quotes=ORIGINAL";
      stringArray0[1] = "invertible,splitCompounds=false,splitContractions=false,quotes=ORIGINAL";
      stringArray0[2] = "invertible";
      stringArray0[3] = "invertible,splitCompounds=false,splitContractions=false,quotes=ORIGINAL";
      stringArray0[4] = "invertible";
      stringArray0[5] = "invertible,splitCompounds=false,splitContractions=false,quotes=ORIGINAL";
      stringArray0[6] = "invertible,splitCompounds=false,splitContractions=false,quotes=ORIGINAL";
      stringArray0[7] = "Beginning tokenization";
      CoreLabel coreLabel0 = null;
      try {
        coreLabel0 = new CoreLabel((Class[]) null, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // Cannot read the array length because \"keys\" is null
         //
         verifyException("edu.stanford.nlp.ling.CoreLabel", e);
      }
  }

  @Test(timeout = 4000)
  public void testGetTokenizer()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      tokenizerAnnotator0.getTokenizer((Reader) null);
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenThrowsIllegalArgumentException()  throws Throwable  {
      CoreLabel coreLabel0 = new CoreLabel();
      Class<CoreAnnotations.AfterAnnotation> class0 = CoreAnnotations.AfterAnnotation.class;
      coreLabel0.set(class0, "\t");
      List<CoreLabel> list0 = new ArrayList<CoreLabel>();
      list0.add(coreLabel0);
      // Undeclared exception!
      try { 
        TokenizerAnnotator.adjustFinalToken(list0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // adjustFinalToken: Unexpected final char: |\t| (9)
         //
         verifyException("edu.stanford.nlp.pipeline.TokenizerAnnotator", e);
      }
  }

  @Test(timeout = 4000)
  public void testAdjustFinalTokenWithNull()  throws Throwable  {
      TokenizerAnnotator.adjustFinalToken((List<CoreLabel>) null);
  }

  @Test(timeout = 4000)
  public void testRequiresAndCreatesTokenizerAnnotatorTakingNoArguments()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator();
      Set<Class<? extends CoreAnnotation>> set0 = (Set<Class<? extends CoreAnnotation>>)tokenizerAnnotator0.requires();
      assertTrue(set0.isEmpty());
  }

  @Test(timeout = 4000)
  public void testRequiresAndAdjustFinalToken()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0);
      TokenizerAnnotator.adjustFinalToken((List<CoreLabel>) null);
      TokenizerAnnotator.TokenizerType.values();
      tokenizerAnnotator0.requires();
      TokenizerAnnotator.TokenizerType tokenizerAnnotator_TokenizerType0 = TokenizerAnnotator.TokenizerType.Chinese;
      // Undeclared exception!
      try { 
        TokenizerAnnotator.TokenizerType.valueOf("yI");
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // No enum constant edu.stanford.nlp.pipeline.TokenizerAnnotator.TokenizerType.yI
         //
         verifyException("java.lang.Enum", e);
      }
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2Arguments3()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(true, properties0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingProperties1()  throws Throwable  {
      Properties properties0 = new Properties();
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(properties0);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTakingString4()  throws Throwable  {
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator((String) null);
  }

  @Test(timeout = 4000)
  public void testCreatesTokenizerAnnotatorTaking2ArgumentsAndCreatesTokenizerAnnotatorTaking2Arguments()  throws Throwable  {
      Properties properties0 = new Properties(731);
      TokenizerAnnotator tokenizerAnnotator0 = new TokenizerAnnotator(false, properties0);
  }
}
